<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[kafka相关]]></title>
    <url>%2F2025%2F01%2F03%2Fsenssic.github.io%2F202211%2Fkafka%2F</url>
    <content type="text"><![CDATA[Ⅰ kafka配置SASL认证https://blog.csdn.net/weixin_38251332/article/details/105637628 kafka安全机制kakfa 的安全机制主要分为两部分： 身份认证（Authentication）： 对客户端的身份进行认证 权限控制（Authorization）： 对topic级别的权限进行控制 kafka 目前支持 SSL，SASL(Kerberos)，SASL（PLAIN) 三种认证机制。 这里只讲解最容易实现的SASL（PLAIN）机制，值的注意的是SASL(PLAIN)是通过明文传输用户名和密码的。因此在不安全的网络环境下需要建立在TLS安全层之上。 kafka的service配置SASL用户名密码 1.在配置文件所在目录添加jaas的文件 kafka_server_jaas.conf 123456KafkaServer &#123; org.apache.kafka.common.security.plain.PlainLoginModule required username=&quot;admin&quot; password=&quot;admin-123&quot; user_admin=&quot;admin-123&quot;;&#125;; 2.修改kafka服务配置文件 server.properties 增加 1234567#追加如下内容inter.broker.listener.name=INTERNAL#inter.broker.listener.name=SASL_PLAINTEXTsasl.mechanism.inter.broker.protocol=PLAINsasl.enabled.mechanisms=PLAINauthorizer.class.name = kafka.security.auth.SimpleAclAuthorizersuper.users=User:admin 3.在服务启动脚本增加对于认证的配置kafka-server-start.sh 123#增加加载jaas的配置，替换上述文件的最后两行export KAFKA_OPTS="-Djava.security.auth.login.config=/opt/kafka/config/kafka_server_jaas.conf"exec $base_dir/kafka-run-class.sh $EXTRA_ARGS kafka.Kafka "$@" 若此时客户端想链接需要配置如下 1.假设你有一个用户名为user，密码为password，你可以将这些凭据添加到命令中，如下所示： 1kafka-consumer-groups.bat --bootstrap-server INTERNAL://kafka.test.cn:9092 --command-config client-sasl.properties --list 2.在这里，client-sasl.properties文件是包含认证凭据信息的配置文件，其内容可能类似于： 123security.protocol=SASL_PLAINTEXTsasl.mechanism=PLAINsasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username="user" password="password"; 你需要根据你的实际情况修改用户名和密码。 然后执行就会自动认证链接上kafka了 3.Java客户端链接,无配置文件模式 123props.put("security.protocol", "SASL_PLAINTEXT");props.put("sasl.mechanism", "PLAIN");props.put("sasl.jaas.config", "org.apache.kafka.common.security.plain.PlainLoginModule required username=\"admin\" password=\"adminpasswd\";"); springboot链接模式 12345678910111213141516171819spring: kafka: bootstrap-servers: kafka.test.cn:443 producer: retries: 0 batch-size: 16384 buffer-memory: 33554432 key-serializer: org.apache.kafka.common.serialization.StringSerializer value-serializer: org.apache.kafka.common.serialization.StringSerializer properties: sasl.mechanism: PLAIN security.protocol: SASL_PLAINTEXT jaas: enabled: true loginModule: org.apache.kafka.common.security.plain.PlainLoginModule controlFlag: REQUIRED options: username: admin password: admin-123 Ⅱ kafka 权限控制的配置(ACL控制) 使用非超级用户(即不在super.users=配置的)用户之前先需要ACL授权,超级用户不受ACL权限控制。 权限的内容 权限 说明 READ 读取topic WRITE 写入topic DELETE 删除topic CREATE 创建topic ALTER 修改topic DESCRIBE 获取topic信息 kafka提供命令行工具来添加和修改acl。该命令行工具位于 kafka 目录 ==bin/kafka-acls.sh== Option Description Default Option type –add Indicates to the script that user is trying to add an acl. Action –remove Indicates to the script that user is trying to remove an acl. Action –list Indicates to the script that user is trying to list acts. Action –authorizer Fully qualified class name of the authorizer. kafka.security.auth.SimpleAclAuthorizer Configuration –authorizer-properties key=val pairs that will be passed to authorizer for initialization. For the default authorizer the example values are: zookeeper.connect=localhost:2181 Configuration –cluster Specifies cluster as resource. Resource –topic [topic-name] Specifies the topic as resource. Resource –group [group-name] Specifies the consumer-group as resource. Resource –allow-principal Principal is in PrincipalType:name format that will be added to ACL with Allow permission. You can specify multiple –allow-principal in a single command. Principal –deny-principal Principal is in PrincipalType:name format that will be added to ACL with Deny permission. You can specify multiple –deny-principal in a single command. Principal –allow-host IP address from which principals listed in –allow-principal will have access. if –allow-principal is specified defaults to * which translates to “all hosts” Host –deny-host IP address from which principals listed in –deny-principal will be denied access. if –deny-principal is specified defaults to * which translates to “all hosts” Host –operation Operation that will be allowed or denied. Valid values are : Read, Write, Create, Delete, Alter, Describe, ClusterAction, All All Operation –producer Convenience option to add/remove acls for producer role. This will generate acls that allows WRITE, DESCRIBE on topic and CREATE on cluster. Convenience –consumer Convenience option to add/remove acls for consumer role. This will generate acls that allows READ, DESCRIBE on topic and READ on consumer-group. Convenience 配置例子： add 操作 12# 为用户 alice 在 test（topic）上添加读写的权限bin/kafka-acls.sh --authorizer-properties zookeeper.connect=localhost:2181 --add --allow-principal User:alice --operation Read --operation Write --topic test list 操作 12# 列出 topic 为 test 的所有权限账户bin/kafka-acls.sh --authorizer-properties zookeeper.connect=localhost:2181 --list --topic test remove 操作 12# 移除 Alice 在 test(topic) 上的读写权限bin/kafka-acls.sh --authorizer-properties zookeeper.connect=localhost:2181 --remove --allow-principal User:Alice --operation Read --operation Write --topic test producer 和 consumer 的操作 1234# producerbin/kafka-acls.sh --authorizer-properties zookeeper.connect=localhost:2181 --add --allow-principal User:alice --producer --topic test#consumerbin/kafka-acls.sh --authorizer-properties zookeeper.connect=localhost:2181 --add --allow-principal User:alice --consumer --topic test --group test-group 三，kafka监听地址配置https://juejin.cn/post/6893410969611927566 kafka的监听主要是对两个参数进行配置listeners和advertised.listeners,关于这两个参数总结一句话就是 listeners 指明 kafka 当前节点监听本机的哪个网卡 advertised.listeners 指明客户端通过哪个 ip 可以访问到当前节点 ​ 建议在配，监听地址的时候通过域名配置，这样可以通过配置不同的host解决基于NAT暴露给外部的情况。比如，只用listeners ，采用域名的方式，内部hosts配置kafka本机，外部客户端链接的时候也是同样的域名但是ip配置为外网的ip，由于端口是外网ip端口映射到这个内网端口地址上，所以直接可以请求成功，效果类似于内网穿透。 效果等同如下: 内网ip: 192.168.0.213, 外网ip: 101.89.163.9 但是无网卡，SASL认证 12345678listener.security.protocol.map=INTERNAL:SASL_PLAINTEXT,EXTERNAL:SASL_PLAINTEXTlisteners=INTERNAL://192.168.0.213:19092,EXTERNAL://192.168.0.213:443advertised.listeners=INTERNAL://192.168.0.213:19092,EXTERNAL://101.89.163.9:443inter.broker.listener.name=INTERNALsasl.mechanism.inter.broker.protocol=PLAINsasl.enabled.mechanisms=PLAINauthorizer.class.name = kafka.security.auth.SimpleAclAuthorizersuper.users=User:admin]]></content>
      <categories>
        <category>kafka</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[UML类图相关]]></title>
    <url>%2F2025%2F01%2F03%2Fsenssic.github.io%2F202201%2FUML%E7%B1%BB%E5%9B%BE%E7%9B%B8%E5%85%B3%2F</url>
    <content type="text"><![CDATA[1.UML类之间的关系 如上述UML图: 1.实现: 类实现抽象接口或者抽象类的关系为实现，使用空心箭头虚线标识 2.泛化: 类集成非抽象类的关系为泛化，使用空心箭头的实线标识 3.组合: 此类对象在逻辑上由其他组合而来，由实心箭头的实线标识 4.依赖: 此类和另一个类的关系为依赖关系，比如学生要用自行车上学，由带箭头的虚线标识 5.聚合: 类和另外一个类的关系为集合关系，比如学生和班级，苹果和苹果树，由带空心箭头的实线标识 6.关联: 类和另外一个类有联关系，由无箭头的实线标识 几种关系所表现的强弱程度依次为:组合&gt;聚合&gt;关联&gt;依赖 泛化关系(generalization)​ is-a的关系是个继承的关系，两个对象之间如果可以用 is-a 来表示，就是继承结构，泛化关系是继承结构的一种，另一种是实现关系。 泛化关系用一条带空心箭头的直接表示；如下图表示（B继承自A） 代码的最终表现形式为，继承非抽象类。 实现关系(realize)实现也是 is-a的关系属于继承结构的一种，表示具体事物对抽象事务的具象化。 实现关系用一条带空心箭头的虚线表示；如下图表示（B实现自A） 代码的最终表现形式为，实现抽象类。 聚合关系(aggregation)​ 聚合属于has-a的关系，表示对象之间的集合从属关系，比如苹果树上包含很多苹果，班级包含很多学生。 ​ 聚合关系用一条带空心菱形箭头的直线表示，表示B聚合到A上，或者说A由B组成； 属于关联，整体与部分的关系。聚合是独立的，不随整体共存亡的（生命周期不同步）。 组合关系(composition)contains-a关系，表示对象之间是组成关系，体现了共存的强关系。 组合关系用一条带实心菱形箭头直线表示，如下图表示B组成A，或者A由B组成； 组合关系无法独立存在，与整体共存亡（生命周期同步）。 关联关系(association) 联关系默认不强调方向，表示对象间相互知道，它描述不同类的对象之间的结构关系；它是一种静态关系， 通常与运行状态无关，一般由常识等因素决定的；它一般用来定义对象之间静态的、天然的结构； 所以，关联关系是一种“强关联”的关系； 关联关系是用一条直线表示的； 在最终代码中，关联对象通常是以成员变量的形式实现的； 依赖关系(dependency)​ 依赖关系(Dependency) 是一种使用关系，特定事物的改变有可能会影响到使用该事物的其他事物，在需要表示一个事物使用另一个事物时使用依赖关系，一般都有明确的依赖方向，且应该杜绝双向依赖。 依赖关系用带箭头的虚线表示，由依赖的一方指向被依赖的一方。 依赖关系体现为类构造方法及类方法的传入参数，箭头的指向为调用关系；依赖关系除了临时知道对方外，还“使用”对方的方法和属性；]]></content>
      <categories>
        <category>UML</category>
      </categories>
      <tags>
        <tag>UML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[fastdfs简明教程]]></title>
    <url>%2F2025%2F01%2F03%2Fsenssic.github.io%2F202109%2Ffastdfs%E5%B8%B8%E7%94%A8%E8%83%BD%E5%8A%9B%2F</url>
    <content type="text"><![CDATA[1.docker安装fastdfs+fastdht12#IP为宿主机ip,指定此IP后会使用宿主机网络,即容器内启动的端口宿主机上都会有docker run -d --restart=always --net=host --name=fastdfs -e IP=192.168.0.105 -v ~/fastdfs:/var/local qbanxiaoli/fastdfs 2.fastdfs防盗链配置编辑容器内部 /etc/fdfs/http.conf配置文件，注意第三项修改，文件必须存在且可以被访问到，不然访问的时候会一直卡死住 1234567891011121314151617181920212223242526272829# HTTP default content typehttp.default_content_type = application/octet-stream# MIME types mapping filename# MIME types file format: MIME_type extensions# such as: image/jpeg jpeg jpg jpe# you can use apache&apos;s MIME file: mime.typeshttp.mime_types_filename=mime.types# if use token to anti-steal# default value is false (0)http.anti_steal.check_token=true # 修改1，开启防盗链检查# token TTL (time to live), seconds# default value is 600http.anti_steal.token_ttl=900 # 选择性修改token的过期时间# secret key to generate anti-steal token# this parameter must be set when http.anti_steal.check_token set to true·# the length of the secret key should not exceed 128 byteshttp.anti_steal.secret_key=123456 # 修改2，防盗链密码# return the content of the file when check token fail# default value is empty (no file sepecified)http.anti_steal.token_check_fail=/root/error.jpg # 修改3，配置拒绝访问后显示的图片，需要是个有效可访问的图片# if support multi regions for HTTP Range# default value is truehttp.multi_range.enabed = true 重启容器内部的nginx 1/usr/local/nginx_fdfs/sbin/nginx -s reload 防盗链的token生成代码示例。 12345&lt;dependency&gt; &lt;groupId&gt;org.csource&lt;/groupId&gt; &lt;artifactId&gt;fastdfs-client-java&lt;/artifactId&gt; &lt;version&gt;1.27-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; 123456789101112131415//fileurl示例:group1/M00/00/90/ChP4nmEx3BCAACgfAACy8Sp--xQ309.pngpublic static String getTokenUrl(String fileUrl) throws Exception &#123; String path = StorePath.parseFromUrl(fileUrl).getPath(); //时间戳 单位为秒 int ts = (int) (System.currentTimeMillis() / 1000); String token; try &#123; //上一步配置的防盗链密码 token = ProtoCommon.getToken(path, ts, "123456"); &#125; catch (Exception e) &#123; throw new Exception("FastDFS获取token异常"); &#125; return fileUrl + "?token=" + token + "&amp;ts=" + ts; &#125; 直接加上storage的地址可以尝试生成文件或图片地址，可以多次生成此包含token的url。若token失效或者错误，则会跳转到配置的/root/error.jpg这个文件上。 3.其他fastdfs相关1.命令api 查看fastdfs信息 1/usr/bin/fdfs_monitor /etc/fdfs/storage.conf 命令上传图片测试 1/usr/bin/fdfs_upload_file /etc/fdfs/client.conf ./nginx-1.14.0.tar.gz 命令文件删除 1/usr/bin/fdfs_delete_file /etc/fdfs/client.conf group1/M00/00/00/wKg4CltFU7WAAzX-AA-B0CmJB5A.tar.gz 2.文件路径解释 在fdfs传一份文件时，通常会返回下面的一串字符，这包含了该文件在服务器端一些存储信息 1M00/00/00/wKg4C1tFmTWAFPKBAADdeFFxlXA240.png 下面解释一下这串东西都是什么： group1：是storage的组号，一个fastdfs集群可以有多个组，一个组内可以有多个storage节点（备份容灾） M00：Mxx：xx为十六进制字符，表示存放的基路径（base path）序号。如果存放的base path只有一个，那固定就是M00，这样FastDFS支持多个磁盘（base path），所以要通过Mxx来区分，其中xx为磁盘的序号，基于0。数据就可以根据store_path0=/data/fastdfs/storage # 如果store_path0没有就去找base_path存数据，两个是一样的，所有固定为M00 /00/01/:store_path0=/data/fastdfs/storage配置的目录下的目录，用于存放上传的数据 3.fastdht ​ 由于FastDFS本身不能对重复上传的文件进行去重，而FastDHT可以做到去重。FastDHT是一个高性能的分布式哈希系统，它是基于键值对存储的，而且它需要依赖于Berkeley DB作为数据存储的媒介，同时需要依赖于libfastcommon。]]></content>
      <categories>
        <category>fastdfs</category>
      </categories>
      <tags>
        <tag>fastdfs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[minikube试验田]]></title>
    <url>%2F2025%2F01%2F03%2Fsenssic.github.io%2F202106%2Fminikube%E8%AF%95%E9%AA%8C%E7%94%B0%2F</url>
    <content type="text"><![CDATA[1.linux下载并安装minikube并启动12345678910111213141516171819202122232425262728#1.创建非root用户adduser testpasswd test#创建docker组sudo groupadd docker#将您的用户添加到该docker组sudo usermod -aG docker test#在Linux上，运行以下命令来激活对组的更改newgrp docker#2.安装dockercurl -fsSL https://get.docker.com | bash -s docker --mirror aliyun#3.安装kubectlcurl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectlsudo chmod a+x ./kubectlsudo mv ./kubectl /usr/local/bin/kubectl#4.安装minikubecurl -Lo minikube https://kubernetes.oss-cn-hangzhou.aliyuncs.com/minikube/releases/v1.20.0/minikube-linux-amd64 &amp;&amp; chmod +x minikube &amp;&amp; sudo mv minikube /usr/local/bin/#5.多节点启动##创建主集群(默认Profile为minikube,可以加 -p 创建不通的k8s集群)minikube start --force##增加节点minikube node add##查看节点minikube node list##启动主节点仪表盘minikube dashboard##删除集群minikube delete 2.开启Kubernetes试验田 2.1 物理机访问虚拟机内部的容器1234#虚拟机开启路由转发echo "net.ipv4.ip_forward=1" &gt;&gt; /etc/sysctl.conf#物理机 win10 路由表加入route add 172.18.0.0 mask 255.255.255.0 192.168.137.200 2.2 登录harhubdocker build -t 10.19.151.227/test/docker-test . harbor地址：https://10.19.151.227 用户名：admin 密码：Xinzhiharbor123 1234567891011vim /etc/docker/daemon.json&#123; &quot;registry-mirrors&quot;: [ &quot;https://dockerhub.azk8s.cn&quot;, &quot;https://hub-mirror.c.163.com&quot; ], &quot;insecure-registries&quot;: [ &quot;10.19.151.227&quot; ]&#125;docker login -u $&#123;HARBOR_CREDS_USR&#125; -p $&#123;HARBOR_CREDS_PSW&#125; harbor.zuoguocai.xyz:4443]]></content>
      <categories>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis集群监控key过期]]></title>
    <url>%2F2025%2F01%2F03%2Fsenssic.github.io%2F202105%2Freds%E9%9B%86%E7%BE%A4%E7%9B%91%E6%8E%A7key%E8%BF%87%E6%9C%9F%2F</url>
    <content type="text"><![CDATA[工作中遇到需要监听redis过期时间,整理了一下redis集群过期监听的设置过程。注意key的监听比较消耗资源，测试完毕后记得将监听设置去除掉。 修改redis配置文件​ 集群的redis需要在每个集群redis配置文件中开启redis过期监听。将redis配置文件中的(redis.conf) notify-keyspace-events设置未Ex即可。所有集群的配置文件都需要更改。 ​ ​ 当然也可以不用重启redis动态更新redis的配置。因为我这边只是做测试使用，所以直接使用这种方式了，不用重启redis集群立即生效，每个redis集群节点都需要设置一下。 123config set notify-keyspace-events Ex# 查十分配置成功config get notify-keyspace-events 关于notify-keyspace-events 配置含义可以参考下图 ​ 集成springboot配置依赖123456789101112131415161718192021222324252627282930&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;2.1.7.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;cn.hutool&lt;/groupId&gt; &lt;artifactId&gt;hutool-all&lt;/artifactId&gt; &lt;version&gt;5.6.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 配置文件123456server: port: 8201spring: redis: cluster: nodes: 10.11.136.121:7001,10.11.136.121:7002,10.11.136.122:7001,10.11.136.122:7002,10.11.136.123:7001,10.11.136.123:7002 redis监听配置类123456789101112131415161718192021222324252627282930@Configuration@ConditionalOnClass(&#123;JedisConnection.class, RedisOperations.class, Jedis.class, MessageListener.class&#125;)@AutoConfigureAfter(&#123;JacksonAutoConfiguration.class, RedisAutoConfiguration.class&#125;)public class RedisAutoConfiguration &#123; @Configuration public static class RedisStandAloneAutoConfiguration &#123; @Bean public RedisMessageListenerContainer customizeRedisListenerContainer( RedisConnectionFactory redisConnectionFactory, MessageListener messageListener) &#123; RedisMessageListenerContainer redisMessageListenerContainer = new RedisMessageListenerContainer(); redisMessageListenerContainer.setConnectionFactory(redisConnectionFactory); redisMessageListenerContainer.addMessageListener(messageListener, new PatternTopic("__keyevent@0__:expired")); return redisMessageListenerContainer; &#125; &#125; @Configuration public static class RedisClusterAutoConfiguration &#123; @Bean public RedisMessageListenerFactory redisMessageListenerFactory(BeanFactory beanFactory, RedisConnectionFactory redisConnectionFactory) &#123; RedisMessageListenerFactory beans = new RedisMessageListenerFactory(); beans.setBeanFactory(beanFactory); beans.setRedisConnectionFactory(redisConnectionFactory); return beans; &#125; &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class RedisMessageListenerFactory implements BeanFactoryAware, ApplicationListener&lt;ContextRefreshedEvent&gt; &#123; private DefaultListableBeanFactory beanFactory; private RedisConnectionFactory redisConnectionFactory; @Autowired private MessageListener messageListener; @Override public void setBeanFactory(BeanFactory beanFactory) throws BeansException &#123; this.beanFactory = (DefaultListableBeanFactory) beanFactory; &#125; public void setRedisConnectionFactory(RedisConnectionFactory redisConnectionFactory) &#123; this.redisConnectionFactory = redisConnectionFactory; &#125; @Override public void onApplicationEvent(ContextRefreshedEvent contextRefreshedEvent) &#123; RedisClusterConnection redisClusterConnection = redisConnectionFactory.getClusterConnection(); if (redisClusterConnection != null) &#123; Iterable&lt;RedisClusterNode&gt; nodes = redisClusterConnection.clusterGetNodes(); for (RedisClusterNode node : nodes) &#123; if (node.isMaster()) &#123; System.out.println("获取到redis的master节点为[&#123;&#125;]" + node.toString()); String containerBeanName = "messageContainer" + node.hashCode(); if (beanFactory.containsBean(containerBeanName)) &#123; return; &#125; JedisShardInfo jedisShardInfo = new JedisShardInfo(node.getHost(), node.getPort()); JedisConnectionFactory factory = new JedisConnectionFactory(jedisShardInfo); BeanDefinitionBuilder containerBeanDefinitionBuilder = BeanDefinitionBuilder .genericBeanDefinition(RedisMessageListenerContainer.class); containerBeanDefinitionBuilder.addPropertyValue("connectionFactory", factory); containerBeanDefinitionBuilder.setScope(BeanDefinition.SCOPE_SINGLETON); containerBeanDefinitionBuilder.setLazyInit(false); beanFactory.registerBeanDefinition(containerBeanName, containerBeanDefinitionBuilder.getRawBeanDefinition()); RedisMessageListenerContainer container = beanFactory.getBean(containerBeanName, RedisMessageListenerContainer.class); String listenerBeanName = "messageListener" + node.hashCode(); if (beanFactory.containsBean(listenerBeanName)) &#123; return; &#125; container.addMessageListener(messageListener, new PatternTopic("__keyevent@0__:expired")); container.start(); &#125; &#125; &#125; &#125;&#125; redis工具类1234567891011121314151617181920212223242526272829303132333435363738394041424344@Componentpublic class RedisHelper &#123; @Autowired private StringRedisTemplate stringRedisTemplate; /** * scan 实现 * * @param pattern * 表达式 * @param consumer * 对迭代到的key进行操作 */ public void scan(String pattern, Consumer&lt;byte[]&gt; consumer) &#123; this.stringRedisTemplate.execute((RedisConnection connection) -&gt; &#123; try (Cursor&lt;byte[]&gt; cursor = connection.scan(ScanOptions.scanOptions().count(Long.MAX_VALUE).match(pattern).build())) &#123; cursor.forEachRemaining(consumer); return null; &#125; catch (IOException e) &#123; e.printStackTrace(); throw new RuntimeException(e); &#125; &#125;); &#125; /** * 获取符合条件的key * * @param pattern * 表达式 * @return */ public List&lt;String&gt; keys(String pattern) &#123; List&lt;String&gt; keys = new ArrayList&lt;&gt;(); this.scan(pattern, item -&gt; &#123; //符合条件的key String key = new String(item, StandardCharsets.UTF_8); keys.add(key); &#125;); return keys; &#125;&#125; 监听过期123456789101112@Componentpublic class KeyExpiredEventMessageListener implements MessageListener &#123; @Override public void onMessage(Message message, byte[] pattern) &#123; String expiredKey = message.toString(); System.out.println(DateUtil.format(new Date(), DatePattern.CHINESE_DATE_TIME_PATTERN) + "======接收监听====" + expiredKey); &#125;&#125; 运行主类1234567891011121314151617181920212223242526272829303132@SpringBootApplication@RestController@EnableSchedulingpublic class RedisTestApplication &#123; @Autowired private RedisHelper redisHelper; public static void main(String[] args) &#123; SpringApplication.run(RedisTestApplication.class, args); &#125; @Autowired protected StringRedisTemplate redisTemplate; @RequestMapping("/testRedis") public void testRedis() &#123; redisHelper.scan("SECURE:*", bytes -&gt; &#123; String key = new String(bytes, StandardCharsets.UTF_8); System.out.println(DateUtil.format(new Date(), DatePattern.CHINESE_DATE_TIME_PATTERN) + " key: " + key + " ===&gt; " + redisTemplate.getExpire(key, TimeUnit.SECONDS)); &#125;); &#125; @Scheduled(fixedRate = 30 * 60 * 1000) public void scheduler() &#123; System.out.println("=========&gt; start scan &lt;========="); redisHelper.scan("SECURE:*", bytes -&gt; &#123; String key = new String(bytes, StandardCharsets.UTF_8); System.out.println(DateUtil.format(new Date(), DatePattern.CHINESE_DATE_TIME_PATTERN) + " key: " + key + " ===&gt; " + redisTemplate.getExpire(key, TimeUnit.SECONDS)); &#125;); System.out.println("=========&gt; stop scan &lt;========="); &#125;&#125;]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tk-mybatis的自定义Mapper实现原理]]></title>
    <url>%2F2025%2F01%2F03%2Fsenssic.github.io%2F202103%2Ftk-mybatis%E7%9A%84%E8%87%AA%E5%AE%9A%E4%B9%89Mapper%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[1.环境版本 spring-boot 2.1.7.RELEASE mapper-spring-boot-starter 2.1.5 2.基本原理 MappedStatement MappedStatement维护了一条&lt;select|update|delete|insert&gt;节点的封装 SqlSource 负责根据用户传递的parameterObject，动态地生成SQL语句，将信息封装到BoundSql对象中。 BoundSql 示动态生成的SQL语句以及相应的参数信息 当调用SqlSource的getBoundSql方法，传入的就是parameterMappings相对应的参数,最终生成BoundSql对象,有了BoundSql就可以执行sql语句了。 ​ 在 MyBatis 中，使用@SelectProvider 这种方式定义的方法，最终会构造成 ProviderSqlSource，ProviderSqlSource 是一种处于中间的 SqlSource，它本身不能作为最终执行时使用的 SqlSource，但是他会根据指定方法返回的 SQL 去构造一个可用于最后执行的 StaticSqlSource，StaticSqlSource的特点就是静态 SQL，支持在 SQL 中使用#{param} 方式的参数，但是不支持 ， 等标签。 12345public interface SelectMapper&lt;T&gt; &#123; //使用mybatis提供的@SelectProvider注解 @SelectProvider(type = BaseSelectProvider.class, method = "dynamicSQL") List&lt;T&gt; select(T record);&#125; ​ 在 MyBatis 中，每一个方法（注解或 XML 方式）经过处理后，最终会构造成 MappedStatement 实例，这个对象包含了方法id（namespace+id）、结果映射、缓存配置、SqlSource 等信息，和 SQL 关系最紧密的是其中的 SqlSource，MyBatis 最终执行的 SQL 时就是通过这个接口的 getBoundSql 方法获取的。 ​ 针对不同的运行环境，需要用不同的方式去替换。当使用纯 MyBatis （没有Spring）方式运行时，替换很简单，因为会在系统中初始化 SqlSessionFactory，可以初始化的时候进行替换，这个时候也不会出现前面提到的问题。替换的方式也很简单，通过 SqlSessionFactory 可以得到 SqlSession，然后就能得到 Configuration，通过 configuration.getMappedStatements() 就能得到所有的 MappedStatement，循环判断其中的方法是否为通用接口提供的方法，如果是就按照前面的方式替换就可以了。 ​ 在使用 Spring 的情况下，以继承的方式重写了 MapperScannerConfigurer 和 MapperFactoryBean，在 Spring 调用 checkDaoConfig 的时候对 SqlSource 进行替换。在使用 Spring Boot 时，提供的 mapper-starter 中，直接注入 List sqlSessionFactoryList 进行替换。 3.基于springboot版本的代码分析​ tk.mybatis.spring.mapper.MapperFactoryBean为整个基于springboot加载的入口类。其继承的抽象类org.springframework.dao.support.DaoSupport实现了org.springframework.beans.factory.InitializingBean最终会执行到MapperFactoryBean的checkDaoConfig()方法。 12345678910111213141516171819202122//位置tk.mybatis.spring.mapper.MapperFactoryBean,动态创建每个mapper的代理protected void checkDaoConfig() &#123; super.checkDaoConfig(); Assert.notNull(this.mapperInterface, "Property 'mapperInterface' is required"); Configuration configuration = this.getSqlSession().getConfiguration(); if (this.addToConfig &amp;&amp; !configuration.hasMapper(this.mapperInterface)) &#123; try &#123; configuration.addMapper(this.mapperInterface); &#125; catch (Exception var6) &#123; this.logger.error("Error while adding the mapper '" + this.mapperInterface + "' to configuration.", var6); throw new IllegalArgumentException(var6); &#125; finally &#123; ErrorContext.instance().reset(); &#125; &#125; if (configuration.hasMapper(this.mapperInterface) &amp;&amp; this.mapperHelper != null &amp;&amp; this.mapperHelper.isExtendCommonMapper(this.mapperInterface)) &#123; //为每个代理的mapper开始配置 this.mapperHelper.processConfiguration(this.getSqlSession().getConfiguration(), this.mapperInterface); &#125; &#125; 匹配MappedStatement进行配置，类位置tk.mybatis.mapper.mapperhelper.MapperHelper 123456789101112131415161718public void processConfiguration(Configuration configuration, Class&lt;?&gt; mapperInterface) &#123; String prefix; if (mapperInterface != null) &#123; prefix = mapperInterface.getCanonicalName(); &#125; else &#123; prefix = ""; &#125; //通过configuration获取所有getMappedStatements,循环匹配 for (Object object : new ArrayList&lt;Object&gt;(configuration.getMappedStatements())) &#123; if (object instanceof MappedStatement) &#123; MappedStatement ms = (MappedStatement) object; if (ms.getId().startsWith(prefix)) &#123; //开始处理此MappedStatements processMappedStatement(ms); &#125; &#125; &#125; &#125; 继续处理，找到之前通过扫描缓存的MapperTemplate,所有@SelectProvider注解指定的自定义provider类都会继承MapperTemplate,后续缓存的信息进行和MapperTemplate进行设置处理，类位置tk.mybatis.mapper.mapperhelper.MapperHelper 12345678public void processMappedStatement(MappedStatement ms)&#123; //根据id找到之前缓存的MapperTemplate MapperTemplate mapperTemplate = isMapperMethod(ms.getId()); if(mapperTemplate != null &amp;&amp; ms.getSqlSource() instanceof ProviderSqlSource) &#123; //替换SqlSource,替换信息从mapperTemplate而来 setSqlSource(ms, mapperTemplate); &#125; &#125; 继续跟进设置,为每个MappedStatement替换其setSqlSource,类位置tk.mybatis.mapper.mapperhelper.MapperTemplate 12345678910111213141516171819202122232425262728293031public void setSqlSource(MappedStatement ms) throws Exception &#123; if (this.mapperClass == getMapperClass(ms.getId())) &#123; throw new MapperException("请不要配置或扫描通用Mapper接口类：" + this.mapperClass); &#125; Method method = methodMap.get(getMethodName(ms)); try &#123; //第一种，直接操作ms，不需要返回值 if (method.getReturnType() == Void.TYPE) &#123; method.invoke(this, ms); &#125; //第二种，返回SqlNode else if (SqlNode.class.isAssignableFrom(method.getReturnType())) &#123; SqlNode sqlNode = (SqlNode) method.invoke(this, ms); DynamicSqlSource dynamicSqlSource = new DynamicSqlSource(ms.getConfiguration(), sqlNode); setSqlSource(ms, dynamicSqlSource); &#125; //第三种，返回xml形式的sql字符串 else if (String.class.equals(method.getReturnType())) &#123; String xmlSql = (String) method.invoke(this, ms); SqlSource sqlSource = createSqlSource(ms, xmlSql); //替换原有的SqlSource setSqlSource(ms, sqlSource); &#125; else &#123; throw new MapperException("自定义Mapper方法返回类型错误,可选的返回类型为void,SqlNode,String三种!"); &#125; &#125; catch (IllegalAccessException e) &#123; throw new MapperException(e); &#125; catch (InvocationTargetException e) &#123; throw new MapperException(e.getTargetException() != null ? e.getTargetException() : e); &#125; &#125; 支持在spring容器启动完毕后，所有的MappedStatement的SqlSource都已经被替换完毕。后续的增删等直接调用spring和mybatis的原生接口即可实现。 MyBatis 通用 Mapper 实现原理]]></content>
      <categories>
        <category>mybatis</category>
      </categories>
      <tags>
        <tag>mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rabbitmq简明介绍]]></title>
    <url>%2F2025%2F01%2F03%2Fsenssic.github.io%2F202103%2Frabbitmq%E7%AE%80%E6%98%8E%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[1 rabbit关键概念1.1 rabbit内部概念说明 Message 消息，消息是不具名的，它由消息头和消息体组成。消息体是不透明的，而消息头则由一系列的可选属性组成，这些属性包括routing-key（路由键）、priority（相对于其他消息的优先权）、delivery-mode（指出该消息可能需要持久性存储）等。 Publisher 消息的生产者，也是一个向交换器发布消息的客户端应用程序。 Exchange 交换器，用来接收生产者发送的消息并将这些消息路由给服务器中的队列。 Binding 绑定，用于消息队列和交换器之间的关联。一个绑定就是基于路由键将交换器和消息队列连接起来的路由规则，所以可以将交换器理解成一个由绑定构成的路由表。 Queue 消息队列，用来保存消息直到发送给消费者。它是消息的容器，也是消息的终点。一个消息可投入一个或多个队列。消息一直在队列里面，等待消费者连接到这个队列将其取走。 Connection 网络连接，比如一个TCP连接。 Channel 信道，多路复用连接中的一条独立的双向数据流通道。信道是建立在真实的TCP连接内地虚拟连接，AMQP 命令都是通过信道发出去的，不管是发布消息、订阅队列还是接收消息，这些动作都是通过信道完成。因为对于操作系统来说建立和销毁 TCP 都是非常昂贵的开销，所以引入了信道的概念，以复用一条 TCP 连接。 Consumer 消息的消费者，表示一个从消息队列中取得消息的客户端应用程序。 Virtual Host 虚拟主机，表示一批交换器、消息队列和相关对象。虚拟主机是共享相同的身份认证和加密环境的独立服务器域。每个 vhost 本质上就是一个 mini 版的 RabbitMQ 服务器，拥有自己的队列、交换器、绑定和权限机制。vhost 是 AMQP 概念的基础，必须在连接时指定，RabbitMQ 默认的 vhost 是 / 。 Broker 表示消息队列服务器实体。 1.2 rabbitmq中exchange的类型​ AMQP 中增加了 Exchange 和 Binding 的角色。生产者把消息发布到 Exchange 上，消息最终到达队列并被消费者接收，而 Binding 决定交换器的消息应该发送到那个队列。 ​ 发送端(Publisher)只需要关注将消息内容发送到哪个交换器(exchange)以及要发送的绑定(Binding)是什么关键值即可。 ​ 接收端(Consumer)在启动的时候关注自己的队列(Queue)是哪个，以及绑定到哪个交换器(exchange)以及绑定(Binding)是什么。这样启动后就能获取对应的Publisher发送过来的消息。无论是发送端(Publisher)和 接收端(Consumer)谁先启动都会创建其对应的交换器(exchange)，注意消费端和发送端的exchange类型要保持一致不然先启动的创建后另一个再启动会报错。 exchange的类型Exchange分发消息时根据类型的不同分发策略有区别，目前共四种类型：direct、fanout、topic、headers 。headers 匹配 AMQP 消息的 header 而不是路由键，此外 headers 交换器和 direct 交换器完全一致，但性能差很多，目前几乎用不到了，所以直接看另外三种类型： direct 在使用同一个交换机下,消息中的路由键（routing key）如果和 Binding 中的 binding key 一致， 交换器就将消息发到对应的队列中。它是完全匹配、单播的模式。若每个消费者都启动一个队列去监听这个binding key就和另一种fanout效果一致,变相等效于广播形式。若想实现类似于消费组的功能(组内只有一个消费者收到消息)则可以使用同一个队列进行传递消息。 fanout ​ 每个发到 fanout 类型交换器的消息都会分到所有绑定的队列上去。fanout 交换器不处理路由键，只是简单的将队列绑定到交换器上，每个发送到交换器的消息都会被转发到与该交换器绑定的所有队列上。无论生产者和消费则设置为什么都不会影响。很像子网广播，每台子网内的主机都获得了一份复制的消息。fanout 类型转发消息是最快的。 topic ​ topic 交换器通过模式匹配分配消息的路由键属性，将路由键和某个模式进行匹配，此时队列需要绑定到一个模式上。它将路由键和绑定键的字符串切分成单词，这些单词之间用点隔开。它同样也会识别两个通配符：符号“#”和符号“&#42;”。#匹配0个或多个单词，&#42;匹配不多不少一个单词。 ​ 生产者所有发送到Topic Exchange的消息会通过指定Routing Key被转发到能和其匹配的Queue上。Exchange指定Routing Key将路由进行模糊匹配。可以使用通配符进行模糊匹配，符号“#”匹配多个单词（可以是零个），符号“&#42;”匹配一个单词。因此“usa.#”能够匹配到“usa.news.xxx、usa.weather.xxx”，但是“usa.&#42;” 只会匹配到“usa.news、usa.weather”。 1.3 消息发送接收流程 发送消息： 生产者和Broker建立TCP连接。 生产者和Broker建立通道。 生产者通过通道消息发送Broker，由Exchange将消息进行转发。 Exchage将消息转发到指定的Queue(队列) 接收消息： 消费者和Broker建立TCP连接 消费者和Broker建立通道 消费者监听指定的Queue 当有消息到达Queue时Broker默认将消息推送到消费者 消费者接收到消息 2. RabbitMq关键知识点2.1 消息的持久性 虽然消费者被杀死，消息也不会被丢失。但是如果此时RabbitMQ服务被停止，我们的消息仍然会丢失。 当RabbitMQ退出或者异常退出，将会丢失所有的队列和信息，除非你告诉它不要丢失。我们需要做两件事来确保信息不会被丢失：我们需要给所有的队列和消息设置持久化的标志。 第一， 我们需要确认RabbitMQ永远不会丢失我们的队列。为了这样，我们需要声明它为持久化的。 复制 12boolean durable = true;channel.queueDeclare(&quot;task_queue&quot;, durable, false, false, null); 注：RabbitMQ不允许使用不同的参数重新定义一个队列，所以已经存在的队列，我们无法修改其属性。 第二， 我们需要标识我们的信息为持久化的。通过设置MessageProperties（implements BasicProperties）值为PERSISTENT_TEXT_PLAIN 复制 1channel.basicPublish(&quot;&quot;, &quot;task_queue&quot;,MessageProperties.PERSISTENT_TEXT_PLAIN,message.getBytes()); 现在你可以执行一个发送消息的程序，然后关闭服务，再重新启动服务，运行消费者程序测试。 2.2 Confirm确认消息 Return返回消息 confirm消息确认机制 消息的确认：是指生产者投递消息后，如果Broker收到消息，则会给生产者一个应答 生产者进行接收应答，用来确定这条消息是否正常的发送到Broker，这种方式也是消息的可靠性投递的核心保障。 1234567891011121314//指定消息的投递模式：消息的确认模式channel.confirmSelect();//添加一个确认监听 channel.addConfirmListener(new ConfirmListener() &#123; @Override public void handleAck(long deliveryTag, boolean multiple) throws IOException &#123; System.out.println("----handleAck---"); &#125; @Override public void handleNack(long deliveryTag, boolean multiple) throws IOException &#123; System.out.println("----handleNack---"); &#125; &#125;); Return返回消息机制 某些情况下，如果我们在发送消息的时候，当前的exchange不存在或者指定的路由key路由不到，这时候如果我们需要监听这种不可达的消息，就需要使用Return Listener 在API中有个一重要配置项： Mandatory:如果为true，则监听器会接收到路由不可达的消息，然后进行后续处理，如果为false，则broker端自动删除该消息。 12345678910111213//添加return返回消息监听 channel.addReturnListener(new ReturnListener() &#123; @Override public void handleReturn(int replyCode, String replyText, String exchange, String routingKey, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; System.out.println(replyCode); System.out.println(replyText); System.out.println(exchange); System.out.println(routingKey); System.out.println(properties); System.out.println(Arrays.toString(body)); &#125; &#125;); 2.3 消费端限流场景 ​ 如果RabbitMQ服务上堆积了成千上万条未处理的消息，然后随便打开一个消费者客户端，巨量的消息瞬间被推送过来，但是单个客户端无法同时处理这么多消息，可能会导致服务器宕机，产生线上故障。 所以RabbitMQ提供了一种qos功能（服务质量保证），即在非自动确认消息的前提下，如果一定数目的消息（通过基于consume或者channel设置Qos的值）未被确认前，不进行消费新的消息。 二.BasicQos方法 void BasicQos(int prefetchSize,int prefetchCount,boolean global) prefetchSize：消费端一般设置为0 prefetchCount：消费者同时接收消息的个数 global:true/false 是否将上面的设置应用于channel级别（是channel级别还是consumer级别） prefetchCount和global这两项，rabbitmq没有实现，即在自动应答情况下这两个值是不生效的。 12345678910111213141516171819202122232425262728293031323334353637383940414243public class Consumer &#123; public static void main(String[] args) throws IOException, TimeoutException, InterruptedException &#123; //创建一个连接工厂 ConnectionFactory connectionFactory = new ConnectionFactory(); connectionFactory.setHost("192.168.10.132"); connectionFactory.setPort(5672); connectionFactory.setVirtualHost("/"); //创建连接 Connection connection = connectionFactory.newConnection(); //通过连接创建一个Channel Channel channel = connection.createChannel(); //创建一个队列 String queueName = "qos"; channel.queueDeclare(queueName,true,false,false,null); //限流策略,第一件事要设置autoAck为false，即下面basicConsume方法的第二个参数 channel.basicQos(0,1,false); //设置Channel channel.basicConsume(queueName,false,new MyConsumer(channel)); &#125;&#125;//自定义consumer：public class MyConsumer extends DefaultConsumer &#123; private Channel channel; public MyConsumer(Channel channel) &#123; super(channel); this.channel = channel; &#125; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; System.out.println(consumerTag); System.out.println(envelope); System.out.println(properties); System.out.println(new String(body)); channel.basicAck(envelope.getDeliveryTag(),false); &#125;&#125; 2.4 消费端ack与重回队列 主要的示例代码: 1234boolean ack = false ; //打开消息应答机制 channel.basicConsume(QUEUE_NAME, ack, consumer); //另外需要在每次处理完成一个消息后，手动发送一次应答。 channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false); 消费端ACK使用场景： 1.消费端进行消费的时候，如果由于业务异常我们可以进行日志记录，然后进行补偿。 2.由于服务器宕机等严重问题，那我们就需要手工进行ACK保障消费端消费成功。 生产者: 1234567891011121314151617181920212223242526public static void main(String[] args) throws IOException, TimeoutException &#123; //创建一个连接工厂 ConnectionFactory connectionFactory = new ConnectionFactory(); connectionFactory.setHost("192.168.10.132"); connectionFactory.setPort(5672); connectionFactory.setVirtualHost("/"); //创建连接 Connection connection = connectionFactory.newConnection(); //通过连接创建一个Channel Channel channel = connection.createChannel(); //通过Channel发送数据 // 在这里要设置Mandatory(第三个参数)为true,否则broker会自动删除消息 for(int i=0;i&lt;10;i++)&#123; Map&lt;String ,Object&gt; hearders = new HashMap&lt;&gt;(); hearders.put("ack","ok"+i); AMQP.BasicProperties properties = new AMQP.BasicProperties.Builder() .deliveryMode(2) .contentEncoding("UTF-8") .headers(hearders) .build(); channel.basicPublish("","ack",properties,"hello world".getBytes()); &#125; channel.close(); connection.close();&#125; 消费者: 1234567891011121314151617181920212223242526272829303132333435363738public static void main(String[] args) throws IOException, TimeoutException, InterruptedException &#123; //创建一个连接工厂 ConnectionFactory connectionFactory = new ConnectionFactory(); connectionFactory.setHost("192.168.10.132"); connectionFactory.setPort(5672); connectionFactory.setVirtualHost("/"); //创建连接 Connection connection = connectionFactory.newConnection(); //通过连接创建一个Channel Channel channel = connection.createChannel(); //创建一个队列 String queueName = "ack"; channel.queueDeclare(queueName,true,false,false,null); //设置Channel DefaultConsumer consumer = new DefaultConsumer(channel)&#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; System.out.println(new String(body)); Object ack = properties.getHeaders().get("ack"); System.out.println(ack.toString()); try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; if("ok0".equals(ack.toString()))&#123; //表示消息处理失败了，设置重回队列，Broker端就会将没有成功处理的消息重新发送，并且位于队列底端。 //参数3：requeue 是否重回队列（实际生产会设置false） channel.basicNack(envelope.getDeliveryTag(),false,true); &#125;else&#123; channel.basicAck(envelope.getDeliveryTag(),false); &#125; &#125; &#125;; //手工签收，必须关闭autoAck(false) channel.basicConsume(queueName,false,consumer); &#125; 2.5 TTL队列/消息 TTL time to live 生存时间。 支持消息的过期时间，在消息发送时可以指定。 支持队列过期时间，在消息入队列开始计算时间，只要超过了队列的超时时间配置，那么消息就会自动的清除。 RabbitMQ支持消息的过期时间，在消息发送时可以进行指定 1new AMQP.BasicProperties().builder().expiration("").build(); RabbitMQ支持队列的过期时间，从消息入队列开始计算，只要超过了队列的超时时间配置，那么消息会自动的清除。在声明队列的queueDeclare方法的arguments参数中设置。 2.6 死信队列 DLX：Dead Letter Exchange 死信队列 利用DLX，当消息在一个队列中变成死信（dead message）之后，它能被重新publish到另一个Exchange，这个Exchange就是DLX。 消息变成死信的情况： 消息被拒绝（basic.reject/basic.nack）,并且requeue=false 消息TTL过期。 队列达到最大长度。 ​ DLX也是一个正常的Wxchange，和一般的Exchange没有区别，实际上就是设置队列的某一属性。 当这个队列中有死信时，rabbitmq就会自动将这个消息重新发布到设置的Exchange上去，进而被路由到另一个队列。 可以监听这个队列中消息做相应的处理，这个特性可以弥补RabbitMQ3.0以前支持的immediate参数的功能。 我们正常声明交换机、队列、绑定，只不过我们需要在队列上加一个参数即可，arguments.put(“x-dead-letter-exchange”,exchangeName),这样当有消息变成死信时，消息直接可以路由到该死信队列。 死信队列的设置 设置Exchange和Queue，然后进行绑定 Exchange: dlx.exchange(自定义的名字) queue: dlx.queue（自定义的名字） routingkey: #（#表示任何routingkey出现死信都会被路由过来） 然后正常的声明交换机、队列、绑定，只是我们在队列上加上一个参数：arguments.put(“x-dead-letter-exchange”,”dlx.exchange”); 2.7 消息属性定义 1234567891011121314151617181920212223### 生产者//自定义属性Map&lt;String, Object&gt; headers = new HashMap&lt;&gt;();headers.put("w","123");headers.put("w2","456");//为消息定义属性AMQP.BasicProperties properties = new AMQP.BasicProperties.Builder() .deliveryMode(2) //为1时，则不持久化，为2持久化消息 .contentEncoding("UTF-8") .expiration("100000")//过期时间 .headers(headers)//自定义属性 .build();//再将properties作为参数，传到basicPublish方法中channel.basicPublish("","hello",properties,"hello world".getBytes());### 消费者获取属性while (true)&#123; QueueingConsumer.Delivery delivery = consumer.nextDelivery(); String msg = new String(delivery.getBody()); Map&lt;String, Object&gt; headers = delivery.getProperties().getHeaders(); headers.forEach((x,y)-&gt; System.out.println(x+":"+y)); System.out.println("消费端："+msg);&#125; 2.8 消息的公平分配 ​ 或许会发现，目前的消息转发机制（Round-robin）并非是我们想要的。例如，这样一种情况，对于两个消费者，有一系列的任务，奇数任务特别耗时，而偶数任务却很轻松，这样造成一个消费者一直繁忙，另一个消费者却很快执行完任务后等待。 造成这样的原因是因为RabbitMQ仅仅是当消息到达队列进行转发消息。并不在乎有多少任务消费者并未传递一个应答给RabbitMQ。仅仅盲目转发所有的奇数给一个消费者，偶数给另一个消费者。 ​ 为了解决这样的问题，我们可以使用basicQos方法，传递参数为prefetchCount = 1。这样告诉RabbitMQ不要在同一时间给一个消费者超过一条消息。换句话说，只有在消费者空闲的时候会发送下一条信息。 12int prefetchCount = 1; channel.basicQos(prefetchCount); 3.rabbitmq运维3.1 常用命令 启动监控管理器：rabbitmq-plugins enable rabbitmq_management 关闭监控管理器：rabbitmq-plugins disable rabbitmq_management 启动rabbitmq：rabbitmq-service start 关闭rabbitmq：rabbitmq-service stop 查看所有的队列：rabbitmqctl list_queues 清除所有的队列：rabbitmqctl reset 关闭应用：rabbitmqctl stop_app 启动应用：rabbitmqctl start_app 3.2 角色权限设置 用户和权限设置 添加用户：rabbitmqctl add_user username password 分配角色：rabbitmqctl set_user_tags username administrator 新增虚拟主机：rabbitmqctl add_vhost vhost_name 将新虚拟主机授权给新用户：rabbitmqctl set_permissions -p vhost_name username “.*” “.*” “.*”(后面三个”&#42;”代表用户拥有配置、写、读全部权限) 角色说明 超级管理员(administrator) 可登陆管理控制台，可查看所有的信息，并且可以对用户，策略(policy)进行操作。 监控者(monitoring) 可登陆管理控制台，同时可以查看rabbitmq节点的相关信息(进程数，内存使用情况，磁盘使用情况等) 策略制定者(policymaker) 可登陆管理控制台, 同时可以对policy进行管理。但无法查看节点的相关信息(上图红框标识的部分)。 普通管理者(management) 仅可登陆管理控制台，无法看到节点信息，也无法对策略进行管理。 其他 无法登陆管理控制台，通常就是普通的生产者和消费者。 rabbitmq教程 rabbitmq官网]]></content>
      <categories>
        <category>rabbitmq</category>
      </categories>
      <tags>
        <tag>rabbitmq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mule简明介绍]]></title>
    <url>%2F2025%2F01%2F03%2Fsenssic.github.io%2F202101%2Fmule%E7%AE%80%E6%98%8E%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[0.mule esb简要介绍​ Mule ESB是一个轻量级的ESB，内核基于SEDA模型和Spring框架构建。基于Spring，意味有着非常灵活的扩展性。同时Mule ESB不仅仅是一个ESB，它也是流行的微服务体系中的一部分。mule的基本功能在于服务接入，消息转换，消息路由，消息过滤。 0.0Mule的社区版和企业版其中社区版是免费使用的。而企业版则需要付费订阅使用，功能更强大。关于社区版和企业版的主要区别，可以参照下表。一般我们使用社区版即可满足我们的业务。 特性 社区版 企业版 开源的Mule ESB √ √ 可视化开发工具Anypoint Studio √ √ 图形化转换器 DataMapper/DataWeave √ 高可用性(集群) √ 缓存和事务支持 √ 基于Web的管理控制台 √ 批处理模块 √ 社区版连接器 √ √ 企业版连接器,包括Security等模块 √ Hotfix&amp;在线服务支持 √ 0.1mule esb安装和部署​ mule esb主要用于旧系统的集成与改造，ETL数据转换，快速创建后端接口应用等场景。其可视化编排工具为基于eclipse改造的Anypoint Studio能够快速拖拽形成可执行部署的后端接口应用，或基于数据驱动的图节点处理引擎。 ​ mule的Anypoint Studio以及runtime下载地址为: mule runtime：https://docs.mulesoft.com/mule-runtime/3.9/downloading-and-starting-mule-esb anypoint Studio:https://docs.mulesoft.com/studio/6/to-download-and-install-studio 0.1.1anypoint studio使用社区版runtime安装社区版运行时，可以使用下列步骤。 点击Help/Install New Software…菜单 在Work with下拉框中选择Mule Runtimes for Anypoint Studio 输入http://studio.mulesoft.org/r6/studio-runtimes 选择Runtime 3.9.0 CE ,其中EE为企业版 0.1.2 导出工程部署到mule runtime运行 在工程的目录上右键选择export到处选择mule相关导出。导出一个app.zip安装包。 将导出的zip包放到解压好的mule runtime的app目录下面 在Mule Runtime的bin目录下执行./mule或mule.bat启动命令 ​ 0.1.3 mule应用的xm描述介绍​ Mule的应用程序就是由一个或者多个Mule Configuration File组成，每个Mule Configuration File里面可以放置一个或者多个Flow。每一个FLow又是由Connector和Processor等组成。而Flow是Mule的核心概念，下图展示了Flow的结构。 ​ 0.1.4 Mule ESB构造元素 - FlowMule ESB的应用程序通常是设计用来接收和处理消息。接收消息我们通常使用Connector Source来做，而处理消息通常使用一个或者多个Processor来做。Flow就是用来组织Connector和Processor的组。在一个Flow中，你可以将多个单独的Mule元素链接起来，用来实现接收，处理，过滤，路由消息等功能。 Flow实际就是上图的边框。实际还有Sub Flow的概念，主要用于Flow的公用，这些不展开讲述。 0.1.5 Mule ESB构造元素 - ConnectorMule的Connector是其非常优秀的功能，数百个开箱即用Connector可以帮助开发者连接不同的应用。从常见的HTTP，TCP，FTP，LDAP等协议，Hadoop大数据，到大型的商用系统SAP，Oracle，Salesforce，Mule都提供了相应的Connector。 Connector又分成Source Connector（又称为Inbound Connector）和Target Connector（又称为Outbound Connector）。 Source Connector用来接收消息，可以理解成监听器，而Target Connector是用来发送消息的组件。 0.1.6. Mule ESB构造元素 - ProcessorMule的Processor包含的内容更广泛，从Studio右侧的工具箱可以看到很多的控件元素，除去上文讲述的Connector，余下的基本都可以归纳到Processor。 Processor大概可以分成几类。 Transformers 可以称作转换器，用来转换消息的类型，结构和内容，比如将XML换成JSON。 Components 组件，可以使用Java或者脚本语言组件，比如JavaScript等。这些组件使用程序语言来描述商业逻辑。 Flow Control 控制消息的流向，比如消息的路由，消息的分割聚合等。 Scopes 通过Scope，我们可以改变内部Processor的行为特征。 Filters 过滤消息，我们可以定义规则过滤非法的消息。 1.Mule message结构 Flow的结构和构成元素，在Flow中流动的就是Mule Message。 ​ Mule Message是一个数据结构，也有相对应的Java Class。它包括几部分Payload，Property，Attachment。如下图所示 ​ Property Mule Message的Property又分成Inbound Properties和Outbound Properties。这一点类似于HTTP协议的请求头和响应头。 Inbound properties 入站参数: ​ Outbound properties 出站参数: ​ Payload Mule的Payload是一个对象，类型是不固定的。可能是Stream，也可能是Hashmap，也可能是XML字符串。这一点类似于HTTP协议的请求正文，或者说是请求体。 Attachment Mule的Attachment就是消息的附件，这一点类似于HTTP协议中的multipartform-data请求。 如果你想看到整个MuleMessage的结构，使用Mule的Logger组件可以很方便的看到Message完整的组成。使用Logger打印出message，logger组件会重载message的toString方法，打印出Pretty格式的message。 123456789101112131415&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;mule xmlns:http="http://www.mulesoft.org/schema/mule/http" xmlns="http://www.mulesoft.org/schema/mule/core" xmlns:doc="http://www.mulesoft.org/schema/mule/documentation" xmlns:spring="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-current.xsdhttp://www.mulesoft.org/schema/mule/core http://www.mulesoft.org/schema/mule/core/current/mule.xsdhttp://www.mulesoft.org/schema/mule/http http://www.mulesoft.org/schema/mule/http/current/mule-http.xsd"&gt; &lt;http:listener-config name="HTTP_Listener_Configuration" host="0.0.0.0" port="8081" doc:name="HTTP Listener Configuration"/&gt; &lt;flow name="loggertestFlow"&gt; &lt;http:listener config-ref="HTTP_Listener_Configuration" path="/" doc:name="HTTP"/&gt; &lt;set-payload value="#[&amp;quot;Mule Message&amp;quot;]" doc:name="Set Payload"/&gt; &lt;logger message="#[message]" level="INFO" doc:name="Logger"/&gt; &lt;/flow&gt;&lt;/mule&gt; 我们可以从下图的记录中找到和上图Message Structure相对应的节点。出于篇幅原因，做了简略处理。 12345678910111213141516171819202122232425262728293031323334org.mule.DefaultMuleMessage&#123; id=f88d0090-074c-11e9-89b7-0c5415358ba9 payload=java.lang.String correlationId=&lt;not set&gt; correlationGroup=-1 correlationSeq=-1 encoding=UTF-8 exceptionPayload=&lt;not set&gt;Message properties: INVOCATION scoped properties: INBOUND scoped properties: accept=*/* accept-encoding=gzip, deflate, br accept-language=zh-CN,zh;q=0.9,en;q=0.8 cache-control=no-cache connection=keep-alive content-length=2 content-type=text/plain;charset=UTF-8 host=localhost:8081 http.listener.path=/ http.method=POST http.query.params=ParameterMap&#123;[]&#125; http.query.string= http.relative.path=/ http.remote.address=/127.0.0.1:57630 http.request.path=/ http.request.uri=/ http.scheme=http http.uri.params=ParameterMap&#123;[]&#125; http.version=HTTP/1.1 SESSION scoped properties:&#125; 1.1. Mule Message的PayloadPayload翻译成中文是负荷，负载的意思。它是Mule Message的主要部分，也是Mule处理的主要对象。我们后续说的数据转换就是对Payload的转换。注意Mule Message的Payload是有可能为空的，比如接收到一个Http Get请求，Http Get请求的请求体是空的，所以这个时候Mule Message的Payload是空的。 在Flow中，最常用的动作就是给payload赋值，给Payload赋值会使用set-payload组件。如果我们在Flow中想获取payload，可以使用MEL表达式。 下面的源代码表示payload的赋值和取值。 12345&lt;flow name="payloadFlow"&gt; &lt;http:listener config-ref="HTTP_Listener_Configuration" path="/" doc:name="HTTP"/&gt; &lt;set-payload value="#[&amp;quot;Mule Message&amp;quot;]" doc:name="Set Payload"/&gt; &lt;logger message="#[payload]" level="INFO" doc:name="Logger"/&gt;&lt;/flow&gt; 1.2. Mule Message的PropertyMule Message的Property是一个键值对，有name和对应的value。Mule Message有两种类型的Property，Inbound Properties和Outbound Properties。Inbound Properties或者Outbound Properties可以有多个Property，也就是多个键值对。 Inbound Properties是不可变的，是由Message Source产生的。就类似于Http的请求参数，是由用户的数据请求，经过Java的Servlet，或者Asp.Net等框架封装成Http Request对象。 Outbound Properties是可变的，我们在Mule的Flow中新增或者改变这些属性。注意，比如转换器，有些Mule Processor会自动增加有些属性。 在Mule中设定Property使用set-property组件，如果需要获取，同样使用MEL表达式。详细的MEL表达式，我们下篇会展开讲解。 1234&lt;flow name="propertyFlow"&gt; &lt;http:listener config-ref="HTTP_Listener_Configuration" path="/" doc:name="HTTP"/&gt; &lt;set-property propertyName="#[&amp;quot;userName&amp;quot;]" value="#[&amp;quot;Tom&amp;quot;]" doc:name="Property"/&gt;&lt;/flow&gt; 1.3. Mule Message的AttachmentAttachment，正如字面上意思，可以理解成消息的附件。想象一封邮件，有邮件发送人等头信息，也有邮件正文，同样还有邮件附件。和Property一样，Attachment也有两种类型，Inbound Attachment和Outbound Attachment。我们通常将一些大的对象作为附件传输。 使用set-attachment设置附件，这里将payload作为pdf文档附件供消费者下载。 1234&lt;flow name="variableFlow"&gt; &lt;http:listener config-ref="HTTP_Listener_Configuration" path="/" doc:name="HTTP"/&gt; &lt;set-attachment attachmentName="#[&amp;quot;doc&amp;quot;]" value="#[payload]" contentType="application/pdf" doc:name="Attachment"/&gt;&lt;/flow&gt; 1.4. Mule的VariableVariable也就是变量，有几种类型的变量，或者说几种不同范围的变量，如下：Flow Variable，Session Variable，Record Variable。Flow Variable在一个Flow是有效的，Session Variable是可以跨Flow的，Record Variable则是处理数据列表时会用到。 这里不详细讲述。从使用上说，有些类似于Java里面的局部变量，Session变量，但不完全一致。后续实战文章会分析这一点。 在Mule里，使用set-variable和MEL表达式对变量做赋值和取值操作。 1234&lt;flow name="attachmentFlow"&gt; &lt;http:listener config-ref="HTTP_Listener_Configuration" path="/" doc:name="HTTP"/&gt; &lt;set-variable variableName="orderNo" value="#[&amp;quot;1238&amp;quot;]" doc:name="Variable"/&gt;&lt;/flow&gt; 1.5. 使用Java操作Mule Message对程序员来说，千言万语不如代码，如何使用Java操作Mule Message呢？通过Java代码我们可以清楚的看到Mule Message的结构，成员变量和方法等。 12345678910111213//mulemessage接口提供了很多方法，具體參考apipublic void explorMessage(MuleMessage message) &#123; // 获取InboundProperty String requestPath = message.getInboundProperty("http.request.path"); // 设定OutboundProperty message.setOutboundProperty("content-type", "application/json"); // 获取Payload Object payload = message.getPayload(); // 获取InboundAttachment DataHandler fileAttachment = message.getInboundAttachment("fileName"); // 获取flow变量 message.getProperty("flowVarTest", PropertyScope.INVOCATION);&#125; 2. MEL表达式​ MEL是一种表达式，和脚本语言类似，但并不相同。表达式通常用于动态获取值或者设定值，或对数据进行简单的操作。表达式语言和脚本语言之间在功能上存在重叠，但如果您编写的内容非常复杂，需要的不仅仅是几行代码，或者您需要包含条件逻辑，那么脚本语言通常会更有用。如果简单的获取或设定值，调用方法或执行函数，则使用表达式则更方便。 2.1 MEL的使用场景MEL表达式常用的使用场景大概可以分成三种。 获取值 1#[payload] 表示获取message的负载 1#[message.inboundProperties.&apos;http.query.params&apos;.customerNo] 表示获取查询参数customerNo 1#[payload.callMethod(parameters) 表示调用payload对象的callMethod方法，并获取方法返回值 1#[xpath(&apos;//root/element&apos;)] 表示使用xpath语法解析并获取相应节点内容。 条件比较，返回的结果就是布尔变量 #[payload.amount &gt; 2000] 1#[message.inboundProperties.&apos;http.method&apos; == &apos;GET&apos;] 表示判断HTTP请求是不是GET方法 设定值，通常用于Message Enricher组件。 1#[flowVars.dbResult] 这里表示相应的值设定到dbResult变量中。 2.2 MEL的示例 使用表达式提取值，根据消息的内容，属性决定执行流程。在下面的示例中，payload是一个Java对象，我们根据购买类型，将订单分发路由到不同的JMS消息队列中。 12345678&lt;choice&gt; &lt;when expression="#[payload.getOrderType() == 'book']"&gt; &lt;jms:outbound-endpoint queue="bookQueue" /&gt; &lt;/when&gt; &lt;when expression="#[payload.getOrderType() == 'music']"&gt; &lt;jms:outbound-endpoint queue="musicQueue" /&gt; &lt;/when&gt;&lt;/choice&gt; 使用表达式提取值，并将值传递给Connector，如下示例就是使用MEL计算的值设定SMTP Connector的邮件标题，邮件接收人等。 1&lt;smtp:outbound-endpoint from="#[flowVars.mailFrom]" to="#[flowVars.mailTo]" subject="#[payload.mailSubject]" doc:name="SMTP"/&gt; 如果payload是Java对象，可以调用payload方法，获取方法的返回值。示例就说调用calAmount方法，并打印计算出来的金额。 1&lt;logger message="#[payload.calAmount()]" /&gt; 2.3 MEL的上下文对象(四大内置对象)我们在上述的MEL表达式示例中可以看到MEL有多个部分组成，第一部分就是上下文对象。MEL常见的上下文对象如下: 内置对象 说明 #[server] 当前服务器，可以获取服务器的时间，JDK版本等，如#[server.dateTime]，#[server.javaVersion] #[mule] 当前Mule实例，可以获取Mule的版本，目录等。如#[mule.version] #[app] 当前Mule应用的实例，可以获取应用的名称等。如#[app.name] #[message] 这个是我们最经常使用的对象，就说Mule message。如#[message.payload]，#[message.inboundProperties.’http.query.params’.customerNo]等 server上下文对象的常用属性: Field Field描述 dateTime 系统当前时间 host 主机名 ip 主机IP osName 操作系统名称 userName 当前用户 userDir 当前用户工作目录 mule上下文对象的常用属性: Field Field描述 home Mule Runtime的安装目录 version Mule Runtime的版本 nodeId 集群下的本机ID clusterId 集群ID app上下文对象的常用属性: Field Field描述 name Mule App应用名称 workdir Mule App工作目录 message上下文对象的常用属性: Field Field描述 id message的唯一ID rootId message的根ID payload message的负载 inboundProperties message的inbound头信息 inboundAttachments message的inbound附件信息 outboundProperties message的outbound头信息 outboundAttachments message的outbound附件信息 2.4 MEL的Variable不同于上點提到的上下文对象，MEL中还可以使用变量，使用变量并不要求在表达式中使用上下文对象。变量是顶层的标识符。MEL中常见的变量如下： flowVars - flowVars的有效范围是在一个Flow中，定义flowVars之后，后续的Message Processor都可以使用。 sessionVars - 在跨Flow通信时，可以使用sessionVars来传递变量。需要注意的是，sessionVars并不总是有效的，其实取决于Inboud Endpoint的类型。后续再出专题介绍flowVars和sessionVars等之间的区别。 1#[flowVars.foo = sessionVars.bar] 上述的表达式的意思是，将session变量赋值给flow变量。 变量类型 生命周期 调用方式 flowVars 同一个Flow #[flowVars.定义变量] sessionVars 同一个程序下的所有Flow #[sessionVars.定义变量] 2.5 MEL访问属性 点语法。适用对象通常是Java Pojo。MEL中可以使用点语法来访问相关的对象属性，同样对象属性的属性也是可以用点号来访问的。 1#[message.payload.item.name] Null安全性访问。Java编程中经常遇到NullPointerException错误，也就是说对空对象进行访问操作会报错。而在MEL表达式，可以通过点语法.?来避免出错。如下示例，即使item为null，该表达式仍然不会报错，它会返回null值。 1#[message.payload.?item.name] 属性名称的转义。如果属性名称有特殊字符，那么使用点语法会遇到问题，这个时候可以单引号进行转义。如下示例，http.query.params是一个整体。我们访问这个属性名，必须使用单引号进行转义。 1#[message.inboundProperties.&apos;http.query.params&apos;.customerNo] 中括号语法。如果对象是数组，或者Map，那么可以使用中括号进行访问 1#[payload[5]] 1#[payload[&apos;userName&apos;]] 2.6 MEL操作符常用的操作符如下，和普通的开发语言类似。还有更多的操作符可以查阅官方手册。 算术运算符 + - / * % #[2 + 4] #[&#39;fu&#39; + &#39;bar&#39;] 比较运算符 == != &gt; &lt; &gt;= &lt;= #[&#39;A&#39; == &#39;A&#39;] #[7 &gt; 5] 逻辑运算符 &amp;&amp; || #[(a == b) &amp;&amp; (c != d)] 三元操作符 #[lastname = (name == &#39;Smith&#39;) ? &#39;Smith&#39; : &#39;Unknown&#39;] 3.mule的扩展3.1 connector-devkit编写​ devkit是方便用户编写自己的connect，当然也可以将编写的控件作为mule的process执行，官网文档为:https://docs.mulesoft.com/connector-devkit/3.9/ 编写connector-devkit首先要基础devkit的父级pom 12345&lt;parent&gt; &lt;groupId&gt;org.mule.tools.devkit&lt;/groupId&gt; &lt;artifactId&gt;mule-devkit-parent&lt;/artifactId&gt; &lt;version&gt;3.7.0&lt;/version&gt;&lt;/parent&gt; 然后使用connector-devkit提供的配置注解进行业务的描述，mule的devkit插件会根据注解的描述生成anypoint的控件配置界面和运行时代码。 定义connect的注解@Connector 1234567891011121314151617181920212223242526272829303132//@Connector注解标记此类为控件,@OnException注解标记此控件process或source抛出异常处理的handler类@Connector(name = "testName", friendlyName = "控件显示名称", minMuleVersion = "3.9.0")@OnException(handler = ErrorHandler.class)public class TestConnector &#123; //外部提供的静态配置，会生成配置弹出界面 @Config private GlobalConfig config; //节点开始会执行 @Start public void init() &#123; &#125; //中间节点的处理器处理代码，可以有多个@Processor根据名称不同供界面选择 @Processor(name = "testProcessor", friendlyName = "process控件显示名称") public Object processExc(String userName, final MuleEvent muleEvent) throws Exception &#123; System.out.println("--&gt;我要开始抛出异常了"); if (true) &#123; throw new Exception("asdfasdf"); &#125; return muleEvent.getMessage().getPayload(); &#125; //首节点的处理器处理代码，可以有多个@Source根据名称不同供界面选择 @Source(friendlyName = "process控件显示名称") public void readFromTopic(String userName, String address, Integer age, final SourceCallback sourceCallback)throws Exception &#123; sourceCallback.process("数据传递!"); &#125; //节点停止会执行 @Stop public void destroy() &#123; &#125;&#125; 定义OnException的处理节点 12345678910@Handlerpublic class ErrorHandler &#123; @Handle public void handle(Exception ex) throws Exception &#123; System.out.println("异常了--&gt;" ); ex.printStackTrace(); &#125;&#125; 定义Config的静态配置类 12345678910111213141516171819202122232425262728@Configuration(friendlyName = "自定义控件全局变量")public class GlobalConfig &#123; @Configurable @FriendlyName("变量名称一") @Placement(tab = "标签一") private String va1; @Configurable @FriendlyName("变量名称二") @Default("枚举一") @Placement(tab = "标签一tab", group = "标签一group", order = 1) //枚举 private EnumTest protocol; @Configurable @FriendlyName("变量名称三") @Optional @Placement(tab = "标签一tab", group = "标签一group", order = 2) private String va2; @Configurable @FriendlyName("变量名称三") @Optional @Placement(tab = "标签二tab", group = "标签二group", order = 3) private String va3; //getter setter mvn进行install打包成eclipse的课安装UpdateSite.zip包 使用anypoint的help-&gt;install new software,重启后即可拖拽使用 ​ 根据上述三个的注解描述类生成相对应的处理控件 ​ 3.2 mule runtimeplugin编写​ 我们可以编写插件对mule的运行时做一些额外的业务处理，比如社区版的自定义集群，当应用部署或启动停止的一些业务监听等。 引用依赖,由于我们的插件依赖mule的runtime都有，所以此处为provided 123456789101112131415161718&lt;dependency&gt; &lt;groupId&gt;org.mule&lt;/groupId&gt; &lt;artifactId&gt;mule-core&lt;/artifactId&gt; &lt;version&gt;3.9.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.mule.modules&lt;/groupId&gt; &lt;artifactId&gt;mule-module-reboot&lt;/artifactId&gt; &lt;version&gt;3.9.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.mule.modules&lt;/groupId&gt; &lt;artifactId&gt;mule-module-launcher&lt;/artifactId&gt; &lt;version&gt;3.9.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 实现MuleCoreExtension,DeploymentServiceAware,DeploymentListener接口做自己的业务定制化即可 MuleCoreExtension全路径为org.mule.MuleCoreExtension 其主要是提供了mule节点的Lifecycle接口，可以方便的在节点启动，停止，初始化，销毁等生命周期做业务处理。 还继承了NamedObject，可以提供复写当前运行时的全局名称 DeploymentServiceAware全路径为org.mule.module.launcher.DeploymentServiceAware 其主要提供了setDeploymentService(DeploymentService var1)方法，方便将DeploymentService 注入到业务中使用，其中DeploymentService 是非常重要的获取或操作运行时内部的应用的入口。 DeploymentListener全路径为org.mule.module.launcher.DeploymentListener 其提供了关于业务应用运行生命周期的事件回调，方便我们对部署的应用进行全生命周期管理。 将打包好的插件jar包放到muleRuntme的/lib/opt供mule启动运行加载 3.3 常用的修改3.3.1 启用远程调试​ 修改运行时环境目录的conf/wrapper.conf文件将按如下打开注释，注意将修改为对一个的jvm入参序列号,起始值为上面配置最后一个下标位置开始 12345# Debug remotely, the application will wait for the external debugger to connect.wrapper.java.additional.15=-Xdebugwrapper.java.additional.16=-Xnoagentwrapper.java.additional.17=-Djava.compiler=NONEwrapper.java.additional.18=-Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=5005 3.3.2 配置spring context按如下图增加spring配置文件和配置属性文件。因为muleRuntime本身的实现就是基于spring容器实现的所以很方便与spring集成做自己的业务。 spring-context.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263&lt;?xml version="1.0" encoding="UTF-8" standalone="no"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:tx="http://www.springframework.org/schema/tx" xmlns:dubbo="http://code.alibabatech.com/schema/dubbo" xsi:schemaLocation="http://www.springframework.org/schema/beanshttp://www.springframework.org/schema/beans/spring-beans-3.0.xsd http://www.springframework.org/schema/contexthttp://www.springframework.org/schema/context/spring-context-3.0.xsd http://www.springframework.org/schema/txhttp://www.springframework.org/schema/tx/spring-tx.xsd http://code.alibabatech.com/schema/dubbohttp://code.alibabatech.com/schema/dubbo/dubbo.xsd"&gt;&lt;!-- 扫描Bean --&gt; &lt;context:component-scan base-package="mule.mytest.*" &gt; &lt;/context:component-scan&gt; &lt;!-- 数据库相关 --&gt; &lt;bean id="xthis" class="com.zaxxer.hikari.HikariDataSource" destroy-method="close"&gt; &lt;property name="driverClassName" value="$&#123;datasource.driver&#125;"/&gt; &lt;property name="jdbcUrl" value="$&#123;datasource.url&#125;"/&gt; &lt;property name="username" value="$&#123;datasource.username&#125;"/&gt; &lt;property name="password" value="$&#123;datasource.password&#125;"/&gt; &lt;property name="maximumPoolSize" value="50"/&gt; &lt;property name="minimumIdle" value="2"/&gt; &lt;property name="dataSourceProperties"&gt; &lt;props&gt; &lt;prop key="cachePrepStmts"&gt;true&lt;/prop&gt; &lt;prop key="prepStmtCacheSize"&gt;250&lt;/prop&gt; &lt;prop key="prepStmtCacheSqlLimit"&gt;2048&lt;/prop&gt; &lt;prop key="useServerPrepStmts"&gt;true&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!-- 配置Mybatis --&gt;&lt;bean id="jdbcTemplateOra"class="org.springframework.jdbc.core.JdbcTemplate"&gt; &lt;property name="dataSource" ref="xthis"/&gt; &lt;/bean&gt; &lt;!-- 事务管理 --&gt; &lt;bean id="txManager"class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt; &lt;property name="dataSource" ref="xthis"/&gt; &lt;/bean&gt; &lt;tx:annotation-driven transaction-manager="txManager"/&gt;&lt;bean id="sqlSessionFactory"class="org.mybatis.spring.SqlSessionFactoryBean"&gt; &lt;property name="dataSource" ref="xthis" /&gt; &lt;property name="configLocation" value="classpath:mybatis-config.xml"/&gt; &lt;!-- 自动扫描mapping.xml文件--&gt; &lt;property name="mapperLocations" value="classpath:mapper/*.xml"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 扫描持久化层 --&gt; &lt;bean class="org.mybatis.spring.mapper.MapperScannerConfigurer"&gt; &lt;property name="basePackage" value="mule.mytest.dao" /&gt; &lt;property name="sqlSessionFactoryBeanName" value="sqlSessionFactory"&gt;&lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; application.properties 1234567#数据库配置datasource.url=jdbc:mysql://127.0.0.1:3306/testdb?useUnicode=true&amp;characterEncoding=utf8&amp;useSSL=false&amp;autoReconnect=true&amp;serverTimezone=GMT%2B8datasource.username=rootdatasource.password=123456datasource.driver=com.mysql.jdbc.Driver mybatis-config.xml 123456789101112&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE configuration PUBLIC "-//mybatis.org//DTD Config 3.0//EN" "http://mybatis.org/dtd/mybatis-3-config.dtd"&gt;&lt;configuration&gt; &lt;settings&gt; &lt;setting name="mapUnderscoreToCamelCase" value="true"/&gt; &lt;!-- 驼峰命名 --&gt; &lt;setting name="lazyLoadingEnabled" value="true"/&gt; &lt;!-- 是否开启懒加载 --&gt; &lt;setting name="logImpl" value="STDOUT_LOGGING"/&gt; &lt;!-- 打印查询日志 --&gt; &lt;setting name="callSettersOnNulls" value="true"/&gt; &lt;!-- 为null的字段忽略 --&gt; &lt;/settings&gt;&lt;/configuration&gt; mule官方文档 EnjoyingSoft之Mule ESB开发教程]]></content>
      <categories>
        <category>mule</category>
      </categories>
      <tags>
        <tag>mule</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux压测工具]]></title>
    <url>%2F2025%2F01%2F03%2Fsenssic.github.io%2F202012%2Flinux%E5%8E%8B%E6%B5%8B%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[0. talk (Linux Performance Tools)系统性能专家 Brendan D. Gregg根据长期的摸索和经验发现最好用的还是那些久经考验的、简单的小工具。 并在 LinuxCon NA 2014 大会以幻灯片的形式展示。 0.1 监控 0.2 测试 0.3 优化 1.Netdata Netdata是一个高度优化的Linux守护进程，它为Linux系统，应用程序，SNMP服务等提供实时的性能监测。 GITHUB地址：https://github.com/firehol/netdata 2.prometheus新一代的云原生监控系统 官网地址:https://prometheus.io/download/ 3.NagiosNagios 是一款自动化运维工具，可以协助运维人员监控服务器的运行状况，并且拥有报警功能. 官网地址: https://www.nagios.com/ 4.zabbixZabbix是一个企业级解决方案，支持实时监控数千台服务器，虚拟机和网络设备，采集百万级监控指标。 官网地址:https://www.zabbix.com/cn/download 5.GlancesGlances是一个跨平台的监控工具，旨在通过诅咒或基于Web的界面呈现大量的监控信息。信息根据用户界面的大小动态调整。 github地址:https://github.com/nicolargo/glances 参考 Netdata prometheus Nagios Zabbix Glances]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[influx-db简明介绍]]></title>
    <url>%2F2025%2F01%2F03%2Fsenssic.github.io%2F202012%2Finflux-db%E7%AE%80%E6%98%8E%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[0.时序数据库介绍时序数据库特点metric: 度量，相当于关系型数据库中的table。 data point: 数据点，相当于关系型数据库中的row。 timestamp：时间戳，代表数据点产生的时间。 field: 度量下的不同字段。比如位置这个度量具有经度和纬度两个field。一般情况下存放的是会随着时间戳的变化而变化的数据。 tag: 标签，或者附加信息。一般存放的是并不随着时间戳变化的属性信息。timestamp加上所有的tags可以认为是table的primary key。 influx-db基本概念基本概念 mysql influxdb 说明 database database 数据库 table measurement 类似mysql中表的概念 record tag + field + timestamp 传统表中的一行数据，映射到influxdb中，可以划分为三个 1. database数据库，和mysql的数据库相比，没有太大的歧义 2. measurement对比的是mysql中的table，从实际体验来看，两个之间最明显的区别在于没有单独的创建measurement的方法，直接新增一条数据时，若measurement不存在，则直接创建并插入一条数据 3. Point这个对比的是mysql中的record，在influxDB中，表示每个表中，某个时刻，满足某个条件的filed数据（简单来说就是 timestamp + tag + filed)的组成一个point timestamp : 时间戳，ns单位，每个记录都必然有这个属性，没有显示添加时，默认给一个 tag: 标签，kv结构，在database中， tag + measurement 一起构建索引 参与索引创建，因此适合作为查询的过滤条件 tag的数据量不要太多，最好能有典型的辨别性（和mysql的建立索引的原则差不多） value为String类型 tag是可选的，在measurement不设置tag也是ok的 field：存储数据，kv结构 数据类型为: long, String, boolean, float 4. SeriesSeries: tag key 与tag value的唯一组合 1.influx-db安装部署1234567891011wget https://dl.influxdata.com/influxdb/releases/influxdb-1.7.10.x86_64.rpmyum localinstal influxdb-1.8.1.x86_64.rpmservice influxdb start#配置文件地址/etc/influxdb/influxdb.conf#生成默认配置文件influxd config &gt; default.conf#进入控制台Influx#指定配置文件启动influxd -config /etc/influxdb/influxdb.conf 2.influx-db常用命令以及配置基本操作命令基础命令1234567891011121314151617181920212223242526272829303132# 创建数据库CREATE DATABASE "db_name"# 显示所有数据库SHOW DATABASES# 删除数据库DROP DATABASE "db_name"# 使用数据库USE mydb# 显示该数据库中的表SHOW MEASUREMENTS# 创建表# 直接在插入数据的时候指定表名（weather就是表名）insert weather,altitude=1000,area=北 temperature=11,humidity=-4# 删除表DROP MEASUREMENT "measurementName"# 查看数据SELECT * FROM weathershow series from weather# 显示用户SHOW USERS# 创建用户CREATE USER "username" WITH PASSWORD 'password'# 创建管理员权限的用户CREATE USER "username" WITH PASSWORD 'password' WITH ALL PRIVILEGES# 删除用户DROP USER "username" 进阶命令12345678910111213141516171819202122232425262728293031323334SHOW MEASUREMENTS --查询当前数据库中含有的表SHOW FIELD KEYS --查看当前数据库所有表的字段SHOW series from pay --查看key数据SHOW TAG KEYS FROM "pay" --查看key中tag key值SHOW TAG VALUES FROM "pay" WITH KEY = "merId" --查看key中tag 指定key值对应的值SHOW TAG VALUES FROM cpu WITH KEY IN ("region", "host") WHERE service = 'redis'DROP SERIES FROM &lt;measurement_name[,measurement_name]&gt; WHERE &lt;tag_key&gt;='&lt;tag_value&gt;' --删除keySHOW CONTINUOUS QUERIES --查看连续执行命令SHOW QUERIES --查看最后执行命令KILL QUERY &lt;qid&gt; --结束命令SHOW RETENTION POLICIES ON mydb --查看保留数据ALTER RETENTION POLICY default ON online DEFAULT --修改保留期DROP RETENTION POLICY &lt;retentionpolicy&gt; ON &lt;database&gt; --删除保留期CREATE RETENTION POLICY "rp_name" ON "db_name" DURATION 30d REPLICATION 1 DEFAULT --创建保留期-- rp_name：策略名-- db_name：具体的数据库名-- 30d：保存30天，30天之前的数据将被删除-- 它具有各种时间参数，比如：h（小时），w（星期）m minutes h hours d days w weeks INF infinite-- REPLICATION 1：副本个数，这里填1就可以了-- DEFAULT 设为默认的策略SHOW USERSCREATE USER jdoe WITH PASSWORD '1337password' -- Create a normal database user.CREATE USER jdoe WITH PASSWORD '1337password' WITH ALL PRIVILEGES -- Create an admin user.REVOKE ALL PRIVILEGES FROM jdoe revoke admin privileges from jdoeREVOKE READ ON mydb FROM jdoe -- revoke read privileges from jdoe on mydbSHOW GRANTS FOR jdoe -- show grants for jdoeGRANT ALL TO jdoe -- grant admin privilegesGRANT READ ON mydb TO jdoe -- grant read access to a databaseDROP USER jdoeSHOW SHARDS --查看数据存储文件DROP SHARD 1SHOW SHARD GROUPSSHOW SUBSCRIPTIONS 常用函数聚合函数：FILL(), INTEGRAL()，SPREAD()， STDDEV()，MEAN(), MEDIAN(), DISTINCT(), COUNT(), SUM()等。 选择函数: SAMPLE(), PERCENTILE(), FIRST(), LAST(), TOP(), BOTTOM(),MAX(),MIN()等。 转换函数: DERIVATIVE(),DIFFERENCE(),ELAPSED(),MOVING_AVERAGE(),NON_NEGATIVE_DERIVATIVE(),STDDEV()等. 预测函数：HOLT_WINTERS()。 连续查询连续查询(CONTINUOUS QUERY，简写为CQ)是指定时自动在实时数据上进行的InfluxQL查询，查询结果可以存储到指定的measurement中。 基本连续查询1234567891011121314CREATE CONTINUOUS QUERY &lt;cq_name&gt; ON &lt;database_name&gt;BEGIN &lt;cq_query&gt;ENDcq_query格式：SELECT &lt;function[s]&gt; INTO &lt;destination_measurement&gt; FROM &lt;measurement&gt; [WHERE &lt;stuff&gt;] GROUP BY time(&lt;interval&gt;)[,&lt;tag_key[s]&gt;]##例子startCREATE CONTINUOUS QUERY "cq_basic" ON "transportation"BEGIN SELECT mean("passengers") INTO "average_passengers" FROM "bus_data" GROUP BY time(1h)END##例子end 高级连续查询12345CREATE CONTINUOUS QUERY &lt;cq_name&gt; ON &lt;database_name&gt;RESAMPLE EVERY &lt;interval&gt; FOR &lt;interval&gt;BEGIN &lt;cq_query&gt;END 与基本语法不同的是，多了RESAMPLE关键字。高级语法里CQ的执行时间和查询时间范围则与RESAMPLE里面的两个interval有关系。 高级语法中CQ以EVERY interval的时间间隔执行，执行时查询的时间范围则是FOR interval来确定。如果FOR interval为2h，当前时间为17:00，则查询的时间范围为15:00-16:59.999999。RESAMPLE的EVERY和FOR两个关键字可以只有一个。 配置文件12# 生成默认配置文件influxd config &gt; default.conf 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126#全局配置reporting-disabled = false # 该选项用于上报influxdb的使用信息给InfluxData公司，默认值为falsebind-address = &quot;:8088&quot; # 备份恢复时使用，默认值为8088#1、meta相关配置[meta]dir = &quot;/var/lib/influxdb/meta&quot; # meta数据存放目录retention-autocreate = true # 用于控制默认存储策略，数据库创建时，会自动生成autogen的存储策略，默认值：truelogging-enabled = true # 是否开启meta日志，默认值：true#2、data相关配置[data]dir = &quot;/var/lib/influxdb/data&quot; # 最终数据（TSM文件）存储目录wal-dir = &quot;/var/lib/influxdb/wal&quot; # 预写日志存储目录query-log-enabled = true # 是否开启tsm引擎查询日志，默认值： truecache-max-memory-size = 1048576000 # 用于限定shard最大值，大于该值时会拒绝写入，默认值：1000MB，单位：bytecache-snapshot-memory-size = 26214400 # 用于设置快照大小，大于该值时数据会刷新到tsm文件，默认值：25MB，单位：bytecache-snapshot-write-cold-duration = &quot;10m&quot; # tsm引擎 snapshot写盘延迟，默认值：10Minutecompact-full-write-cold-duration = &quot;4h&quot; # tsm文件在压缩前可以存储的最大时间，默认值：4Hourmax-series-per-database = 1000000 # 限制数据库的级数，该值为0时取消限制，默认值：1000000max-values-per-tag = 100000 # 一个tag最大的value数，0取消限制，默认值：100000#3、coordinator查询管理的配置选项[coordinator]write-timeout = &quot;10s&quot; # 写操作超时时间，默认值： 10smax-concurrent-queries = 0 # 最大并发查询数，0无限制，默认值： 0query-timeout = &quot;0s # 查询操作超时时间，0无限制，默认值：0slog-queries-after = &quot;0s&quot; # 慢查询超时时间，0无限制，默认值：0smax-select-point = 0 # SELECT语句可以处理的最大点数（points），0无限制，默认值：0max-select-series = 0 # SELECT语句可以处理的最大级数（series），0无限制，默认值：0max-select-buckets = 0 # SELECT语句可以处理的最大&quot;GROUP BY time()&quot;的时间周期，0无限制，默认值：0#4、retention旧数据的保留策略[retention]enabled = true # 是否启用该模块，默认值 ： truecheck-interval = &quot;30m&quot; # 检查时间间隔，默认值 ：&quot;30m&quot;#5、shard-precreation分区预创建[shard-precreation]enabled = true # 是否启用该模块，默认值 ： truecheck-interval = &quot;10m&quot; # 检查时间间隔，默认值 ：&quot;10m&quot;advance-period = &quot;30m&quot; # 预创建分区的最大提前时间，默认值 ：&quot;30m&quot;#6、monitor 控制InfluxDB自有的监控系统。 默认情况下，InfluxDB把这些数据写入_internal 数据库，如果这个库不存在则自动创建。 _internal 库默认的retention策略是7天，如果你想使用一个自己的retention策略，需要自己创建。[monitor]store-enabled = true # 是否启用该模块，默认值 ：truestore-database = &quot;_internal&quot; # 默认数据库：&quot;_internal&quot;store-interval = &quot;10s # 统计间隔，默认值：&quot;10s&quot;#7、admin web管理页面[admin]enabled = true # 是否启用该模块，默认值 ： falsebind-address = &quot;:8083&quot; # 绑定地址，默认值 ：&quot;:8083&quot;https-enabled = false # 是否开启https ，默认值 ：falsehttps-certificate = &quot;/etc/ssl/influxdb.pem&quot; # https证书路径，默认值：&quot;/etc/ssl/influxdb.pem&quot;#8、http API[http]enabled = true # 是否启用该模块，默认值 ：truebind-address = &quot;:8086&quot; # 绑定地址，默认值：&quot;:8086&quot;auth-enabled = false # 是否开启认证，默认值：falserealm = &quot;InfluxDB&quot; # 配置JWT realm，默认值: &quot;InfluxDB&quot;log-enabled = true # 是否开启日志，默认值：truewrite-tracing = false # 是否开启写操作日志，如果置成true，每一次写操作都会打日志，默认值：falsepprof-enabled = true # 是否开启pprof，默认值：truehttps-enabled = false # 是否开启https，默认值：falsehttps-certificate = &quot;/etc/ssl/influxdb.pem&quot; # 设置https证书路径，默认值：&quot;/etc/ssl/influxdb.pem&quot;https-private-key = &quot;&quot; # 设置https私钥，无默认值shared-secret = &quot;&quot; # 用于JWT签名的共享密钥，无默认值max-row-limit = 0 # 配置查询返回最大行数，0无限制，默认值：0max-connection-limit = 0 # 配置最大连接数，0无限制，默认值：0unix-socket-enabled = false # 是否使用unix-socket，默认值：falsebind-socket = &quot;/var/run/influxdb.sock&quot; # unix-socket路径，默认值：&quot;/var/run/influxdb.sock&quot;#9、subscriber 控制Kapacitor接受数据的配置[subscriber]enabled = true # 是否启用该模块，默认值 ：truehttp-timeout = &quot;30s&quot; # http超时时间，默认值：&quot;30s&quot;insecure-skip-verify = false # 是否允许不安全的证书ca-certs = &quot;&quot; # 设置CA证书write-concurrency = 40 # 设置并发数目，默认值：40write-buffer-size = 1000 # 设置buffer大小，默认值：1000#10、graphite 相关配置[[graphite]]enabled = false # 是否启用该模块，默认值 ：falsedatabase = &quot;graphite&quot; # 数据库名称，默认值：&quot;graphite&quot;retention-policy = &quot;&quot; # 存储策略，无默认值bind-address = &quot;:2003&quot; # 绑定地址，默认值：&quot;:2003&quot;protocol = &quot;tcp&quot; # 协议，默认值：&quot;tcp&quot;consistency-level = &quot;one&quot; # 一致性级别，默认值：&quot;onebatch-size = 5000 # 批量size，默认值：5000batch-pending = 10 # 配置在内存中等待的batch数，默认值：10batch-timeout = &quot;1s&quot; # 超时时间，默认值：&quot;1s&quot;udp-read-buffer = 0 # udp读取buffer的大小，0表示使用操作系统提供的值，如果超过操作系统的默认配置则会出错。 该配置的默认值：0separator = &quot;.&quot; # 多个measurement间的连接符，默认值： &quot;.&quot;#11、collectd[[collectd]]enabled = false # 是否启用该模块，默认值 ：falsebind-address = &quot;:25826&quot; # 绑定地址，默认值： &quot;:25826&quot;database = &quot;collectd&quot; # 数据库名称，默认值：&quot;collectd&quot;retention-policy = &quot;&quot; # 存储策略，无默认值typesdb = &quot;/usr/local/share/collectd&quot; # 路径，默认值：&quot;/usr/share/collectd/types.db&quot;auth-file = &quot;/etc/collectd/auth_file&quot;batch-size = 5000batch-pending = 10batch-timeout = &quot;10s&quot;read-buffer = 0 # udp读取buffer的大小，0表示使用操作系统提供的值，如果超过操作系统的默认配置则会出错。默认值：0#12、opentsdb[[opentsdb]]enabled = false # 是否启用该模块，默认值：falsebind-address = &quot;:4242&quot; # 绑定地址，默认值：&quot;:4242&quot;database = &quot;opentsdb&quot; # 默认数据库：&quot;opentsdb&quot;retention-policy = &quot;&quot; # 存储策略，无默认值consistency-level = &quot;one&quot; # 一致性级别，默认值：&quot;one&quot;tls-enabled = false # 是否开启tls，默认值：falsecertificate= &quot;/etc/ssl/influxdb.pem&quot; # 证书路径，默认值：&quot;/etc/ssl/influxdb.pem&quot;log-point-errors = true # 出错时是否记录日志，默认值：truebatch-size = 1000batch-pending = 5batch-timeout = &quot;1s&quot;#13、udp[[udp]]enabled = false # 是否启用该模块，默认值：falsebind-address = &quot;:8089&quot; # 绑定地址，默认值：&quot;:8089&quot;database = &quot;udp&quot; # 数据库名称，默认值：&quot;udp&quot;retention-policy = &quot;&quot; # 存储策略，无默认值batch-size = 5000batch-pending = 10batch-timeout = &quot;1s&quot;read-buffer = 0 # udp读取buffer的大小，0表示使用操作系统提供的值，如果超过操作系统的默认配置则会出错。 该配置的默认值：0 #14、continuous_queries[continuous_queries]enabled = true # enabled 是否开启CQs，默认值：truelog-enabled = true # 是否开启日志，默认值：truerun-interval = &quot;1s&quot; # 时间间隔，默认值：&quot;1s&quot; 3.influx-db 客户端以及接口12345&lt;dependency&gt; &lt;groupId&gt;org.influxdb&lt;/groupId&gt; &lt;artifactId&gt;influxdb-java&lt;/artifactId&gt; &lt;version&gt;2.17&lt;/version&gt;&lt;/dependency&gt; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public class InfluxDbTest &#123; private InfluxDB influxDB = null; @Before public void befor() &#123; final String serverURL = "http://10.19.151.218:7076", username = "root", password = "123"; influxDB = InfluxDBFactory.connect(serverURL,username,password); &#125; @After public void after() &#123; influxDB.close(); &#125; @Test public void testDropTable() &#123; influxDB.query(new Query("drop database test_db")); &#125; @Test public void testCreateTable() &#123; for (int i = 0; i &lt; 1000; i++) &#123; influxDB.query(new Query("CREATE DATABASE teaestst_dfdb"+i)); &#125; &#125; @Test public void testCreateData() &#123; influxDB.enableBatch(BatchOptions.DEFAULTS); for (int i = 0; i &lt; 5; i++) &#123; final BatchPoints build = BatchPoints.database("test_db").points(Point.measurement("point_test1") .time(System.currentTimeMillis(), TimeUnit.MILLISECONDS) .tag("location", "test_location_tag") .addField("level description", "test_描述") .addField("water_level", RandomUtil.randomDouble(1000)) .build(), Point.measurement("point_test2") .time(System.currentTimeMillis(), TimeUnit.MILLISECONDS) .tag("location", "test_location_tag") .addField("level description", "test_描述") .addField("water_level", RandomUtil.randomDouble(1000)) .build(), Point.measurement("point_test3") .time(System.currentTimeMillis(), TimeUnit.MILLISECONDS) .tag("location", "test_location_tag") .addField("level description", "test_描述") .addField("water_level", RandomUtil.randomDouble(1000)) .build(), Point.measurement("point_test4") .time(System.currentTimeMillis(), TimeUnit.MILLISECONDS) .tag("location", "test_location_tag") .addField("level description", "test_描述") .addField("water_level", RandomUtil.randomDouble(1000)) .build(), Point.measurement("point_test5") .time(System.currentTimeMillis(), TimeUnit.MILLISECONDS) .tag("location", "test_location_tag") .addField("level description", "test_描述") .addField("water_level", RandomUtil.randomDouble(1000)) .build()).build(); // influxDB.write(build); &#125; &#125;&#125; 4.influx-db开源集群方案influx-proxy 4.1 架构示例 client：influxdb-java、influxdb-shell (influx)、curl、浏览器等客户端 load balance：负载均衡，如 F5、Nginx、LVS、HAProxy 等 influx-proxy：influx-proxy 实例，架构示意图部署了两个 influx-proxy 实例 circle：一致性哈希环(circle)，一个 circle 包含了若干个 influxdb 实例，共同存储了一份全量的数据，即每个 circle 都是全量数据的一个副本，各个 circle 数据互备。不同 circle 不能包含相同 influxdb 实例，每个 circle 包含的 influxdb 实例个数可以不相等。circle 只是一种逻辑划分，无实体存在，架构示意图配置了三个 circle influxdb：influxdb 实例，以 url 进行区分，可以部署在同一服务器上以不同端口运行多个实例，一个 influxdb 实例只存储了一份全量数据的一部分数据 4.2 原理4.2.1设计原理4.2.1.1一致性哈希原理原理文章：一致性Hash(Consistent Hashing)原理剖析 一致性哈希算法解决了分布式环境下机器扩缩容时，简单的取模运算导致数据需要大量迁移的问题 一致性哈希算法能达到较少的机器数据迁移成本，实现快速扩缩容 通过虚拟节点的使用，一致性哈希算法可以均匀分担机器的数据负载 4.2.1.2一致性哈希 circle 设计 一个 circle 是一个逻辑上的一致性哈希环，包含少数的物理节点和更多数的虚拟节点 一个 circle 中的所有 influxdb 实例对应了这个一致性哈希环的物理节点 4.2.1.3数据存储位置 每个 circle 维护了一份全量数据，一个 influxdb 实例上的数据只是从属 circle 数据的一部分 每个 circle 数据存储位置计算： 1db,measurement + influxdb实例列表 + 一致性哈希算法 =&gt; influxdb实例 当influxdb实例列表不发生改变时，db,measurement将只会唯一对应一台influxdb实例 当influxdb实例列表发生改变时，需要对少量机器数据进行迁移，即 重新平衡 (rebalance) 4.3请求流程4.3.1写请求 client 请求 load balance 地址 load balance 根据负载均衡算法选择一个 influx-proxy 转发请求 influx-proxy 收到请求，根据请求中 db 和 measurement 信息，每个 circle 使用一致性哈希算法计算出一个 influxdb 实例，并将请求转发给这些 influxdb 实例 influxdb 实例处理请求，写入数据 若存在 influxdb 实例宕掉，或者网络、存储故障导致无法 influxdb 无法写入，则 influx-proxy 会将数据写入到缓存文件中，并直到 influxdb 实例恢复后重新写入 4.3.2读请求 client 请求 load balance 地址 load balance 根据负载均衡算法选择一个 influx-proxy 转发请求 influx-proxy 收到请求，选择一个所有 influxdb 实例都正常运行、状态健康的 circle 若请求中带有 db 和 measurement 信息，该 circle 使用一致性哈希算法计算出一个 influxdb 实例，并将请求转发给这个 influxdb 实例；若请求中只带有 db 信息，则判断为数据库相关的集群查询语句，并将请求转发给该 circle 的所有 influxdb 实例 influxdb 实例处理请求，读出数据，返回给 influx-proxy 若是单个实例返回数据，则直接返回 client；若是多个实例返回数据，则合并后返回 client 5.influx-db运维相关5.0 influxdb界面访问 :8083 即可访问界面 5.1 保留策略（retention policy） 每个数据库刚开始会自动创建一个默认的存储策略 autogen，数据保留时间为永久，在集群中的副本个数为1，之后用户可以自己设置（查看、新建、修改、删除），例如保留最近2小时的数据。插入和查询数据时如果不指定存储策略，则使用默认存储策略，且默认存储策略可以修改。InfluxDB 会定期清除过期的数据。 每个数据库可以有多个过期策略： show retention policies on “db_name” Shard 在 influxdb中是一个比较重要的概念，它和 retention policy 相关联。每一个存储策略下会存在许多 shard，每一个 shard 存储一个指定时间段内的数据，并且不重复，例如 7点-8点 的数据落入 shard0 中，8点-9点的数据则落入 shard1 中。每一个 shard 都对应一个底层的 tsm 存储引擎，有独立的 cache、wal、tsm file。 这样做的目的就是为了可以通过时间来快速定位到要查询数据的相关资源，加速查询的过程，并且也让之后的批量删除数据的操作变得非常简单且高效。 建议在数据库建立的时候设置存储策略，不建议设置过多且随意切换 create database testdb2 with duration 30d 5.2 存储引擎（Timestamp-Structure Merge Tree）TSM是在LSM的基础上优化改善的，引入了serieskey的概念，对数据实现了很好的分类组织。 TSM主要由四个部分组成： cache、wal、tsm file、compactor： cache：插入数据时，先往 cache 中写入再写入wal中，可以认为 cache 是 wal 文件中的数据在内存中的缓存，cache 中的数据并不是无限增长的，有一个 maxSize 参数用于控制当 cache 中的数据占用多少内存后就会将数据写入 tsm 文件。如果不配置的话，默认上限为 25MB wal：预写日志，对比MySQL的 binlog，其内容与内存中的 cache 相同，作用就是为了持久化数据，当系统崩溃后可以通过 wal 文件恢复还没有写入到 tsm 文件中的数据，当 InfluxDB 启动时，会遍历所有的 wal 文件，重新构造 cache。 tsm file：每个 tsm 文件的大小上限是 2GB。当达到 cache-snapshot-memory-size,cache-max-memory-size 的限制时会触发将 cache 写入 tsm 文件。 compactor：主要进行两种操作，一种是 cache 数据达到阀值后，进行快照，生成一个新的 tsm 文件。另外一种就是合并当前的 tsm 文件，将多个小的 tsm 文件合并成一个，减少文件的数量，并且进行一些数据删除操作。 这些操作都在后台自动完成，一般每隔 1 秒会检查一次是否有需要压缩合并的数据。 5.3 存储目录influxdb的数据存储有三个目录，分别是meta、wal、data： meta 用于存储数据库的一些元数据，meta 目录下有一个 meta.db 文件； wal 目录存放预写日志文件，以 .wal 结尾； data 目录存放实际存储的数据文件，以 .tsm 结尾。 5.4 操作优化 控制 series 的数量； 使用批量写； 使用恰当的时间粒度； 存储的时候尽量对 Tag 进行排序； 根据数据情况，调整 shard 的 duration； 无关的数据写不同的database； 控制 Tag Key, 与 Tag Value 值的大小； 存储分离 ，将 wal 目录与 data 目录分别映射到不同的磁盘上，以减少读写操作的相互影响。 InfluxDB 入门 时序数据库InfluxDB使用详解 InfluxDB中文文档 influx-proxy Influxdb配置文件详解]]></content>
      <categories>
        <category>influx-db</category>
      </categories>
      <tags>
        <tag>influx-db</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos7安装ceph]]></title>
    <url>%2F2025%2F01%2F03%2Fsenssic.github.io%2F201906%2Fcenos7%E5%AE%89%E8%A3%85ceph%2F</url>
    <content type="text"><![CDATA[节点信息配置 虚拟机名称 虚拟机ip 虚拟机应用 ceph-master 192.168.56.101 ceph-master/deployment ceph-node-1 192.168.56.102 ceph-node ceph-node-2 192.168.56.102 ceph-node 环境准备1.关闭防火墙(所有节点) 1234sed -i 's/SELINUX=.*/SELINUX=disabled/' /etc/selinux/configsetenforce 0systemctl stop firewalldsystemctl disable firewalld 2.配置节点host解析设置hostname(所有节点) 123456789192.168.56.101 ceph-master192.168.56.102 ceph-node-1192.168.56.103 ceph-node-2#ceph-mastersudo hostnamectl set-hostname ceph-master#ceph-node-sudo hostnamectl set-hostname ceph-node-1#ceph-node-2sudo hostnamectl set-hostname ceph-node-2 3.安装依赖(所有节点) 1yum install tree nmap sysstat lrzsz dos2unix wegt git net-tools -y 4.设置免密登录 生成秘钥文件(ceph-master节点) ssh-keygen -t rsa 拷贝秘钥文件 123ssh-copy-id root@ceph-masterssh-copy-id root@ceph-node-1ssh-copy-id root@ceph-node-2 5.配置NTP服务 安装NTP服务(所有节点) yum install -y ntp ceph-master节点配置 修改NTP配置文件/etc/ntp.conf 123456789vim /etc/ntp.conf#server 0.centos.pool.ntp.org iburst#server 1.centos.pool.ntp.org iburst#server 2.centos.pool.ntp.org iburst#server 3.centos.pool.ntp.org iburst#网关和广播地址restrict 192.168.56.1 mask 255.255.255.0 nomodify notrapserver 127.127.1.0 minpoll 4fudge 127.127.1.0 stratum 0 修改配置文件/etc/ntp/step-tickers 123# vim /etc/ntp/step-tickers#0.centos.pool.ntp.org127.127.1.0 启动NTP服务并设置开机启动 12systemctl enable ntpdsystemctl start ntpd 所有OSD节点配置 修改NTP配置文件/etc/ntp.conf 123456vim /etc/ntp.conf#server 0.centos.pool.ntp.org iburst#server 1.centos.pool.ntp.org iburst#server 2.centos.pool.ntp.org iburst#server 3.centos.pool.ntp.org iburstserver 192.168.56.101 启动NTP服务并设置开机启动 12systemctl enable ntpdsystemctl start ntpd 验证NTP(所有节点) 12345ntpstatntpq -p remote refid st t when poll reach delay offset jitter==============================================================================*ceph-master .LOCL. 1 u 16 64 377 0.269 0.032 0.269 安装ceph1.更新系统源(所有节点) 123456789yum install -y wgetrm -rf /etc/yum.repos.d/*.repowget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repowget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.reposed -i '/aliyuncs/d' /etc/yum.repos.d/CentOS-Base.reposed -i 's/$releasever/7/g' /etc/yum.repos.d/CentOS-Base.reposed -i '/aliyuncs/d' /etc/yum.repos.d/epel.repoyum clean allyum makecache fast 2.安装ceph-deploy和配置ceph集群(master节点执行) 安装ceph-deploy 1yum install http://mirrors.163.com/ceph/rpm-jewel/el7/noarch/ceph-deploy-1.5.38-0.noarch.rpm 创建ceph集群 1eph-deploy new ceph-node-1 ceph-node-2 编辑ceph配置文件 在global下添加一下配置 123456vim ceph.conf [global]mon_clock_drift_allowed = 5osd_journal_size = 20480#查看自己的网关地址public_network=192.168.56.1/24 使用163源安装CEPH 1ceph-deploy install --release jewel --repo-url http://mirrors.163.com/ceph/rpm-jewel/el7 --gpg-url http://mirrors.163.com/ceph/keys/release.asc ceph-master ceph-node-1 ceph-node-2 初始化节点 1ceph-deploy mon create-initial 配置管理节点(ceph-master) 1234ceph-deploy admin ceph-masterchmod +r /etc/ceph/ceph.client.admin.keyring#查询集群状态ceph -s 创建和配置OSD存储节点1.查看OSD节点的磁盘情况(找到要挂载的新磁盘) 12eph-deploy disk list ceph-node-1eph-deploy disk list ceph-node-2 2.创建并激活OSD节点 123456789101112131415161718192021222324#重建分区表,磁盘存储要大些,如果比较小会报错ceph-deploy disk zap ceph-node-1:/dev/sdbceph-deploy disk zap ceph-node-2:/dev/sdb#创建OSDceph-deploy osd prepare ceph-node-1:/dev/sdbceph-deploy osd prepare ceph-node-2:/dev/sdb#激活若激活失败报:Cannot discover filesystem type 请在OSD执行激活后执行ceph-disk activate-allceph-deploy osd activate ceph-node-1:/dev/sdbceph-deploy osd activate ceph-node-2:/dev/sdb#查看是否激活挂载成功fdisk -l /dev/sdb磁盘 /dev/sdb：1099.5 GB, 1099511627776 字节，2147483648 个扇区Units = 扇区 of 1 * 512 = 512 bytes扇区大小(逻辑/物理)：512 字节 / 512 字节I/O 大小(最小/最佳)：512 字节 / 512 字节磁盘标签类型：gptDisk identifier: AA34481A-A35C-4CB1-BB5E-9D334594D67C# Start End Size Type Name 1 41945088 2147483614 1004G Ceph OSD ceph data 2 2048 41945087 20G Ceph Journal ceph journal#查看ceph的状态ceph health#将配置拷贝到其他节点ceph-deploy --overwrite-conf admin ceph-master ceph-node-1 ceph-node-2 部署时常用命令12345678910111213141516171819202122232425262728293031323334353637383940414243#若部署出现问题可以清空一切重新开始部署#安装包也清除ceph-deploy purge ceph-master ceph-node-1 ceph-node-2ceph-deploy purgedata ceph-master ceph-node-1 ceph-node-2ceph-deploy forgetkeys#需要用命令进行服务的启动和关闭等#监控相关systemctl start ceph-mon.targetsystemctl stop ceph-mon.target#osd相关systemctl start ceph-osd.targetsystemctl stop ceph-osd.target#ceph相关systemctl start ceph.targetsystemctl stop ceph.target#设置开机启动systemctl enable ceph-mon.targetsystemctl enable ceph-osd.targetsystemctl enable ceph.target#验证ceph安装是否成功#创建一个测试文件echo &quot;hello liberalman&quot; &gt; testfile.txt#创建一个poolrados mkpool data#将文件写入poolrados put test-object-1 testfile.txt --pool=data#查看文件是否存在于pool中rados -p data ls#确定文件的位置ceph osd map data test-object-1#从pool中读取文件rados get test-object-1 --pool=data myfile#查看读取的文件是否和之前的一样cat myfile#从pool移除文件rados rm test-object-1 --pool=data#查看状态ceph -sceph osd tree 默认相关文件地址 配置文件：默认 /etc/ceph/ceph.conf 日志文件：默认 /var/log/ceph 运行时文件:默认 /var/run/ceph 每个进程的管理套接字位置：/var/run/ceph/cluster-name.asok 使用管理套接字查看osd.0的运行时配置信息： 1$ ceph --admin-daemon /var/run/ceph/ceph-osd.0.asok config show | less 集群启动后，每个守护进程从配置文件 /etc/ceph/ceph.conf中查看配置信息 1234567891011[ global ]#该配置下设置应用于所有ceph守护进程[ osd ]#该配置下设置应用于所有osd守护进程#或者重写global配置[ osd.0 ]#该配置设置应用于osd 0进程，或者重写前面配置[ mon ]#该配置应用于所有监视器进程[ mds ]#该配置应用于所有元数据服务进程 其他相关 1234567#查看pool类型 默认rbdceph osd pool ls#获取rbd大小ceph osd pool get rbd size#设置rbd大小ceph osd pool set rbd size 3ceph osd pool set rbd min_size 3 centos 7.4安装ceph集群]]></content>
      <tags>
        <tag>ceph</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建NTP服务器]]></title>
    <url>%2F2025%2F01%2F03%2Fsenssic.github.io%2F201905%2F%E6%90%AD%E5%BB%BANTP%E6%9C%8D%E5%8A%A1%E5%99%A8%2F</url>
    <content type="text"><![CDATA[时间相关准备12345678910#设置时区(东八区)cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime -R#设置时间date -s "20190601 16:51:50"#查看格式化时间date "+%Y-%m-%d %H:%M:%S"#查看硬件时间hwclock -r#将当前时间回写到硬件上hwclock -w 安装NTP离线安装包以及其依赖包下载NTP离线安装包 服务器端-192.168.0.13212345678#安装相关离线包和NTP服务器rpm -ivh autogen-libopts-5.18-5.el7.x86_64.rpmrpm -ivh ntp-4.2.6p5-18.el7.centos.x86_64.rpmrpm -ivh ntpdate-4.2.6p5-18.el7.centos.x86_64.rpm#启动ntp服务并设置开机启动,若有防火墙需要将防火墙关闭,或者允许123端口systemctl start ntpdsystemctl enable ntpd 客户端配置1234567891011121314151617181920#安装相关离线包rpm -ivh ntpdate-4.2.6p5-18.el7.centos.x86_64.rpm#同步服务器时间ntpdate -u 192.168.0.132#设置自动同步服务器时间crontab -e#追加定时任务同步时间(0 0 0 * * ? * 每天凌晨同步一次)#每30分钟同步一次*/30 * * * * /usr/sbin/ntpdate 192.168.0.132#查看crond的状态service crond statuscrond -l#crond的启动重启停止service crond startservice crond stopservice crond reloadservice crond restart]]></content>
      <categories>
        <category>搭建</category>
      </categories>
      <tags>
        <tag>ntp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[harbor安装教程]]></title>
    <url>%2F2025%2F01%2F03%2Fsenssic.github.io%2F201905%2Fharbor%E5%AE%89%E8%A3%85%E6%89%8B%E5%86%8C%2F</url>
    <content type="text"><![CDATA[前期准备 查看此机器之前有无登陆过 12who /var/log/wtmplast 查看linux版本 centos 1lsb_release -a 所有linux版本 1uname -a RedHat,Centos 1cat /etc/redhat-release 安装docker以及docker-compose12345678910111213141516171819202122yum update -yyum -y install docker #临时关闭selinuxsetenforce 0 #关闭防火墙systemctl stop firewalld systemctl disable firewalld.service#关闭selinuxvi /etc/sysconfig/selinux#修改SELINUX=enforcing 为SELINUX=disabledsetenforce 0systemctl start docker#安装：docker-composeyum install -y epel-releaseyum install -y python-pip#如有报错更新pip#python -m pip install --upgrade pippip install docker-compose docker --version docker-compose --version 下载harbor并生成证书123wget https://storage.googleapis.com/harbor-releases/release-1.7.0/harbor-offline-installer-v1.7.4.tgztar -xvf harbor-offline-installer-v1.7.4.tgzcd harbor 生成证书123456789101112131415161718192021222324mkdir -p certsopenssl req -newkey rsa:4096 -nodes -sha256 -keyout certs/harbor.key -x509 -days 365 -out certs/harbor.crt Generating a 4096 bit RSA private key....++..............................................................................................................................................................................++writing new private key to 'certs/harbor.key'-----You are about to be asked to enter information that will be incorporatedinto your certificate request.What you are about to enter is what is called a Distinguished Name or a DN.There are quite a few fields but you can leave some blankFor some fields there will be a default value,If you enter '.', the field will be left blank.-----Country Name (2 letter code) [XX]:string is too long, it needs to be less than 2 bytes longCountry Name (2 letter code) [XX]:State or Province Name (full name) []:Locality Name (eg, city) [Default City]:Organization Name (eg, company) [Default Company Ltd]:Organizational Unit Name (eg, section) []:Common Name (eg, your name or your server's hostname) []:aliyun.harborEmail Address []:[root@senssic harbor]# 注意:Common Name (eg, your name or your server’s hostname)为仓库的域名. 在当前目录的certs中会生成两个证书文件 harbor.crt #客户端需要(客户端可以是远程客户端),需要将此证书复制到/etc/docker/certs.d/aliyun.harbor/harbor.crt 路径,目录不存在则需要自己创建 harbor.key 配置harbor的配置文件编辑当前目录的harbor.cfg文件修改如下配置项: 123456hostname = aliyun.harborui_url_protocol = httpscustomize_crt = off#刚才生成certs的路径,确保能读取到harbor.crt和harbor.keyssl_cert = /root/harbor/certs/harbor.crtssl_cert_key = /root/harbor/certs/harbor.key 执行预安装命令./prepare 123456789101112131415[root@senssic harbor]# ./prepare loaded secret from file: /data/secretkeyGenerated configuration file: ./common/config/nginx/nginx.confGenerated configuration file: ./common/config/adminserver/envGenerated configuration file: ./common/config/core/envGenerated configuration file: ./common/config/registry/config.ymlGenerated configuration file: ./common/config/db/envGenerated configuration file: ./common/config/jobservice/envGenerated configuration file: ./common/config/jobservice/config.ymlGenerated configuration file: ./common/config/log/logrotate.confGenerated configuration file: ./common/config/registryctl/envGenerated configuration file: ./common/config/core/app.confCopied configuration file: ./common/config/coreprivate_key.pemCopied configuration file: ./common/config/registryroot.crtThe configuration files are ready, please use docker-compose to start the service. 使私有仓库同时支持mirro功能,编辑common/config/registry/config.yml追加 12proxy: remoteurl: https://registry-1.docker.io 配置完毕执行安装命令./install.sh 客户端拉取上传镜像1.将上述生成的harbor.crt放置到客户端所在机器的/etc/docker/certs.d/aliyun.harbor/ 目录下,若目录不存在则创建. 12mkdir -p /etc/docker/certs.d/aliyun.harbor/cp certs/harbor.crt /etc/docker/certs.d/aliyun.harbor/ 2.拉取测试镜像,生成tag,登陆私有镜像仓库并上传镜像 增加对于aliyun.harbor的hosts解析 编辑/etc/hosts 追加 私有仓库ip aliyun.harbor 登陆私有仓库输入用户名密码,可以在上面的harbor.cfg设置 123456789[root@senssic harbor]# docker login aliyun.harborUsername: adminPassword: WARNING! Your password will be stored unencrypted in /root/.docker/config.json.Configure a credential helper to remove this warning. Seehttps://docs.docker.com/engine/reference/commandline/login/#credentials-storeLogin Succeeded[root@senssic harbor]# 在harbor管理界面新建项目,项目名为test 给已存在的镜像打标签(标签前缀即为私有仓库域名,第层为上面一步创建的项目名称 test),并推送到仓库 1234#aliyun.harbor/test/showdoc中的test需要在harbor界面管理中创建,也可直接使用默认的librarydocker tag registry.docker-cn.com/star7th/showdoc aliyun.harbor/test/showdoc:1.0.0#推送到远端私有仓库docker push aliyun.harbor/test/showdoc:1.0.0 拉取上传的镜像文件 123456789101112131415[root@cjvm101 aliyun.harbor]# docker login aliyun.harborUsername: adminPassword: WARNING! Your password will be stored unencrypted in /root/.docker/config.json.Configure a credential helper to remove this warning. Seehttps://docs.docker.com/engine/reference/commandline/login/#credentials-storeLogin Succeeded[root@cjvm101 aliyun.harbor]# docker pull aliyun.harbor/test/showdoc:1.0.01.0.0: Pulling from test/showdocff3a5c916c92: Pull complete 2ca736d3a2d3: Pull complete ed01bffbd8ba: Pull complete 86a241b7142f: Pull complete 2ffa2200859b: Downloading [=======&gt; 安装过程中常用命令1234567891011#docker加载配置文件systemctl daemon-reloadservice docker restart#在harbor安装根目录下#停止运行容器docker-compose stop#删除容器docker-compose rm#启动harbor./install.sh]]></content>
      <categories>
        <category>harbor</category>
      </categories>
      <tags>
        <tag>harbor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式锁的常见实现]]></title>
    <url>%2F2025%2F01%2F03%2Fsenssic.github.io%2F201901%2F%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%9A%84%E5%B8%B8%E8%A7%81%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[现在的系统部署大部分都是分布式部署的方式,对于需要使用锁的场景不能再通过使用单纯的Java Api实现。产生了基于数据库，缓存(redis,memcached,tair),和zookeeper实现的分布式锁。 对于分布式锁我们希望的理想锁的表现 在分布式环境中保证同一个临界区在同一时间只在一台机器上执行。 这把分布式锁是可重入锁[避免死锁] 可以根据业务需要变成阻塞锁 获取和释放锁性能高 基于数据库实现分布式锁基于唯一索引实现1.创建一张带唯一索引的表 12345678CREATE TABLE `blockLock` ( `id` int(11) NOT NULL AUTO_INCREMENT COMMENT '主键', `block_name` varchar(64) NOT NULL DEFAULT '' COMMENT '锁定的块名称', `desc` varchar(1024) NOT NULL DEFAULT '备注信息', `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '保存数据时间，自动生成', PRIMARY KEY (`id`), UNIQUE KEY `uidx_method_name` (`block_name `) USING BTREE) ENGINE=InnoDB DEFAULT CHARSET=utf8; 2.在想要添加锁的块代码之前插入数据,由于block_name做了唯一索引,同样块名称的操作只能有一个成功。 1insert into methodLock(method_name,desc) values (‘block_name’,‘the same block_name commit’); 3.临界代码执行完毕需要释放锁,此时只需要将block_name这条数据删除或更新即可 1delete from methodLock where method_name ='block_name' 优点: 实现方便,便于理解 缺点: 如果数据库是单点,则可靠性不能保证 没有失效时间,不会自动释放锁,一旦解锁失败会导致其他线程无法再获取到锁。 这把锁只能是非阻塞的,插入失败直接报错返回,无法自动阻塞再次尝试获取锁 这把锁是非重入锁,线程获取锁后无法再次获取此锁,因为数据库已存在唯一索引值。 对于基于数据库的锁获取和释放锁的开销相对比较大 基于数据库的排他锁在mySql的InnoDB引擎的查询语句后增加for update,这样在查询的过程中数据库会增加排他锁【注意:如果想使用查询参数要建立唯一索引,由于InnoDB 预设是Row-Level Lock，所以只有「明确」的指定主键，MySQL 才会执行Row lock (只锁住被选取的数据) ，否则MySQL 将会执行Table Lock (将整个数据表单给锁住】。 添加锁代码1234567891011121314151617181920public boolean lock()&#123; Long timeout=10000； long futureTime = System.currentTimeMillis() + timeOuts; connection.setAutoCommit(false) while(true)&#123; try&#123; result = select * from blockLock where block_name=xxx for update; if(result==null)&#123; return true; &#125; &#125;catch(Exception e)&#123; &#125; sleep(1000); if(futureTime&lt;System.currentTimeMillis())&#123; break; &#125; &#125; return false;&#125; 释放锁代码123public void unlock()&#123; connection.commit();&#125; 优点: 阻塞锁,for update语句会一直等待直到执行成功后返回结果 自动释放锁,当数据库连接断开时候会自动释放锁 缺点: 如果数据库是单点,则可靠性不能保证 对于基于数据库的锁获取和释放锁的开销相对比较大 使用不当容易变成表级锁,容易影响业务 利用事务进行加锁的时候会导致很多连接不能及时释放,导致连接池爆满 基于缓存实现分布式锁相较于数据库实现的分布式锁,基于缓存实现的分布式锁更加高效，且有很多成熟的方案,redis,memcached以及tair等都有很好的支持。 下面是基于redis实现的分布式锁 添加锁代码123456789101112private static final String LOCK_SUCCESS = "OK";private static final String SET_IF_NOT_EXIST = "NX";private static final String SET_WITH_EXPIRE_TIME = "PX";public static boolean tryGetDistributedLock(Jedis jedis, String lockKey, String requestId, int expireTime) &#123; String result = jedis.set(lockKey, requestId, SET_IF_NOT_EXIST, SET_WITH_EXPIRE_TIME, expireTime); if (LOCK_SUCCESS.equals(result)) &#123; return true; &#125; return false;&#125; 第一个为key，我们使用key来当锁，因为key是唯一的。 第二个为value，我们传的是requestId，很多童鞋可能不明白，有key作为锁不就够了吗，为什么还要用到value？原因就是我们在上面讲到可靠性时，分布式锁要满足第四个条件解铃还须系铃人，通过给value赋值为requestId，我们就知道这把锁是哪个请求加的了，在解锁的时候就可以有依据。requestId可以使用UUID.randomUUID().toString()方法生成。 第三个为nxxx，这个参数我们填的是NX，意思是SET IF NOT EXIST，即当key不存在时，我们进行set操作；若key已经存在，则不做任何操作； 第四个为expx，这个参数我们传的是PX，意思是我们要给这个key加一个过期的设置，具体时间由第五个参数决定。 第五个为time，与第四个参数相呼应，代表key的过期时间。 ##释放锁代码: 12345678910111213private static final Long RELEASE_SUCCESS = 1L;public static boolean releaseDistributedLock(Jedis jedis, String lockKey, String requestId) &#123; //就是在eval命令执行Lua代码的时候，Lua代码将被当成一个命令去执行，并且直到eval命令执行完成，Redis才会执行其他命令。 String script = "if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end"; Object result = jedis.eval(script, Collections.singletonList(lockKey), Collections.singletonList(requestId)); if (RELEASE_SUCCESS.equals(result)) &#123; return true; &#125; return false; &#125; 首先获取锁对应的value值，检查是否与requestId相等，如果相等则删除锁（解锁）。使用Lua语言来确保上述操作是原子性。 优点： 缓存服务可以做集群提高可用性 获取锁和释放锁效率高 可以设置超时时间,超时会自动释放锁 缺点: 这是把非阻塞锁,无论成功失败会直接返回 这是把非重入锁,当一个线程获取锁后在释放锁前此线程无法再次获得该锁 失效时间平衡设置比较困难(时间短,会产生并发问题,时间长,会导致浪费的资源等待) 基于zookeeper实现分布式锁zookeeper会为客户端加锁的请求建立唯一一个瞬时有序节点,判断获取锁只需要判断此节点是否为此有序节点中序号最小的一个。当释放锁时候,只需要将这个瞬时节点删除可以。 使用curator客户端操作zookeeper 123456789101112131415161718public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException &#123; try &#123; return interProcessMutex.acquire(timeout, unit); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return true;&#125;public boolean unlock() &#123; try &#123; interProcessMutex.release(); &#125; catch (Throwable e) &#123; log.error(e.getMessage(), e); &#125; finally &#123; executorService.schedule(new Cleaner(client, path), delayTimeForClean, TimeUnit.MILLISECONDS); &#125; return true;&#125; 优点: 锁释放,当客户获取锁后突然挂掉(session连接断开),临时节点会自动删除。其他客户端可以再次获取锁 可实现阻塞锁,客户端通过在zk中创建有顺序节点,并且绑定监听,如果节点变化zk会通知客户端,客户端检查自己创建的节点是不是当前所有节点中序号最小的从而判断是否获取到锁。 可重入,客户端在创建节点时,zk会把当前客户端主机信息和线程信息写到节点中,客户端线程再次想获取锁时候和当前最小节点的数据对比一下就可以了。如果信息一样便是已获取到锁。 高可用,zk是集群部署的。 缺点: 由于需要很多判断和信息写入读取,以及分发信息,效率并没有基于缓存的高 有极低的概率会(zk有重试机制只有多次重试仍检测不到客户端心跳就会删除客户端临时节点)导致并发问题,如:当网络抖动失去客户端连接,别的客户端可能会得到分布式锁。 分布式锁的几种实现Redis 分布式锁的正确实现方式（ Java 版 ）]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>锁</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[你好,世界]]></title>
    <url>%2F2025%2F01%2F03%2Fsenssic.github.io%2F%E4%BD%A0%E5%A5%BD%2C%E4%B8%96%E7%95%8C%2F</url>
    <content type="text"><![CDATA[你好,世界 你好,世界！不要在生活中迷失！ –2018年08月07日01:38:41]]></content>
      <categories>
        <category>生活百味</category>
      </categories>
      <tags>
        <tag>生活</tag>
        <tag>杂项</tag>
        <tag>感悟</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[temp]]></title>
    <url>%2F2025%2F01%2F03%2Fsenssic.github.io%2Ftemp%2F</url>
    <content type="text"><![CDATA[[TOC] 0.windows相关0.0 windows关于端口查询&amp;自启动目录123456789# 查看被占用的端口的进程netstat -aon|findstr "8081"#杀死进程PID以及子进程taskkill /T /F /PID 9088#自启动脚本的.vbs文件不弹框set ws=WScript.CreateObject("WScript.Shell")ws.Run "C:\start\bat-start.bat",0#将上面的代码文本编辑重命名.vbs文件放到下面的自启动目录C:\ProgramData\Microsoft\Windows\Start Menu\Programs\StartUp 0.1 windows使用自带命令监听本地端口转发到其他服务器123456#这条命令会监听所有本地的3306端口的请求，并将它们转发到xx.xx.xx.xx的3306端口上。以管理员权限启动cmdnetsh interface portproxy add v4tov4 listenport=3306 listenaddress=0.0.0.0 connectport=3306 connectaddress=xx.xx.xx.xx#删除本条转发规则netsh interface portproxy delete v4tov4 listenport=3306 listenaddress=0.0.0.0#查看所有正在转发的规则netsh interface portproxy show all 0.2 hyper-v开启centos的虚拟化并安装docker的Windows镜像123456789101112131415161718192021222324252627282930313233341.开启hyper-v的centos虚拟机的KVM虚拟化#1.0查看centos虚拟机有没有开启egrep -o 'vmx|svm' /proc/cpuinfo#1.1 若没开启，关闭centos，打开宿主机的powershell使用管理员身份打开##列出虚拟机Get-VM##查看虚拟化选项参数，ExposeVirtualizationExtensions参数发现是falseGet-VMProcessor -VMName centos虚拟机名称 | fl##将ExposeVirtualizationExtensions参数设置为TrueSet-VMProcessor -ExposeVirtualizationExtensions $true -VMName centos虚拟机名称## 重新虚拟机并查看是否已经支持kvm，发现执行后会有多个VMX，有几个意味着有几个cpuegrep -o 'vmx|svm' /proc/cpuinfo## 参考github开源docker部署windowshttps://github.com/dockur/windows## docker-compose书写如下，启动成功后可以使用远程链接，或者http浏览器访问services: windows: image: dockurr/windows container_name: windows environment: VERSION: "winxp" LANGUAGE: "cn" DISK_SIZE: "128G" volumes: - /opt/win:/storage devices: - /dev/kvm cap_add: - NET_ADMIN ports: - 8006:8006 - 3389:3389/tcp - 3389:3389/udp stop_grace_period: 2m 1.linux相关1.1 hexo一键执行脚本12345678910111213#!/bin/shnowdate=$(date)echo $&#123;nowdate&#125;cd /Users/senssic/work/mkdown/githublog/senssichexo cleanhexo ghexo dcd ./source/_posts/senssic.github.iogit pullgit add .git commit -m 'updated:'$(date +%y年%m月%d日%H时%M分)git pushcd /Users/senssic/work/mkdown/githublog 1.2 centos初始化1234567891011121314151617181920#增加NDS解析echo -e "nameserver 4.4.4.4\nnameserver 8.8.8.8" | sudo tee -a /etc/resolv.conf &gt; /dev/null#替换清华源curl -o /etc/yum.repos.d/Centos7-tuna.repo https://mirrors.wlnmp.com/centos/Centos7-tuna-x86_64.repo#安装依赖yum install -y epel-releaseyum install -y chrony conntrack ipvsadm ipset jq iptables curl sysstat libseccomp wget socat git#停止防火墙systemctl stop firewalldsystemctl disable firewalldiptables -F &amp;&amp; iptables -X &amp;&amp; iptables -F -t nat &amp;&amp; iptables -X -t natiptables -P FORWARD ACCEPT#关闭swap分区swapoff -ased -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstabsetenforce 0#关闭SELINUXsed -i 's/^SELINUX=.*/SELINUX=disabled/' /etc/selinux/config#安装dockercurl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun 1.3 linux操作系统相关1234567891011121314151617181. 设置hostname名称sudo hostnamectl set-hostname &lt;newhostname&gt;2. tcpdump的命令使用#详细输出且目标端host为10.19.146.223且目标端端口为28201 且网卡为ens160tcpdump -s 0 -l -w - dst 10.19.146.223 and port 28201 -i ens160|strings &gt; tcpdump.txt3. 使用ffmpeg命令拉流并截图保存ffmpeg -an -vf select='eq(pict_type\,I)' -vsync 2 -f image2 -strftime 1 "%H_%M_%S.jpg" -i rtsp://admin:admin@192.168.1.12:554/h264/ch33/main/av_stream4.linux系统增加只读账号对某个目录只读限定#增加只读用户useradd readonly#修改密码passwd readonly#添加用户对文件的只读r权限setfacl -R -m u:readonly:rX /data/software#收回对应的权限setfacl -R -x u:readonly:rX /data/software#查看文件权限赋权信息getfacl /data/software/ 1.4 centos8 root用户忘记密码 1.启动centos8系统,在开机界面选择第一行，按e 2.进入以下界面，找到ro并将其修改为rw init=/sysroot/bin/bash 3.同时按住ctrl和x键，系统进入以下紧急模式界面 4.输入以下命令修改密码 1234chroot /sysroot/ #切换回原始系统LANG=en #把语言改为英文passwd #设置新密码touch /.autorelabel #使密码生效 5.同时按住Ctrl和d键，进入以下界面，输入reboot，重启系统,直接使用新密码操作即可 1.5 linux的初始化优化1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465# 1.设置主机名称hostnamectl set-hostname xxx # 将 xxx 替换为当前主机名# 2.设置hostcat &gt;&gt; /etc/hosts &lt;&lt;EOF172.27.138.251 xxx-01172.27.137.229 xxx-02172.27.138.239 xxx-03EOF#3.添加节点信任关系ssh-keygen -t rsa ssh-copy-id root@xxx-01ssh-copy-id root@xxx-02ssh-copy-id root@xxx-03#4.安装基础依赖yum install -y epel-releaseyum install -y chrony conntrack ipvsadm ipset jq iptables curl sysstat libseccomp wget socat git#5.关闭防火墙systemctl stop firewalldsystemctl disable firewalldiptables -F &amp;&amp; iptables -X &amp;&amp; iptables -F -t nat &amp;&amp; iptables -X -t natiptables -P FORWARD ACCEPT#6.关闭 swap 分区swapoff -ased -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab #7.关闭 SELinuxsetenforce 0sed -i 's/^SELINUX=.*/SELINUX=disabled/' /etc/selinux/config#8.优化内核参数cat &gt; temp.conf &lt;&lt;EOFnet.bridge.bridge-nf-call-iptables=1net.bridge.bridge-nf-call-ip6tables=1net.ipv4.ip_forward=1net.ipv4.tcp_tw_recycle=0net.ipv4.neigh.default.gc_thresh1=1024net.ipv4.neigh.default.gc_thresh1=2048net.ipv4.neigh.default.gc_thresh1=4096vm.swappiness=0vm.overcommit_memory=1vm.panic_on_oom=0fs.inotify.max_user_instances=8192fs.inotify.max_user_watches=1048576fs.file-max=52706963fs.nr_open=52706963net.ipv6.conf.all.disable_ipv6=1net.netfilter.nf_conntrack_max=2310720EOFcp temp.conf /etc/sysctl.d/temp.confsysctl -p /etc/sysctl.d/temp.conf#9.设置系统时区timedatectl set-timezone Asia/Shanghai#10.设置系统时钟同步systemctl enable chronydsystemctl start chronyd#11.关闭无关的服务systemctl stop postfix &amp;&amp; systemctl disable postfix#12.升级内核rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpm# 安装完成后检查 /boot/grub2/grub.cfg 中对应内核 menuentry 中是否包含 initrd16 配置，如果没有，再安装一次！yum --enablerepo=elrepo-kernel install -y kernel-lt# 设置开机从新内核启动grub2-set-default 0syncreboot#安装dockercurl -sSL https://get.daocloud.io/docker | sh 1.6 linux双网卡NAT路由映射123456789101112131415161718# 前提:# 服务器 A ：配有外网 IP 地址 1.1.1.1 和内网 IP 地址 192.168.1.1 ，操作系统为 CentOS Linux 7 ；# 数据库服务器 B ：仅配有内网 IP 地址 192.168.1.2 ，操作系统没有限制，Windows 也可。# 需求:# 需要通过外网去访问数据库服务器 B 的 3306 端口，即将 1.1.1.1:30000 映射为 192.168.1.2:3306 。# 开启 IP 路由转发echo "net.ipv4.ip_forward = 1" &gt;&gt; /etc/sysctl.confsysctl -p# 清除原有的 NAT 表中的规则iptables -t nat -F# 清除原有的 filter 表中的规则iptables -F# 缺省允许 IP 转发iptables -P FORWARD ACCEPT# SNAT(source NAT,对源 IP 地址做 NAT)将 x.x.x.x:yyyy → 192.168.1.2:3306 转换为 192.168.1.1:zzzz → 192.168.1.2:3306 iptables -t nat -A PREROUTING -p tcp --dport 30000 -j DNAT --to-destination 192.168.1.2:3306# DNAT（ destination NAT ，对目的 IP 地址做 NAT ），即将 x.x.x.x:yyyy → 1.1.1.1:30000 转换为 x.x.x.x:yyyy → 192.168.1.2:3306 iptables -t nat -A POSTROUTING -d 192.168.1.2 -p tcp --dport 3306 -j SNAT --to 192.168.1.1 1.7 主盘扩容(/dev/mapper/centos-root 空间不足)123456789ls /dev/sd* #使用fdisk分区然后找一块空的分区pvcreate /dev/sda3 #使用空的分区创建pvvgs #先使用vgs查看vg组大小vgextend centos /dev/sda3 #扩展vgvgs #再查看一下vg组大小，看是否发生变化lvs #查看lv大小,虽然我们把vg扩展了，但是lv还没有扩展lvextend -L +20G /dev/mapper/centos-root #扩展lv,使用lvextendxfs_growfs /dev/mapper/centos-root #命令使系统重新读取大小df -h #查看磁盘是否成功变化大小 1.8 新增磁盘挂载1234567891011121314151617181920#列出新的的磁盘fdisk -l#若需要划分分区，执行如下操作，若不需要分区直接格式化挂载即可，如果使用分区则需要挂载分区后的比如xvde1#1.第一种要划分分区，或者划分空间分区#fdisk /dev/xvde#输入 n 开始进行设置#输入 p 设置主分区#分区号默认#起始扇区默认,按enter默认开始#结束扇区默认,若按enter默认所有的结束按需#输入 w 设置保存#2.第二种直接格式化整个磁盘进行挂载#格式化此磁盘,若报错不存在,使用partprobe /dev/sda重建分区，lsblk来查看是否成功mkfs -t ext4 /dev/xvde#创建新目录并挂载此磁盘mkdir -p /mnt/homemount /dev/xvde /mnt/home#设置开机挂载 编辑 vim /etc/fstab 增加如下/dev/xvde /mnt/home ext4 defaults 0 0 1.9 linux虚拟网卡和路由 https://www.linuxidc.com/Linux/2017-09/146914.htm 123456789101112131415161718192021222324252627282930313233343536#1.新增虚拟网卡,【或者直接使用虚拟机创建两个实体网卡】#***********ubuntu 配置开始**************vi /etc/network/interfaces# 需替换为实际物理网卡auto eth0:1iface eth0:1 inet staticaddress 192.168.2.10netmask 255.255.255.0#重启网络/etc/init.d/networking restart#***********ubuntu 配置结束**************#***********centos 配置开始**************vi /etc/sysconfig/network-scripts/ifcfg-eth0:1# 需替换为实际物理网卡DEVICE=eth0:1ONBOOT=yesBOOTPROTO=staticIPADDR=192.168.2.10NETMASK=255.255.255.0#重启网络service network restart#***********centos 配置结束**************#2.若需要上级网段访问下级网段可以配置路由#配置转发，Linux 本身开启转发功能后就是一个路由器echo "net.ipv4.ip_forward=1" &gt;&gt; /etc/sysctl.conf sysctl -p#https://www.cnblogs.com/embedded-linux/p/10200831.html#设置路由 目标 子网掩码 网关/下一跳route add -net 10.10.20.0 netmask 255.255.255.0 gw 10.10.10.1#3.配置nat转发（在虚拟路由服务器执行）#清除原有的nat表中的规则iptables -F &amp;&amp; iptables -X &amp;&amp; iptables -F -t nat &amp;&amp; iptables -X -t nat#缺省允许IP转发iptables -P FORWARD ACCEPT#利用iptables 实现nat MASQUERADE 共享上网，eth0为可以上网的网卡iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE windows增加路由,访问192.168.x.x的所有请求都经由192.168.176.1网关 12route add -p 192.168.0.0 mask 255.255.240.0 192.168.176.1 metric 1 1.10 增加或扩容swap123456789101112131415161718192021#********创建和扩容**************#创建10G的swap文件在 /mnt/swap文件，若是扩容swap注意此路径不与之前的swap文件相同dd if=/dev/zero of=/mnt/swap bs=1M count=10240#将刚才创建的文件格式为swap文件，并记录返回的磁盘UUIDmkswap /mnt/swap#挂载swap分区swapon /mnt/swap#查看swap分区free -hswapon -s#写入开启磁盘加载文件echo 'UUID=替换为刚才记录的UUID swap swap defaults 0 0' &gt;&gt; /etc/fstab#********卸载和缩容**************#卸载缩容swap文件swapoff /mnt/swap#删除对应的swap磁盘挂载vim /etc/fstab#删除对应swap文件rm /mnt/swap 1.11 centos下载应离线安装包12345##从功能定位上来说推荐使用方式1#方式1:使用yumdownloader若没有先安装yum install yum-utilsyumdownloader -y &lt;package-name&gt;#方式2:使用localinstall只下载的方式实现yum localinstall -y --downloadonly --downloaddir=&lt;目录路径&gt; &lt;package-name&gt; 1.12 linux查询系统进行被杀1234567891011journalctl -xb | egrep -i 'killed process'dmesg | egrep -i 'killed process'egrep -i -r 'killed process' /var/log#增加kill的日志审计，能看到被哪个进程和用户杀死的sudo apt install auditdsystemctl enable auditd.servicesystemctl restart auditd.service#使用auditctl命令添加auditctl -a exit,always -F arch=b64 -S kill -F a1=9#查看日志审计sudo ausearch -sc kill 2.虚拟机相关2.1 virtual Boxs使用virtual host和nat网络固定ip1.新建net网络(管理-&gt;全局设置-&gt;网络设置)2.虚拟机新建网卡1virtual host(可以指定网址段)，设置网络类型为virtual host3.虚拟机新建网卡2设置网络类型为NAT(选择新建的NAT网络,可以指定网址段)4.固定NAT网络IP地址 编辑/etc/sysconfig/network-scripts/对应的网卡信息如果没有则新建 修改属性BOOTPROTO=static 修改属性NOBOOT=yes 新增属性(对应网卡的属性) IPADDR=10.0.2.101 NETMASK=255.255.255.0 GATEWAY=10.0.2.15.同上固定virtual host连接的网络IP地址 virtual boxs上网 0.使用everthing的iso 1.使用NET网络选择准虚拟化网络(virtio-net),混杂模式拒绝 2.创建host-noly网络并选择选择准虚拟化网络(virtio-net),混杂模式拒绝 如果无法自动获取net和host-noly的ip,到/etc/sysconfig/network-scripts/目录下将这两个网卡的配置(ifcfg-xxx)删除然后重启 2.2 桥接网络虚拟机无法自动获取ipdhclient 网卡 -v 2.3 virtual Boxs设置已存在的硬盘的大小C:\Program Files\Oracle\VirtualBox\VBoxManage.exe modifyhd E:\vribox\k8s-temp\k8s-temp-disk1.vdi –resize 512000 2.4 实验室主机虚拟化软件VMware ESXi 和 Proxmox 一般研发推荐Proxmox 2.5 pve 设置虚拟机分辨率123#1.虚拟BIOS需要使用OVMF(UEFI),并再启动时候点击 esc键进入bios#2.依次选择 Device Manager&gt;OVMF Platform Configuration&gt;Change Preferred 选择对应的分辨率就行#3.选择Commit Changes adn Exit 退出bios继续进入系统即可 2.6 Hyper-V NAT 网络设置固定 IP / DHCP以管理员身份启动PowerShell ，执行下列命令,创建NAT名称的网络，并在虚拟机的配置中选择此网络 12345678# 创建虚拟交换机New-VMSwitch -SwitchName "NAT" -SwitchType Internal# 获取虚拟交换机的ifindex，并赋值到变量中$ifindex = Get-NetAdapter -Name "vEthernet (NAT)" | Select-Object -ExpandProperty 'ifIndex'# 在虚拟交换机上设置固定IP，用于网关IPNew-NetIPAddress -IPAddress 192.168.56.254 -PrefixLength 24 -InterfaceIndex $ifindex# 创建nat网络New-NetNat -Name NAT -InternalIPInterfaceAddressPrefix 192.168.56.0/24 编辑虚拟机网络配置vim /etc/sysconfig/network-scripts/ifcfg-eth0123456789101112131415161718TYPE=EthernetPROXY_METHOD=noneBROWSER_ONLY=noBOOTPROTO=staticDEFROUTE=yesIPV4_FAILURE_FATAL=noIPV6INIT=yesIPV6_AUTOCONF=yesIPV6_DEFROUTE=yesIPV6_FAILURE_FATAL=noIPV6_ADDR_GEN_MODE=stable-privacyNAME=eth0UUID=3b8a4cf0-252f-4cc5-9e23-eebd73a37185DEVICE=eth0ONBOOT=yesIPADDR=192.168.56.101GATEWAY=192.168.56.254DNS1=223.5.5.5 重启网络 1service network restart 3.数据库相关3.1 mysql数据库常用操作123-- 重置root密码,并刷新权限update user set authentication_string = password(‘123456’), password_expired = ‘N’, password_last_changed = now() where user = ‘root’;flush privileges; 3.2 数据库问题排查语句3.2.1 数据库诊断命令12345678show processlistshow statusshow variablesshow table statusshow indexshow engineshow master statusshow slave status 3.3.2 数据库死锁排查语句1234567891011121314151617181920212223242526272829# 查看当前连接show processlist;show full processlist;SELECT * FROM INFORMATION_SCHEMA.PROCESSLIST;# 查看当前未提交的事务（如果死锁等待超时,事务可能还没有关闭）SELECT * FROM INFORMATION_SCHEMA.INNODB_TRX;# 查看正在被访问的表show OPEN TABLES where In_use &gt; 0;# 查看最近的死锁记录SHOW ENGINE INNODB STATUS;# 死锁日志show variables like 'innodb_print_all_deadlocks';# 若一直请求不到资源，默认50秒则出现锁等待超时。show variables like 'innodb_lock_wait_timeout';# 设置全局变量 锁等待超时为60秒（新的连接生效）set session innodb_lock_wait_timeout=50;set global innodb_lock_wait_timeout=60;#上面测试中，当事务中的某个语句超时只回滚该语句，事务的完整性属于被破坏了。为了回滚这个事务，启用以下参数：show variables like 'innodb_rollback_on_timeout';show processlist;SELECT trx_mysql_thread_id,trx_state,trx_started,trx_weight FROM INFORMATION_SCHEMA.INNODB_TRX;# 表锁级别# NEVER：加了读锁之后，不允许其他 session 并发插入。# AUTO：加了读锁之后，如果表里没有删除过数据，其他 session 就可以并发插入。# ALWAYS：加了读锁之后，允许其他 session 并发插入。show global variables like '%concurrent_insert%';show master logs; 3.3.3 数据库慢查询链接数过多CPU升高排查语句12345678910111213141516171819202122232425262728-- ***Mysql 开启慢查询***----#查看是否开启了慢查询日志SHOW VARIABLES LIKE '%slow_query_log%'#用命令方式开启慢查询日志，但是重启MySQL后此设置会失效set global slow_query_log = 1#永久生效开启方式可以在my.cnf里进行配置，在[mysqld]下新增以下两个参数，重启MySQL即可生效slow_query_log = 1slow_query_log_file = 日志文件存储路径-- ***Mysql 线程执行时间问题***------ 按客户端 IP 分组，看哪个客户端的链接数最多SELECT client_ip,COUNT(client_ip) AS client_num FROM (SELECT SUBSTRING_INDEX(HOST,':' ,1) AS client_ip FROM information_schema.processlist ) AS connect_info GROUP BY client_ip ORDER BY client_num DESC;-- 查看正在执行的线程，并按 Time 倒排序，看看有没有执行时间特别长的线程SELECT * FROM information_schema.processlist WHERE Command != 'Sleep' ORDER BY TIME DESC;-- 找出所有执行时间超过 3 分钟的线程(排除守护线程)，拼凑出 kill 语句，方便后面查杀 （此处 5分钟 可根据自己的需要调整SQL标红处）可复制查询结果到控制台，直接执行，杀死堵塞进程SELECT CONCAT('kill ', id, ';') FROM information_schema.processlist WHERE Command != 'Sleep' AND Command != 'Daemon' AND TIME &gt; 180 ORDER BY TIME DESC;-- 查询线程及相关信息 (ID 为此线程ID，Time为线程运行时间，Info为此线程SQL)SHOW FULL PROCESSLIST-- 上面的语句等同于下面SELECT * FROM information_schema.processlist-- 查看最大连接数SHOW VARIABLES LIKE '%max_connection%';-- 重新设置最大连接数SET GLOBAL max_connections=1000;-- mysql查看连接数（连接总数、活跃数、最大并发数）SHOW STATUS LIKE 'Threads%';-- 查询服务器thread_cache_size的值SHOW VARIABLES LIKE 'thread_cache_size'; 3.3 mysqldump常用命令123456789101112131415161718192021222324# 备份全部数据库（包含存储过程、自定义函数及事件） mysqldump -uroot -pxxxxxx --single-transaction -R -E --all-databases &gt; /tmp/all_database.sql # 要求记录 binlog 位点信息 可用于搭建从库 mysqldump -uroot -pxxxxxx --single-transaction -R -E --all-databases --master-data=2 &gt; /tmp/all_database.sql # 备份指定数据库 mysqldump -uroot -pxxxxxx --single-transaction -R -E --databases db1 &gt; /tmp/db1.sql mysqldump -uroot -pxxxxxx --single-transaction -R -E --databases db1 db2 &gt; /tmp/db1_db2.sql # 备份部分表 mysqldump -uroot -pxxxxxx --single-transaction db1 tb1 &gt; /tmp/tb1.sql mysqldump -uroot -pxxxxxx --single-transaction db1 tb1 tb2 tb3 &gt; /tmp/tb.sql # 导出某个表，数据以单行insert显示 mysqldump -uroot -pxxxxxx --single-transaction --skip-extended-insert db1 tb1 &gt; /tmp/tb1.sql # 导出单表的部分数据 mysqldump -uroot -pxxxxxx --single-transaction db1 tb1 --where=" create_time &gt;= '2021-06-01 00:00:00' " &gt; /tmp/tb1.sql mysqldump -uroot -pxxxxxx --single-transaction db1 tb1 --where='id &lt; 10' &gt; /tmp/tb1.sql # 排除某些表导出 mysqldump -uroot -pxxxxxx --single-transaction --databases db1 --ignore-table=db1.tb1 --ignore-table=db1.tb2 &gt; /tmp/db1.sql # 只导出结构或只导出数据 mysqldump -uroot -pxxxxxx db1 --no-data &gt; /tmp/db1_jiegou.sql mysqldump -uroot -pxxxxxx db1 --no-create-info &gt; /tmp/db1_data.sql # 只导出某个库的存储过程及自定义函数 mysqldump -uroot -pxxxxxx -d -t -R db1 &gt; /tmp/db1_routine.sql # 远程导出 即MySQL服务端不在本地 mysqldump -uroot -pxxxxxx -hxxx.xxx.xx -P3306 --single-transaction --databases db1 &gt; /tmp/db1.sql 4.容器相关4.1 命令相关123456789101112131415161718192021222324252627282930313233343536371.列出所有的容器 IDdocker ps -aq2.停止所有的容器docker stop $(docker ps -aq)3.删除所有的容器docker rm $(docker ps -aq)或docker container prune -f4.删除所有镜像docker rmi $(docker images -q)或docker image prune -f -a5.删除所有网络docker network prune -f -a6.复制文件docker cp mycontainer:/opt/file.txt /opt/local/docker cp /opt/local/file.txt mycontainer:/opt/7.查看镜像的启动命令alias runlike="docker run --rm -v /var/run/docker.sock:/var/run/docker.sock assaflavie/runlike"runlike -p 容器8.查看镜像的构建Dockerfile命令#使用命令docker history 容器 --no-trunc#使用其他容器命令alias whaler="docker run -t --rm -v /var/run/docker.sock:/var/run/docker.sock:ro pegleg/whaler"whaler -sV=1.36 容器9.调试docker容器#安装docker-debughttps://github.com/zeromake/docker-debug/blob/master/README-zh-Hans.md10.调试k8s的pod容器#如果是私有仓库需要自己将debug-agent:v0.1.1 和 nicolaka/netshoot:latest push到私有仓库,docker tag,docker pushkubectl-debug -n dev pod-xxx --agentless=true --port-forward=true --agent-image=aylei/debug-agent:v0.1.111.docker一键清理所有没有用到的网络，镜像，磁盘挂载等docker system prune -a12.安装docker-composecurl -L https://get.daocloud.io/docker/compose/releases/download/v2.16.0/docker-compose-`uname -s`-`uname -m` &gt; /usr/local/bin/docker-composechmod +x /usr/local/bin/docker-compose 4.2 安装docker和minikube12345678910111213141516171819202122232425262728#1.创建非root用户adduser testpasswd test#创建docker组sudo groupadd docker#将您的用户添加到该docker组sudo usermod -aG docker test#在Linux上，运行以下命令来激活对组的更改newgrp docker#2.安装dockercurl -fsSL https://get.docker.com | bash -s docker --mirror aliyun#3.安装kubectlcurl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectlsudo chmod a+x ./kubectlsudo mv ./kubectl /usr/local/bin/kubectl#4.安装minikubecurl -Lo minikube https://kubernetes.oss-cn-hangzhou.aliyuncs.com/minikube/releases/v1.20.0/minikube-linux-amd64 &amp;&amp; chmod +x minikube &amp;&amp; sudo mv minikube /usr/local/bin/#5.多节点启动##创建主集群(默认Profile为minikube,可以加 -p 创建不通的k8s集群)minikube start --force##增加节点minikube node add##查看节点minikube node list##启动主节点仪表盘minikube dashboard##删除集群minikube delete 4.3 安装jenkins1234567docker pull jenkins/jenkins#挂载配置文件mkdir -p /var/jenkins_mount &amp;&amp; chmod 777 /var/jenkins_mount#启动Jenkins端口为10240docker run -d -p 10240:8080 -p 10241:50000 -v /var/jenkins_mount:/var/jenkins_home -v /etc/localtime:/etc/localtime --name myjenkins jenkins/jenkins# 清华大学官方镜像：https://mirrors.tuna.tsinghua.edu.cn/jenkins/updates/update-center.jsonvi hudson.model.UpdateCenter.xml 4.4 自定义jenkins的镜像当前目录下存在: config Dockerfile glibc-2.23-r3.apk kubectl settings.xml 文件 12345678910111213141516171819202122232425262728FROM jenkins/jenkins:alpineLABEL auth="qisensen"USER rootARG MAVEN_VERSION=3.6.3ARG MAVEN_SHA=fae9c12b570c3ba18116a4e26ea524b29f7279c17cbaadc3326ca72927368924d9131d11b9e851b8dc9162228b6fdea955446be41207a5cfc61283dd8a561d2fARG MAVEN_BASE_URL=https://apache.osuosl.org/maven/maven-3/$&#123;MAVEN_VERSION&#125;/binariesRUN echo "https://mirrors.aliyun.com/alpine/v3.8/main/" &gt; /etc/apk/repositories \ &amp;&amp; echo "https://mirrors.aliyun.com/alpine/v3.8/community/" &gt;&gt; /etc/apk/repositories \ &amp;&amp; apk add --no-cache curl ca-certificates openrc tar procps tzdata shadow docker \ &amp;&amp; cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime &amp;&amp; echo Asia/Shanghai &gt; /etc/timezone \ &amp;&amp; mkdir -p /usr/share/maven /usr/share/maven/ref/repository \ &amp;&amp; curl -fsSL -o /tmp/apache-maven.tar.gz $&#123;MAVEN_BASE_URL&#125;/apache-maven-$&#123;MAVEN_VERSION&#125;-bin.tar.gz \ &amp;&amp; tar -xzf /tmp/apache-maven.tar.gz -C /usr/share/maven --strip-components=1 \ &amp;&amp; rm -f /tmp/apache-maven.tar.gz \ &amp;&amp; ln -s /usr/share/maven/bin/mvn /usr/bin/mvn \ &amp;&amp; usermod -aG 999 jenkins \ &amp;&amp; chown 1000:1000 /usr/share/maven/ref/repository \ &amp;&amp; apk del tzdata shadow tar &amp;&amp; rc-update add docker boot &amp;&amp; mkdir -p ~/.kube/COPY kubectl /usr/local/bin/COPY config ~/.kube/ENV MAVEN_HOME /usr/share/mavenENV KUBECONFIG ~/.kube/configVOLUME /usr/share/maven/ref/repositoryCOPY settings.xml /usr/share/maven/conf/settings.xml 执行容器命令启动 1docker run -d -p 10240:8080 -p 10241:50000 -v /root/test/jenkins:/var/jenkins_home -v /etc/localtime:/etc/localtime -v "/var/run/docker.sock:/var/run/docker.sock:rw" --name myjenkins f7b60faddb9e 4.5 运行的容器制作成镜像，以及镜像打包和推送到远程仓库12345678910111213141516171819202122232425262728293031323334353637383940#结尾添加"非安全的 IP地址\域名" vim /lib/systemd/system/docker.service...[Service]ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock --insecure-registry 192.168.1.102:5000或者,等效，只能配置其一/etc/docker/daemon.json&#123; "registry-mirrors": [ "https://docker.mirrors.ustc.edu.cn/", "https://1rlt72n0.mirror.aliyuncs.com", "https://registry.docker-cn.com", "http://hub-mirror.c.163.com", "https://docker.mirrors.ustc.edu.cn", "https://reg-mirror.qiniu.com", "https://dockerhub.azk8s.cn", "https://mirror.ccs.tencentyun.com" ], "insecure-registries": [ "192.168.1.102:5000" ], "dns" : [//dns可以配置私有dns "114.114.114.114" ]&#125;...systemctl daemon-reloadsystemctl restart docker#其他机器登录docker login 192.168.1.102:5000# 1.对于运行的容器打包成镜像使用commit命令docker commit -m '增加' 运行容器的名字 192.168.1.102:5000/dev/test:v2.0# 2.对于已存在的镜像打tag,以便推送到私有仓库上docker tag jenkins 192.168.1.102:5000/dev/jenkins:v2.0# 3.推送tag或者镜像文件到私有仓库上## 3.1登录私有仓库docker login -u admin -p admin 192.168.1.102:5000## 3.2推送镜像文件docker push 192.168.1.102:5000/dev/jenkins:v2.0 4.6 docker-compose安装grafana和prometheus12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152version: '2.1'networks: monitor-net: driver: bridgevolumes: prometheus_data: &#123;&#125; grafana_data: &#123;&#125;services: prometheus: image: prom/prometheus:v2.17.1 container_name: prometheus ports: - "9090:9090" volumes: - ./prometheus:/etc/prometheus - prometheus_data:/prometheus command: - '--config.file=/etc/prometheus/prometheus.yml' - '--storage.tsdb.path=/prometheus' - '--web.console.libraries=/etc/prometheus/console_libraries' - '--web.console.templates=/etc/prometheus/consoles' - '--storage.tsdb.retention.time=200h' - '--web.enable-lifecycle' restart: always expose: - 9090 networks: - monitor-net labels: org.label-schema.group: "monitoring" grafana: image: grafana/grafana:6.7.2 container_name: grafana ports: - "3000:3000" volumes: - grafana_data:/var/lib/grafana - ./grafana/provisioning:/etc/grafana/provisioning environment: - GF_SECURITY_ADMIN_USER=$&#123;ADMIN_USER&#125; - GF_SECURITY_ADMIN_PASSWORD=$&#123;ADMIN_PASSWORD&#125; - GF_USERS_ALLOW_SIGN_UP=false restart: always expose: - 3000 networks: - monitor-net labels: org.label-schema.group: "monitoring" 4.7 基于ubuntu机器学习的环境Dockerfile12345678910111213141516171819202122FROM ubuntu:21.10USER rootRUN ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtimeENV DEBIAN_FRONTEND=noninteractiveRUN sed -i s@/archive.ubuntu.com/@/mirrors.aliyun.com/@g /etc/apt/sources.listRUN apt-get cleanRUN apt-get updateRUN apt-get install ffmpeg libsm6 libxext6 wget make build-essential libssl-dev zlib1g-dev libbz2-dev \ libreadline-dev libsqlite3-dev wget curl llvm libncurses5-dev libncursesw5-dev \ xz-utils tk-dev libffi-dev liblzma-dev zlib1g-dev python3-distutils -yRUN wget https://www.python.org/ftp/python/3.8.0/Python-3.8.0.tgz --no-check-certificate \ &amp;&amp; tar -xf Python-3.8.0.tgz &amp;&amp; cd Python-3.8.0 &amp;&amp; ./configure --prefix=/usr/local/python3 --enable-optimizations \ &amp;&amp; make &amp;&amp; make installRUN wget https://bootstrap.pypa.io/get-pip.py &amp;&amp; python3 get-pip.pyRUN mkdir -p /opt/data/deploy/discernment_aiWORKDIR /opt/data/deploy/discernment_aiCOPY . .RUN pip3 install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simpleVOLUME /opt/data/deploy/discernment_aiEXPOSE 5003ENTRYPOINT ["python3","-u"]CMD ["app.py"] 4.8 已存在的容器调试方法有些三方的镜像已经被构建且没有构建相关的Dockerfile，但是我们又想调试可以尝试覆盖进入命令进行覆盖启动 别忘了同步修改暴露5005端口 1234#1.使用docker inspect获取启动的cmd或者Entrypoint命令docker inspect &lt;容器名称&gt; &gt;path_to_modified_json.json#2.更新容器的配置docker update --config &lt;path_to_modified_json&gt; &lt;container&gt; 还可以使用修改启动镜像命令的方式覆盖启动命令 123456789101112docker run -p 5005:5005 --entrypoint new-entrypoint.sh image_name或者直接修改docker-compose的entrypointservices: your_service: image: your_image entrypoint: - java - -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5005 - org.maxkey.MyApplication ports: - "9527:9527" - "5005:5005" 4.9 容器代理dockerd 设置网络代理 1234567mkdir -p /etc/systemd/system/docker.service.dvi /etc/systemd/system/docker.service.d/http-proxy.conf## 添加如下内容[Service]Environment="HTTP_PROXY=socks5://proxy.example.com:8080/"Environment="HTTPS_PROXY=socks5://proxy.example.com:8080/"Environment="NO_PROXY=localhost,127.0.0.1,.example.com" docker 容器设置网络代理 1234567891011121314vim ~/.docker/config.json# 第一种方式 添加如下内容&#123; "proxies": &#123; "default": &#123; "httpProxy": "socks5://proxy.example.com:8080/", "httpsProxy": "socks5://proxy.example.com:8080/", "noProxy": "localhost,127.0.0.1,.example.com" &#125; &#125;&#125;# 第二种方式通过启动容器时 --env HTTP_PROXY="http://proxy.example.com:8080/" 去设置代理 Docker客户端使用代理 12345678910#vim ~/.docker/config.json&#123; "proxies": &#123; "default": &#123; "httpProxy": "socks5://proxy.example.com:8080", "httpsProxy": "socks5://proxy.example.com:8080", "noProxy": "localhost,127.0.0.1" &#125; &#125;&#125; docker build 过程设置网络代理 1234567891011# 第一种方式启动时候指定变量docker build \ --build-arg "HTTP_PROXY=socks5://proxy.example.com:8080/" \ --build-arg "HTTPS_PROXY=socks5://proxy.example.com:8080/" \ --build-arg "NO_PROXY=localhost,127.0.0.1,.example.com" . # 第二种方式在Dockfile中添加变量# vim Dockfile添加如下变量内容ENV HTTP_PROXY="socks5://proxy.example.com:8080/"ENV HTTPS_PROXY="socks5://proxy.example.com:8080/"ENV NO_PROXY="localhost,127.0.0.1,.example.com" 5.大数据相关5.1 kafka相关 集群相关配置 zookeeper 12345678#重要配置，需要在此目录下生成myid文件,即为集群标记dataDir=/mnt/data/#zk链接端口clientPort=2181#集群id和集群ip配置server.0=ip1:2888:3888server.1=ip2:2888:3888server.2=ip3:2888:3888 kafka 12345678910#集群标记,每个需递增borker.id=1#日志文件log.dir=/mnt/data/kafka#配置zk集群zookeeper.connect=ip1:2181,ip2:2181,ip3:2181#配置端口port=9092#绑定机器host.name=ip 常用命令 1234567891011121314151617181920212223241.新建topicbin/kafka-topics.sh --create --zookeeper node:2181 --topic test --partitions 2 --replication-factor 12.修改partition数 只能增./bin/kafka-topics.sh --alter --topic test2 --zookeeper node:2181 --partitions 3 3.查看指定topicbin/kafka-topics.sh --zookeeper zookeeper01:2181 --describe --topic topic_test4.删除topicbin/kafka-topics.sh --delete --topic test --zookeeper node:21815.显示某个消费组的消费详情(CURRENT-OFFSET:已消费的,LOG-END-OFFSET:总数,LAG=LOG-END-OFFSET-CURRENT-OFFSET:堆积的消息)bin/kafka-consumer-groups.sh --new-consumer --bootstrap-server localhost:9092 --describe --group test-consumer-group6.消费者列表查询bin/kafka-topics.sh --zookeeper 127.0.0.1:2181 --list7.所有新消费者列表bin/kafka-consumer-groups.sh --new-consumer --bootstrap-server localhost:9092 --list8.查询集群描述bin/kafka-topics.sh --describe --zookeeper 9.从头开始消费bin/kafka-console-consumer.sh --zookeeper node:2181 --topic test --from-beginning10.获取主题(其分区)的最大偏移量bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list localhost:9092 --topic mytopic11.从尾开始消费指定分区指定消费个数kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic mytopic --offset 10 --partition 0 --max-messages 112.使用命令对指定topic发送kafka消息bin/kafka-console-producer.sh --broker-list 127.0.0.1:9092 --topic test 5.2 impala相关 12345678910111213141516171819202122常用修改操作: https://www.cnblogs.com/yhason/p/4724987.html1.查看表的文件分布show files in xxx;2.查看表的状态show table stats xxx;3.表基本描述describe xxx;4.查看表的见表语句show CREATE TABLE xxx;5.compute stats 为表收集重要的与性能相关的信息,以便被 Impala 用于优化查询6.更新 impalad 元数据中表的存在性与结构invalidate metadata7.刷新 impalad 元数据中 Impala 数据文件对应的 HDFS 块的位置refresh xxx;8.使用jar包查看parquet文件https://github.com/apache/parquet-mr/tree/master/parquet-tools?spm=5176.doc52798.2.6.H3s2kLhttp://logservice-resource.oss-cn-shanghai.aliyuncs.com/tools/parquet-tools-1.6.0rc3-SNAPSHOT.jar?spm=5176.doc52798.2.7.H3s2kL&amp;file=parquet-tools-1.6.0rc3-SNAPSHOT.jar查看结构：java -jar parquet-tools-1.6.0rc3-SNAPSHOT.jar schema -d activity.201711171437.0.parquet |head -n 30查看内容：java -jar parquet-tools-1.6.0rc3-SNAPSHOT.jar head -n 2 activity.201711171437.0.parquet 5.3 hdfs相关hadoop fs &lt;选项&gt; 建议使用hdfs dfs &lt;选项&gt; 选项名称 使用格式 含义 Example -ls -ls &lt;路径&gt; 查看指定路径的当前目录结构 hadoop fs -ls /input -lsr -lsr &lt;路径&gt; 递归查看指定路径的目录结构 hadoop fs -lsr / -du -du &lt;路径&gt; 统计目录下文件的大小 hadoop fs -du /input -dus -dus &lt;路径&gt; 汇总统计目录下文件和文件夹的大小 hadoop fs -du / -mv -mv &lt;源路径&gt; &lt;目的路径&gt; 移动或重命名 hadoop fs -mv /input /tmp -count -count [-q] &lt;路径&gt; 查询文件夹的磁盘空间限额和文件数目限额 hadoop fs -count -p /tmp -cp -cp &lt;源路径&gt; &lt;目的路径&gt; 复制文件(夹)到指定目录 hadoop fs -cp /one /two -put -put &lt;多个 Linux 上的文件&gt; 上传文件到 HDFS 中 hadoop fs -put ~/Downloads/abc.txt /two/one/ -copyFromLocal -copyFromLocal &lt;多个或单个 linux 上的文件&gt; 从本地复制文件到 HDFS hadoop fs -copyFromLocal ~/Downloads/1.txt /two -moveFromLocal -moveFromLocal &lt;多个或单个 linux 上的文件&gt; 从本地移动 hadoop fs -copyFromLocal ~/Downloads/2.txt /two -rm -rm [-skipTrash] &lt;路径&gt; 删除文件或空白文件夹, 加上 -skipTrash 删除不会放到回收站 hadoop -fs -rm -skipTrash /two/one/abc.txt -rmr -rmr [-skipTrash] &lt;路径&gt; 递归删除, 加上 -skipTrash 删除不会放到回收站 hadoop -fs -rmr -skipTrash /two/one -getmerge -getmerge &lt;源路径&gt; [addnl] 合并文件到本地, [addnl] 参数实在每一个文件末尾添加一个换行符 hadoop fs -getmerge /two/*.txt ~/Down addnl -cat -cat 查看文件内容 hadoop fs -cat /input/abc.txt -text -text 查看文件或者 zip 的内容 hadoop fs -text /input/abc.txt -copyToLocal -copyToLocal [-ignoreCrc] [-crc] [hdfs 源路径] [linux 目的路径] 从 hdfs 向本地复制 hadoop fs -copyToLocal /input/* ~/Downloads -moveToLocal -moveToLocal [-crc] 从 hdfs 向本地移动 hdfs dfs -moveToLocal /input/* ~/Downloads -mkdir -mkdir 创建空白文件夹 hadoop fs -mkdir /666 -setrep -setrp [-R] [-w] &lt;副本数&gt; &lt;路径&gt; 修改文件的副本系数。-R选项用于递归改变目录下所有文件的副本系数 hadoop fs -setrep -R -w 3 /user/hadoop/dir -touchz -touchz &lt;文件路径&gt; 创建空白文件 hadoop fs -touchz /666/999.log -stat -stat [format] &lt;路径&gt; 显示文件统计信息 hadoop fs -stat path -tail -tail [-f] &lt;文件&gt; 查看文件尾部信息 hadoop fs -tail pathname -chmod -chmod [-R] &lt;权限模式&gt; [路径] 修改权限 hadoop fs -chmod -R 777 /input -chown -chown [-R] [属主]] 路径 修改属主 hadoop fs -chown -R hadoop0 /input -chgrp -chgrp [-R] 属组名称 路径 修改属组 hadoop fs -chgrp -R root /flume -help -help [命令选项] 查看帮助 hadoop fs -help 6.Java相关6.1 maven插件maven-shade-plugin支持将开源包直接改package名称解决类冲突6.1.1 排除不使用的类1234567891011121314151617181920&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt; &lt;version&gt;3.1.1&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;shade&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;minimizeJar&gt;true&lt;/minimizeJar&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 6.1.2 将依赖的类重命名并打包进来 （隔离方案）1234567891011121314151617181920212223242526272829303132&lt;!--将“org.codehaus.plexus.util”重命名为“org.shaded.plexus.util”，原始jar包中的“org.codehaus.plexus.util.xml.Xpp3Dom”和“org.codehaus.plexus.util.xml.pull”不会被重命名到目的包中；--&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt; &lt;version&gt;3.1.1&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;shade&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;relocations&gt; &lt;relocation&gt; &lt;pattern&gt;org.codehaus.plexus.util&lt;/pattern&gt; &lt;shadedPattern&gt;org.shaded.plexus.util&lt;/shadedPattern&gt; &lt;excludes&gt; &lt;exclude&gt;org.codehaus.plexus.util.xml.Xpp3Dom&lt;/exclude&gt; &lt;exclude&gt;org.codehaus.plexus.util.xml.pull.*&lt;/exclude&gt; &lt;/excludes&gt; &lt;/relocation&gt; &lt;/relocations&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 6.1.3 Java执行单个编译类包括依赖比如，需要执行Simple.class以及其依赖包xxxa.jar以及xxxb.jar 1java -cp .:xxxa.jar;d:\classes\*.jar Simple 6.2 Java VisualVM 远程调试 创建all.policy文件 12345cat &gt; all.policy &lt;&lt;EOFgrant codebase "file:$&#123;java.home&#125;/../lib/tools.jar" &#123;permission java.security.AllPermission;&#125;;EOF 服务器端启动 1jstatd -J-Djava.security.policy=all.policy 打开 Java VisualVM 文件&gt;添加远程主机 填入服务端IP 6.3 springboot的可执行jar不能替换lib目录下jar文件12springboot项目在使用压缩软件替换lib下的依赖包后，启动报错​Exception in thread "main" java.lang.IllegalStateException: Failed to get nested archive for entry BOOT-INF/lib/xxx 原因是:替换或者导入jar包时，jar包被自动压缩，springboot规定嵌套的jar包不能在被压缩的情况下存储。需要使用jar命令解压jar包，在压缩包外重新替换jar包，在进行压缩。 123456#1.解压springboot的可执行jarjar -xvf *.jar#2.替换相关依赖lib目录下的jarmv xxx BOOT-INF/lib/#3.重新压缩jarjar -cfM0 new.jar BOOT-INF/ META-INF/ org/ xxx 6.4 cpu100%线上排查 线程CPU100%可能导致的原因 https://www.cnblogs.com/jajian/p/10578628.html 123456789101112131415161718192021222324252627282930313233#找出消耗cpu最高的线程top #找到占用最高的进程top -H -p pid #找到占用最高进程的最高线程printf "%x\n" tid #将占用最高的线程id转换为16进制#打印jvm线程信息并查看占用CPU最高的线程执行了什么代码jstack pid&gt;stack.txt #保留现场cat stack.txt|grep 十六进制的tid #查看线程忙什么jstack pid |grep tid -A 50 #查询忙线程执行什么#每秒打印GC日志查看gc情况jstat -gcutil pid 1000#dump jvm内存信息,并使用MAT进行分析jmap -dump:format=b,file=./java.dump pid#查看队内存情况和使用的垃圾回收器jmap -heap pid#打印垃圾回收日志-XX:+PrintGCDetails-XX:+PrintGCDateStamps-XX:+PrintTenuringDistribution-XX:+PrintHeapAtGC-XX:+PrintReferenceGC-XX:+PrintGCApplicationStoppedTime-Xloggc:/data/gc-%t.log#使用G1垃圾回收器-XX:+UseG1GC-XX:MaxGCPauseMillis=500-XX:-TieredCompilation-XX:ReservedCodeCacheSize=128m-XX:+UseCodeCacheFlushing#G1常用参数，和介绍https://blog.csdn.net/Megustas_JJC/article/details/105470675https://www.cnblogs.com/klvchen/articles/11672058.html 6.5 git使用代理如果仅设置当前项目的git代理需要在当前项目目录进入命令行，如果需要设置全局git代理，需要在每个git config 命令后加上 –global 123456789#代理git config http.proxy http://192.168.15.40:3128git config https.proxy https://192.168.15.40:3128#取消代理git config --unset http.proxygit config --unset https.proxy#查询是否使用git config http.proxy git config https.proxy 7.中间件7.1 fastdfs扩容Ⅰ.扩容基于goup的store_path进行扩容,扩充group的存储空间，配置多个存储文件目录地址 123456789101112131415161718192021222324252627282930313233343536# 1.停止现有的tracker服务，fdfs_nginx，storage服务。# 2.挂载新的磁盘（过程略）# 3.修改tracker.conf配置文件vi /etc/fdfs/tracker.conf#修改以下参数为2，上传时选择路径规则。（取值只有0和2。0：轮询（默认）；2：负载均衡，选择可用空间最大的文件夹）store_path=2# 4.修改storage.conf配置文件vi /etc/fdfs/storage.conf#将以下参数值改为2store_path_count=2 #新增存储路径store_path1(必须存在的路径，需提前手动创建 mkdir -p /data/fastdfs)store_path1=/data/fastdfs# 5.修改mod_fastdfs.conf配置文件vi /etc/fdfs/mod_fastdfs.conf#修改以下参数为2store_path_count=2#新增存储路径store_path1store_path1=/data/fastdfs（同storage.conf 一致）# 6.启动tracker，storage服务#7.查看状态fdfs_monitor /etc/fdfs/client.conf# 8.修改nginx.conf配置文件并重载nginxvi /usr/local/nginx/conf/nginx.conf# 添加store_path1的路径location ~/group[0-9]/M00 &#123; alias /opt/fastdfs/data/; ngx_fastdfs_module; &#125;location ~/group[0-9]/M01 &#123; alias /data/fastdfs/data/; ngx_fastdfs_module; &#125;#dfs_nginx加载配置文件nginx -s reload# 9.测试上传/usr/bin/fdfs_test /etc/fdfs/client.conf upload test.txt Ⅱ.扩容新的goup,扩充存储节点，新加服务器配置多个storage 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#背景,xx.1 xx.2作为tracker,xx.3,xx.4作为storage两个从属group1,新增一台storage xx.5为group2# 1.停止现有的tracker服务，fdfs_nginx，storage服务。# 2.新的机器装新的storage（过程略）# 3.修改xx.1 xx.2的tracker.conf配置文件vi /etc/fdfs/tracker.conf# the method of selecting group to upload files# 0: group组负载均衡，1: 指定组 2: 负载均衡，选择可用空间最大groupstore_lookup=1# which group to upload file# when store_lookup set to 1, must set store_group to the group namestore_group=group2# 4.修改xx.5 storage.conf配置文件vi /etc/fdfs/storage.conf#指定之前的xx.1 xx.2的tracker地址和端口tracker_server=x.x.1:22122tracker_server=x.x.2:22122group_name=group2# 5.修改xx.5 mod_fastdfs.conf配置文件vi /etc/fdfs/mod_fastdfs.conf#指定之前的xx.1 xx.2的tracker地址和端口tracker_server=x.x.1:22122tracker_server=x.x.2:22122url_have_group_name=truegroup_name=group2group_count=1[group2]group_name=group2# 6.启动tracker，storage服务#7.查看状态fdfs_monitor /etc/fdfs/client.conf# 8.修改修改xx.5 fds的nginx.conf配置文件并重载nginxvi /usr/local/nginx/conf/nginx.conf# 添加store_path1的路径location ~/group[0-9]/M00 &#123; alias /opt/fastdfs/data/; ngx_fastdfs_module; &#125;#dfs_nginx加载配置文件nginx -s reload# 9.测试上传/usr/bin/fdfs_test /etc/fdfs/client.conf upload test.txt 8.其他杂项相关8.1 log日志最优格式化以及配置每日文件滚动:123456log4j.rootLogger=INFO,stdout,fileAppenderlog4j.appender.fileAppender=org.apache.log4j.DailyRollingFileAppenderlog4j.appender.fileAppender.DatePattern=&apos;.&apos;yyyy-MM-ddlog4j.appender.fileAppender.File=/opt/config/fileAppender.loglog4j.appender.fileAppender.layout=org.apache.log4j.PatternLayoutlog4j.appender.fileAppender.layout.ConversionPattern=[%p][%t]%-d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125;: (%c&#123;1&#125;.%M:line %L) - %m%n 8.2 关于断电1.客户端向服务端发送写操作（数据在客户端的内存中）2.数据库服务端接收到写请求的数据（数据在服务端的内存中）3.服务端调用write这个系统调用，将数据往磁盘上写（数据在系统内存的缓冲区中）4.操作系统将缓冲区中的数据转移到磁盘控制器上（数据在磁盘缓存中）5.磁盘控制器将数据写到磁盘的物理介质中（数据真正落到磁盘上） 当数据库系统故障时，这时候系统内核还是正常运行的，此时只要执行完了第3步，数据就是安全的，操作系统会完成后面几步，保证数据最终会落到磁盘上。 当系统断电，这时候上面5项中提到的所有缓存都会失效，并且数据库和操作系统都会停止工作，数据都会丢失，只有当数据在完成第5步后，机器断电才能保证数据不丢失。 8.3 流媒体服务器SRS拉取摄像头流并推流12345678#容器部署SRSdocker run --rm -it -p 1935:1935 -p 1985:1985 -p 8080:8080 registry.cn-hangzhou.aliyuncs.com/ossrs/srs:latest ./objs/srs -c conf/docker.conf#同机器容器使用ffmpeg拉取摄像头流并推送给本机SRS流服务docker run --network host --rm -it -v $(pwd):/config linuxserver/ffmpeg -rtsp_transport tcp -i rtsp://xx:xx@ip:554/h264/ch33/main/av_stream -acodec aac -strict experimental -ar 44100 -ac 2 -b:a 96k -r 25 -b:v 500k -s 640*480 -f flv rtmp://127.0.0.1/live/livestream#客户端可以访问路径RTMP (by VLC): rtmp://srsip/live/livestreamH5(HTTP-FLV): http://srsip:8080/live/livestream.flvH5(HLS): http://srsip:8080/live/livestream.m3u8]]></content>
      <tags>
        <tag>杂项</tag>
        <tag>记录</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring扩展点]]></title>
    <url>%2F2020%2F10%2F13%2Fsenssic.github.io%2F202010%2Fspring%E6%89%A9%E5%B1%95%E7%82%B9%2F</url>
    <content type="text"><![CDATA[0.调用顺序图 1.ApplicationContextInitializerspring容器在刷新之前初始化ConfigurableApplicationContext的回调接口,可以在容器未初始化之前做一些事情。 因为这时候spring容器还没被初始化，所以想要自己的扩展的生效，有以下三种方式： 1.启动类中增加SpringApplication.addInitializers(new TestApplicationContextInitializer())2.配置文件配置context.initializer.classes=com.example.demo.TestApplicationContextInitializer3.Spring SPI扩展，在spring.factories中加入org.springframework.context.ApplicationContextInitializer=com.example.demo.TestApplicationContextInitializer 2.BeanDefinitionRegistryPostProcessor读取项目中的beanDefinition之后执行,你可以在这里动态注册自己的beanDefinition，可以加载classpath之外的bean. 3.BeanFactoryPostProcessor调用时机在spring在读取beanDefinition信息之后，实例化bean之前。在这个时机，用户可以通过实现这个扩展接口来自行处理一些东西，比如修改已经注册的beanDefinition的元信息。 4.InstantiationAwareBeanPostProcessorp[postProcessBeforeInstantiation]BeanPostProcess接口只在bean的初始化阶段进行扩展（注入spring上下文前后），而InstantiationAwareBeanPostProcessor接口在此基础上增加了3个方法，把可扩展的范围增加了实例化阶段和属性注入阶段。 该类主要的扩展点有以下5个方法，主要在bean生命周期的两大阶段：实例化阶段和初始化阶段，下面一起进行说明，按调用顺序为： postProcessBeforeInstantiation：实例化bean之前，相当于new这个bean之前postProcessAfterInstantiation：实例化bean之后，相当于new这个bean之后postProcessPropertyValues：bean已经实例化完成，在属性注入时阶段触发，@Autowired,@Resource等注解原理基于此方法实现postProcessBeforeInitialization：初始化bean之前，相当于把bean注入spring上下文之前postProcessAfterInitialization：初始化bean之后，相当于把bean注入spring上下文之后使用场景：这个扩展点非常有用 ，无论是写中间件和业务中，都能利用这个特性。比如对实现了某一类接口的bean在各个生命期间进行收集，或者对某个类型的bean进行统一的设值等等。 5.SmartInstantiationAwareBeanPostProcessor该接口提供三个触发扩展点: predictBeanType：该触发点发生在postProcessBeforeInstantiation之前(在图上并没有标明，因为一般不太需要扩展这个点)，这个方法用于预测Bean的类型，返回第一个预测成功的Class类型，如果不能预测返回null；当你调用BeanFactory.getType(name)时当通过bean的名字无法得到bean类型信息时就调用该回调方法来决定类型信息。 determineCandidateConstructors：该触发点发生在postProcessBeforeInstantiation之后，用于确定该bean的构造函数之用，返回的是该bean的所有构造函数列表。用户可以扩展这个点，来自定义选择相应的构造器来实例化这个bean。 getEarlyBeanReference：该触发点发生在postProcessAfterInstantiation之后，当有循环依赖的场景，当bean实例化好之后，为了防止有循环依赖，会提前暴露回调方法，用于bean实例化的后置处理。这个方法就是在提前暴露的回调方法中触发。 6.BeanFactoryAware发生在bean的实例化之后，注入属性之前，也就是Setter之前。这个类的扩展点方法为setBeanFactory，可以拿到BeanFactory这个属性。 使用场景为，你可以在bean实例化之后，但还未初始化之前，拿到 BeanFactory，在这个时候，可以对每个bean作特殊化的定制。也或者可以把BeanFactory拿到进行缓存，日后使用. 7.ApplicationContextAwareProcessor该类本身并没有扩展点，该类内部却有6个扩展点可供实现 ，这些类触发的时机在bean实例化之后，初始化之前. 在bean实例化之后，属性填充之后，通过执行以上红框标出的扩展接口，来获取对应容器的变量。 EnvironmentAware：用于获取EnviromentAware的一个扩展类，这个变量非常有用， 可以获得系统内的所有参数。当然个人认为这个Aware没必要去扩展，因为spring内部都可以通过注入的方式来直接获得。 EmbeddedValueResolverAware：用于获取StringValueResolver的一个扩展类， StringValueResolver用于获取基于String类型的properties的变量，一般我们都用@Value的方式去获取，如果实现了这个Aware接口，把StringValueResolver缓存起来，通过这个类去获取String类型的变量，效果是一样的。 ResourceLoaderAware：用于获取ResourceLoader的一个扩展类，ResourceLoader可以用于获取classpath内所有的资源对象，可以扩展此类来拿到ResourceLoader对象。 ApplicationEventPublisherAware：用于获取ApplicationEventPublisher的一个扩展类，ApplicationEventPublisher可以用来发布事件，结合ApplicationListener来共同使用，下文在介绍ApplicationListener时会详细提到。这个对象也可以通过spring注入的方式来获得。 MessageSourceAware：用于获取MessageSource的一个扩展类，MessageSource主要用来做国际化。 ApplicationContextAware：用来获取ApplicationContext的一个扩展类，ApplicationContext应该是很多人非常熟悉的一个类了，就是spring上下文管理器，可以手动的获取任何在spring上下文注册的bean，我们经常扩展这个接口来缓存spring上下文，包装成静态方法。同时ApplicationContext也实现了BeanFactory，MessageSource，ApplicationEventPublisher等接口，也可以用来做相关接口的事情。 8.BeanNameAware这个类也是Aware扩展的一种，触发点在bean的初始化之前，也就是postProcessBeforeInitialization之前，这个类的触发点方法只有一个：setBeanName 使用场景为：用户可以扩展这个点，在初始化bean之前拿到spring容器中注册的的beanName，来自行修改这个beanName的值。 9.@PostConstruct其实就是一个标注。其作用是在bean的初始化阶段，如果对一个方法标注了@PostConstruct，会先调用这个方法。这里重点是要关注下这个标准的触发点，这个触发点是在postProcessBeforeInitialization之后，InitializingBean.afterPropertiesSet之前。 使用场景：用户可以对某一方法进行标注，来进行初始化某一个属性。 10.InitializingBeanInitializingBean接口为bean提供了初始化方法的方式，它只包括afterPropertiesSet方法，凡是继承该接口的类，在初始化bean的时候都会执行该方法。这个扩展点的触发时机在postProcessAfterInitialization之前。 使用场景：用户实现此接口，来进行系统启动的时候一些业务指标的初始化工作。 11.FactoryBean一般情况下，Spring通过反射机制利用bean的class属性指定支线类去实例化bean，在某些情况下，实例化Bean过程比较复杂，如果按照传统的方式，则需要在bean中提供大量的配置信息。配置方式的灵活性是受限的，这时采用编码的方式可能会得到一个简单的方案。Spring为此提供了一个org.springframework.bean.factory.FactoryBean的工厂类接口，用户可以通过实现该接口定制实例化Bean的逻辑。FactoryBean接口对于Spring框架来说占用重要的地位，Spring自身就提供了70多个FactoryBean的实现。它们隐藏了实例化一些复杂bean的细节，给上层应用带来了便利。从Spring3.0开始，FactoryBean开始支持泛型，即接口声明改为FactoryBean的形式 使用场景：用户可以扩展这个类，来为要实例化的bean作一个代理，比如为该对象的所有的方法作一个拦截，在调用前后输出一行log，模仿ProxyFactoryBean的功能。 12.SmartInitializingSingleton这个接口中只有一个方法afterSingletonsInstantiated，其作用是是 在spring容器管理的所有单例对象（非懒加载对象）初始化完成之后调用的回调接口。其触发时机为postProcessAfterInitialization之后。 使用场景：用户可以扩展此接口在对所有单例对象初始化完毕后，做一些后置的业务处理。 13.CommandLineRunnerrun(String… args)，触发时机为整个项目启动完毕后，自动执行。如果有多个CommandLineRunner，可以利用@Order来进行排序。 使用场景：用户扩展此接口，进行启动项目之后一些业务的预处理。 14.DisposableBean扩展点只有一个方法：destroy()，其触发时机为当此对象销毁时，会自动执行这个方法。比如说运行applicationContext.registerShutdownHook时，就会触发这个方法。 15.ApplicationListener准确的说，这个应该不算spring&amp;springboot当中的一个扩展点，ApplicationListener可以监听某个事件的event，触发时机可以穿插在业务方法执行过程中，用户可以自定义某个业务事件。但是spring内部也有一些内置事件，这种事件，可以穿插在启动调用中。我们也可以利用这个特性，来自己做一些内置事件的监听器来达到和前面一些触发点大致相同的事情。 ContextRefreshedEvent ApplicationContext 被初始化或刷新时，该事件被发布。这也可以在ConfigurableApplicationContext接口中使用 refresh()方法来发生。此处的初始化是指：所有的Bean被成功装载，后处理Bean被检测并激活，所有Singleton Bean 被预实例化，ApplicationContext容器已就绪可用。 ContextStartedEvent 当使用 ConfigurableApplicationContext （ApplicationContext子接口）接口中的 start() 方法启动 ApplicationContext时，该事件被发布。你可以调查你的数据库，或者你可以在接受到这个事件后重启任何停止的应用程序。 ContextStoppedEvent 当使用 ConfigurableApplicationContext接口中的 stop()停止ApplicationContext 时，发布这个事件。你可以在接受到这个事件后做必要的清理的工作 ContextClosedEvent 当使用 ConfigurableApplicationContext接口中的 close()方法关闭 ApplicationContext 时，该事件被发布。一个已关闭的上下文到达生命周期末端；它不能被刷新或重启 RequestHandledEvent 这是一个 web-specific 事件，告诉所有 bean HTTP 请求已经被服务。只能应用于使用DispatcherServlet的Web应用。在使用Spring作为前端的MVC控制器时，当Spring处理用户请求结束后，系统会自动触发该事件 Springboot启动扩展点超详细总结]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring和springboot主要注解]]></title>
    <url>%2F2019%2F02%2F26%2Fsenssic.github.io%2F201902%2Fspring%E5%92%8Cspringboot%E4%B8%BB%E8%A6%81%E6%B3%A8%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[spring注解1.声明bean的注解@Component 组件，没有明确的角色 @Service 在业务逻辑层使用（service层） @Repository 在数据访问层使用（dao层） @Controller 在展现层使用，控制器的声明（C） 2.注入bean的注解@Autowired：由Spring提供 @Inject：由JSR-330提供 @Resource：由JSR-250提供 都可以注解在set方法和属性上，推荐注解在属性上（一目了然，少写代码）。 3.java配置类相关注解@Configuration 声明当前类为配置类，相当于xml形式的Spring配置（类上） @Bean 注解在方法上，声明当前方法的返回值为一个bean，替代xml中的方式（方法上） @Configuration 声明当前类为配置类，其中内部组合了@Component注解，表明这个类是一个bean（类上） @ComponentScan 用于对Component进行扫描，相当于xml中的（类上） @WishlyConfiguration 为@Configuration与@ComponentScan的组合注解，可以替代这两个注解 4.切面（AOP）相关注解Spring支持AspectJ的注解式切面编程。 @Aspect 声明一个切面（类上）使用@After、@Before、@Around定义建言（advice），可直接将拦截规则（切点）作为参数。 @After 在方法执行之后执行（方法上）@Before 在方法执行之前执行（方法上）@Around 在方法执行之前与之后执行（方法上） @PointCut 声明切点在java配置类中使用@EnableAspectJAutoProxy注解开启Spring对AspectJ代理的支持（类上） 5.@Bean的属性支持@Scope 设置Spring容器如何新建Bean实例（方法上，得有@Bean）其设置类型包括： Singleton （单例,一个Spring容器中只有一个bean实例，默认模式）,Protetype （每次调用新建一个bean）,Request （web项目中，给每个http request新建一个bean）,Session （web项目中，给每个http session新建一个bean）,GlobalSession（给每一个 global http session新建一个Bean实例） @StepScope 在Spring Batch中还有涉及 @PostConstruct 由JSR-250提供，在构造函数执行完之后执行，等价于xml配置文件中bean的initMethod @PreDestory 由JSR-250提供，在Bean销毁之前执行，等价于xml配置文件中bean的destroyMethod 6.@Value注解@Value 为属性注入值（属性上）支持如下方式的注入：》注入普通字符 @Value(“Michael Jackson”)String name; 》注入操作系统属性 @Value(“#{systemProperties[‘os.name’]}”)String osName; 》注入表达式结果 @Value(“#{ T(java.lang.Math).random() * 100 }”) String randomNumber; 》注入其它bean属性 @Value(“#{domeClass.name}”)String name; 》注入文件资源 @Value(“classpath:com/hgs/hello/test.txt”)String Resource file; 》注入网站资源 @Value(“http://www.javastack.cn&quot;)Resource url; 》注入配置文件 Value(“${book.name}”)String bookName; 注入配置使用方法：① 编写配置文件（test.properties） book.name=《三体》 ② @PropertySource 加载配置文件(类上) @PropertySource(“classpath:com/hgs/hello/test/test.propertie”) ③ 还需配置一个PropertySourcesPlaceholderConfigurer的bean。 7.环境切换@Profile 通过设定Environment的ActiveProfiles来设定当前context需要使用的配置环境。（类或方法上） @Conditional Spring4中可以使用此注解定义条件话的bean，通过实现Condition接口，并重写matches方法，从而决定该bean是否被实例化。（方法上） 8.异步相关@EnableAsync 配置类中，通过此注解开启对异步任务的支持，叙事性AsyncConfigurer接口（类上），点击这里了解使用详情。 @Async 在实际执行的bean方法使用该注解来申明其是一个异步任务（方法上或类上所有的方法都将异步，需要@EnableAsync开启异步任务） 9.定时任务相关@EnableScheduling 在配置类上使用，开启计划任务的支持（类上） @Scheduled 来申明这是一个任务，包括cron,fixDelay,fixRate等类型（方法上，需先开启计划任务的支持） 10.@Enable*注解说明这些注解主要用来开启对xxx的支持。@EnableAspectJAutoProxy 开启对AspectJ自动代理的支持 @EnableAsync 开启异步方法的支持 @EnableScheduling 开启计划任务的支持 @EnableWebMvc 开启Web MVC的配置支持 @EnableConfigurationProperties 开启对@ConfigurationProperties注解配置Bean的支持 @EnableJpaRepositories 开启对SpringData JPA Repository的支持 @EnableTransactionManagement 开启注解式事务的支持 @EnableTransactionManagement 开启注解式事务的支持 @EnableCaching 开启注解式的缓存支持 11.测试相关注解@RunWith 运行器，Spring中通常用于对JUnit的支持 @RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration 用来加载配置ApplicationContext，其中classes属性用来加载配置类 @ContextConfiguration(classes={TestConfig.class}) 12.SpringMVC相关注解@EnableWebMvc 在配置类中开启Web MVC的配置支持，如一些ViewResolver或者MessageConverter等，若无此句，重写WebMvcConfigurerAdapter方法（用于对SpringMVC的配置）。 @Controller 声明该类为SpringMVC中的Controller @RequestMapping 用于映射Web请求，包括访问路径和参数（类或方法上） @ResponseBody 支持将返回值放在response内，而不是一个页面，通常用户返回json数据（返回值旁或方法上） @RequestBody 允许request的参数在request体中，而不是在直接连接在地址后面。（放在参数前） @PathVariable 用于接收路径参数，比如@RequestMapping(“/hello/{name}”)申明的路径，将注解放在参数中前，即可获取该值，通常作为Restful的接口实现方法。 @RestController 该注解为一个组合注解，相当于@Controller和@ResponseBody的组合，注解在类上，意味着，该Controller的所有方法都默认加上了@ResponseBody。 @ControllerAdvice 通过该注解，我们可以将对于控制器的全局配置放置在同一个位置，注解了@Controller的类的方法可使用@ExceptionHandler、@InitBinder、@ModelAttribute注解到方法上，这对所有注解了 @RequestMapping的控制器内的方法有效。 @ExceptionHandler 用于全局处理控制器里的异常 @InitBinder 用来设置WebDataBinder，WebDataBinder用来自动绑定前台请求参数到Model中。 @ModelAttribute 本来的作用是绑定键值对到Model里，在@ControllerAdvice中是让全局的@RequestMapping都能获得在此处设置的键值对。 springboot相关1、@SpringBootApplication 这是 Spring Boot 最最最核心的注解，用在 Spring Boot 主类上，标识这是一个 Spring Boot 应用，用来开启 Spring Boot 的各项能力。 其实这个注解就是 @SpringBootConfiguration、@EnableAutoConfiguration、@ComponentScan 这三个注解的组合，也可以用这三个注解来代替 @SpringBootApplication 注解。 2、@EnableAutoConfiguration 允许 Spring Boot 自动配置注解，开启这个注解之后，Spring Boot 就能根据当前类路径下的包或者类来配置 Spring Bean。 如：当前类路径下有 Mybatis 这个 JAR 包，MybatisAutoConfiguration 注解就能根据相关参数来配置 Mybatis 的各个 Spring Bean。 3、@Configuration 这是 Spring 3.0 添加的一个注解，用来代替 applicationContext.xml 配置文件，所有这个配置文件里面能做到的事情都可以通过这个注解所在类来进行注册。 4、@SpringBootConfiguration 这个注解就是 @Configuration 注解的变体，只是用来修饰是 Spring Boot 配置而已，或者可利于 Spring Boot 后续的扩展。 5、@ComponentScan 这是 Spring 3.1 添加的一个注解，用来代替配置文件中的 component-scan 配置，开启组件扫描，即自动扫描包路径下的 @Component 注解进行注册 bean 实例到 context 中。 前面 5 个注解可以在这篇文章《Spring Boot 最核心的 3 个注解详解》中了解更多细节的。 6、@Conditional 这是 Spring 4.0 添加的新注解，用来标识一个 Spring Bean 或者 Configuration 配置文件，当满足指定的条件才开启配置。 7、@ConditionalOnBean 组合 @Conditional 注解，当容器中有指定的 Bean 才开启配置。 8、@ConditionalOnMissingBean 组合 @Conditional 注解，和 @ConditionalOnBean 注解相反，当容器中没有指定的 Bean 才开启配置。 9、@ConditionalOnClass 组合 @Conditional 注解，当容器中有指定的 Class 才开启配置。 10、@ConditionalOnMissingClass 组合 @Conditional 注解，和 @ConditionalOnMissingClass 注解相反，当容器中没有指定的 Class 才开启配置。 11、@ConditionalOnWebApplication 组合 @Conditional 注解，当前项目类型是 WEB 项目才开启配置。 当前项目有以下 3 种类型。 123456789101112131415161718enum Type &#123; /** * Any web application will match. */ ANY, /** * Only servlet-based web application will match. */ SERVLET, /** * Only reactive-based web application will match. */ REACTIVE&#125; 12、@ConditionalOnNotWebApplication 组合 @Conditional 注解，和 @ConditionalOnWebApplication 注解相反，当前项目类型不是 WEB 项目才开启配置。 13、@ConditionalOnProperty 组合 @Conditional 注解，当指定的属性有指定的值时才开启配置。 14、@ConditionalOnExpression 组合 @Conditional 注解，当 SpEL 表达式为 true 时才开启配置。 15、@ConditionalOnJava 组合 @Conditional 注解，当运行的 Java JVM 在指定的版本范围时才开启配置。 16、@ConditionalOnResource 组合 @Conditional 注解，当类路径下有指定的资源才开启配置。 17、@ConditionalOnJndi 组合 @Conditional 注解，当指定的 JNDI 存在时才开启配置。 18、@ConditionalOnCloudPlatform 组合 @Conditional 注解，当指定的云平台激活时才开启配置。 19、@ConditionalOnSingleCandidate 组合 @Conditional 注解，当指定的 class 在容器中只有一个 Bean，或者同时有多个但为首选时才开启配置。 20、@ConfigurationProperties 用来加载额外的配置（如 .properties 文件），可用在 @Configuration 注解类，或者 @Bean 注解方法上面。 关于这个注解的用法可以参考《Spring Boot读取配置的几种方式》这篇文章。 21、@EnableConfigurationProperties 一般要配合 @ConfigurationProperties 注解使用，用来开启对 @ConfigurationProperties 注解配置 Bean 的支持。 22、@AutoConfigureAfter 用在自动配置类上面，表示该自动配置类需要在另外指定的自动配置类配置完之后。 如 Mybatis 的自动配置类，需要在数据源自动配置类之后。 12@AutoConfigureAfter(DataSourceAutoConfiguration.class)public class MybatisAutoConfiguration &#123; 23、@AutoConfigureBefore 这个和 @AutoConfigureAfter 注解使用相反，表示该自动配置类需要在另外指定的自动配置类配置之前。 24、@Import 这是 Spring 3.0 添加的新注解，用来导入一个或者多个 @Configuration 注解修饰的类，这在 Spring Boot 里面应用很多。 25、@ImportResource 这是 Spring 3.0 添加的新注解，用来导入一个或者多个 Spring 配置文件，这对 Spring Boot 兼容老项目非常有用，因为有些配置无法通过 Java Config 的形式来配置就只能用这个注解来导入。 springcloud相关1.@EnableEurekaServer:用在springboot启动类上，表示这是一个eureka服务注册中心； 2.@EnableDiscoveryClient:用在springboot启动类上，表示这是一个服务，可以被注册中心找到； 3.@LoadBalanced:开启负载均衡能力； 4.@EnableCircuitBreaker:用在启动类上，开启断路器功能； 5.@HystrixCommand(fallbackMethod=”backMethod”):用在方法上，fallbackMethod指定断路回调方法； 6.@EnableConfigServer:用在启动类上，表示这是一个配置中心，开启Config Server； 7.@EnableZuulProxy:开启zuul路由，用在启动类上； 8.@SpringCloudApplication:包含@SpringBootApplication、@EnableDiscoveryClient、@EnableCircuitBreaker这三个注解。 呜谢spring注解大全 springboot注解详解]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java并发包]]></title>
    <url>%2F2019%2F02%2F19%2Fsenssic.github.io%2F201902%2Fjava%E5%B9%B6%E5%8F%91%E5%8C%85%2F</url>
    <content type="text"><![CDATA[JAVA并发包简介J.U.C框架是jdk1.5引入的。主要包含： Executor框架(线程池,Callable,Future),任务的执行和调度框架; AbstractQueueSynchronizer(AQS框架),并发包中实现锁和同步机制的基础,AQS的以CAS和volatile为基础实现的; Locks&amp;Condition(锁和条件变量),比synchronized,wait,notify更方便和强大的锁机制； Synchronizers(同步器),主要用于协助线程同步,有CountDownLatch(闭锁),CyclicBarrier(栅栏),Semaphore(信号量),Exchanger(交换器); Atomic Variables(原子变量),方便在多线程环境下无锁进行原子操作。 BlockingQueue(阻塞队列),如果队列满则入队操作将阻塞知道有空间可用,如果阻塞队列空了,则出队操作将阻塞直到有元素可用; Concurrent Collections(并发容器),主要为ConcurrentHashMap、CopyOnWriteArrayList。 Fork/Join并行计算框架,JDK1.7引入,方便利用多核平台计算能力,简化并行程序的编写。 TimeUnit枚举,提供可读性更好的线程暂停操作,以及方便的时间单位转换的方法; Executor 框架 callable接口12345678910@FunctionalInterfacepublic interface Callable&lt;V&gt; &#123; /** * Computes a result, or throws an exception if unable to do so. * * @return computed result * @throws Exception if unable to compute a result */ V call() throws Exception;&#125; 在jdk5之前我们只有一个Runnable接口,用来定义任务。但是Runnable接口的run()方法是没有返回值的,也不能抛出检查异常,有时候会不方便。 现在可以用Callable接口,可以抛出检查异常以及通过ExecutorService 去执行ExecutorService.submit() 方法将返回一个 Future 对象（待完成的任务结果对象），Future.get() 方法可获取结果。 Future接口Future表示异步任务的结果,Future提供了异步任务查询,任务取消,获取任务结果等方法； 1234567891011121314151617public interface Future&lt;V&gt; &#123; /** * 用于尝试取消当前任务. * 如果任务已开始，并且 mayInterruptIfRunning 为 true，则给任务发送中断信号，否则任务将继续执行 * 此调用返回后，后续的 isDone() 始终返回 true；如果此调用返回 true，则后续的 isCancelled() 始终返回 true */ boolean cancel(boolean mayInterruptIfRunning); /* 任务是否已被取消 */ boolean isCancelled(); /* 任务是否已完成 */ boolean isDone(); /* 获取任务结果，该调用将阻塞 */ V get() throws InterruptedException, ExecutionException; /* 获取任务结果，该调用将阻塞给定时间 */ V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;&#125; FutureTask类表示异步计算任务；同时实现了Runnable和Future接口,因此可以直接交给Thread执行,并获取结果； 12345678910111213141516171819202122232425public class science &#123; public static void main(String[] args) throws Exception &#123; FutureTask&lt;String&gt; task = new FutureTask&lt;&gt;(new Task("test success")); new Thread(task).start(); System.out.println("task result: " + task.get()); &#125;&#125;class Task implements Callable&lt;String&gt; &#123; private String result; public Task(String result) &#123; this.result = result; &#125; @Override public String call() &#123; System.out.println("task is running ..."); try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; System.out.println("task is interrupted!"); return "(null)"; &#125; System.out.println("task is completed."); return result; &#125;&#125; Executor接口Executor接口为线程调度的最顶层接口,只提供了一个用于执行任务的execute()方法； ExecutorService接口此接口继承自Executor接口,提供更加强大丰富的线程池控制方法,比如 shutdown() 用于平滑关闭线程池，submit() 用于提交 Callable 任务（相比 Runnable 任务，它可以有返回值、可以抛出异常）.1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071public interface ExecutorService extends Executor &#123; /** * 关闭线程池 (设置 shutdown 标志位)，执行该方法后线程池将不会再接收新的任务 * 但是线程池也不会等待未完成的任务继续执行，这个应该交给 awaitTermination(). */ void shutdown();/** * 关闭线程池 (设置 shutdown 标志位并调用 interrupt() 中断任务)，中断不一定奏效 * 因此，我们在编写 Runnable/Callable 任务时一定要注意处理好 interrupt 中断标志. * @return List&lt;Runnable&gt; 返回还未开始执行的任务列表 */List&lt;Runnable&gt; shutdownNow();/** * 判断线程池的 shutdown 标志位是否已设置，即是否执行了 shutdown()、shutdownNow(). */boolean isShutdown();/** * 判断线程池的 shutdown 标志位是否已设置并且所有任务是否都已完成，如果是才返回 true. */boolean isTerminated();/** * 等待线程池中的任务完成执行 (前提是设置了 shutdown 标志位)，该调用将阻塞调用线程. * 如果任务都已完成则返回，或者发生超时，或者执行线程收到中断，以先发生的事件为准 * @param timeout 超时时间，为 0 或 -1 也不代表永久等待，而是立即返回 * @param unit 时间单位，java.util.concurrent.TimeUnit 枚举类 * @return boolean 如果线程池中的任务都已完成执行，则返回 true，否则返回 false * @throws InterruptedException 当收到中断信号时将清除中断位，并抛出该异常 */boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException;/** * 提交 Callable 任务，该调用将返回一个 Future 对象，用于控制任务的执行结果. * @param task 要执行的任务 * @return Future&lt;T&gt; 返回 Future&lt;T&gt; 结果对象 */&lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task);/** * 提交 Runnable 任务，该调用将返回一个 Future 对象，任务完成时调用 get() 将返回 result. * @param task 要执行的任务 * @param result 任务完成时返回的结果 * @return Future&lt;T&gt; 返回 Future&lt;T&gt; 结果对象 */&lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result);/** * 提交 Runnable 任务，它相当于 submit(task, null)，因此调用 get() 将返回 null 值. */Future&lt;?&gt; submit(Runnable task);/** * 执行所提交的任务列表，当该调用返回时，所有任务都已完成，调用 Future.isDone() 将返回 true. */&lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException;/** * 执行所提交的任务列表，当全部完成或超时到期时返回一个 Future 列表，调用 Future.isDone() 将返回 true. * 如果超时到期时，任务还未完成，那么这些未完成的任务将被取消 */&lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException;/** * 执行所提交的任务列表，返回成功完成的结果列表 (即未抛出异常)，该调用返回时，未完成的任务将被取消. */&lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException;/** * 执行所提交的任务列表，返回成功完成的结果列表或者超时到期时返回，该调用返回时，未完成的任务将被取消. */&lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException; &#125; AbstractExecutorService抽象类AbstractExecutorService抽象类实现了ExecutorService接口的submit,invoke系列方法,底层通过FutureTask生成新的异步执行实例。 ThreadPoolExecutor类ThreadPoolExecutor核心类,用于创建自定义线程池和并发包线程池的底层实现。 主要的构造方法如下 123456789101112131415161718192021222324252627282930313233343536373839/* 构造方法 */public ThreadPoolExecutor(int corePoolSize, // 核心线程数的最大值 int maximumPoolSize, // 可同时拥有的最大线程数 long keepAliveTime, // 空闲线程的存活时间 * TimeUnit unit, // keepAliveTime 单位 BlockingQueue&lt;Runnable&gt; workQueue) &#123; // 用于缓存任务的阻塞队列 this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), defaultHandler);&#125;public ThreadPoolExecutor(int corePoolSize, // 核心线程数的最大值 int maximumPoolSize, // 可同时拥有的最大线程数 long keepAliveTime, // 空闲线程的存活时间 * TimeUnit unit, // keepAliveTime 单位 BlockingQueue&lt;Runnable&gt; workQueue, // 用于缓存任务的阻塞队列 ThreadFactory threadFactory) &#123; // 指定产生线程的线程工厂 this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, threadFactory, defaultHandler);&#125;public ThreadPoolExecutor(int corePoolSize, // 核心线程数的最大值 int maximumPoolSize, // 可同时拥有的最大线程数 long keepAliveTime, // 空闲线程的存活时间 * TimeUnit unit, // keepAliveTime 单位 BlockingQueue&lt;Runnable&gt; workQueue, // 用于缓存任务的阻塞队列 RejectedExecutionHandler handler) &#123; // 指定拒绝接收新任务的策略 * this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), handler);&#125;public ThreadPoolExecutor(int corePoolSize, // 核心线程数的最大值 int maximumPoolSize, // 可同时拥有的最大线程数 long keepAliveTime, // 空闲线程的存活时间 * TimeUnit unit, // keepAliveTime 单位 BlockingQueue&lt;Runnable&gt; workQueue, // 用于缓存任务的阻塞队列 ThreadFactory threadFactory, // 指定产生线程的线程工厂 RejectedExecutionHandler handler); // 指定拒绝接收新任务的策略 */* 空闲超时策略默认针对"临时"线程，即超过 corePoolSize 数的线程，核心线程即使空闲也不会超时终止 *//* 拒绝策略是指当 workQueue 已满，且池内线程数达到 maximumPoolSize 时拒绝接受新任务采取的策略 */ 构造函数详解前三个构造函数都是调用的第四个构造函数进行初始化操作，各参数的作用： corePoolSize：线程池中的核心线程数，也就是正式员工数量； maximumPoolSize：线程池中能同时拥有的最大线程数（maximumPoolSize - corePoolSize = 临时线程数）； keepAliveTime：空闲线程的存活时间（默认针对临时线程）； unit：keepAliveTime 单位； TimeUnit.NANOSECONDS纳秒 TimeUnit.MICROSECONDS微秒 TimeUnit.MILLISECONDS毫秒 TimeUnit.SECONDS秒 TimeUnit.MINUTES分 TimeUnit.HOURS时 TimeUnit.DAYS天 workQueue：缓存任务的阻塞队列； ArrayBlockingQueue：一个由数组结构组成的有界阻塞队列； LinkedBlockingQueue：一个由链表结构组成的有界阻塞队列； LinkedTransferQueue：一个由链表结构组成的无界阻塞队列； LinkedBlockingDeque：一个由链表结构组成的有界阻塞双端队列； SynchronousQueue：一个不存储元素的无界阻塞（同步）队列； PriorityBlockingQueue：一个支持优先级排序的无界阻塞队列； DelayQueue：一个支持延时获取元素的无界阻塞队列； threadFactory：创建线程的工厂； handler：当 workQueue 已满，且线程数达 maximumPoolSize 时，拒绝新任务采取的策略； ThreadPoolExecutor.AbortPolicy：（默认）丢弃新任务并抛出 RejectedExecutionException 异常（RT） ThreadPoolExecutor.CallerRunsPolicy：让调用线程执行新任务 ThreadPoolExecutor.DiscardPolicy：丢弃新任务，不抛出异常 ThreadPoolExecutor.DiscardOldestPolicy：丢弃旧任务（最先提交却未得到执行的任务），然后重新尝试执行新任务 提交任务之后的流程当试图通过 execute()、submit() 方法将一个任务添加到线程池中时，将按照如下顺序处理： 如果线程池中的线程数量少于 corePoolSize，即使线程池中有空闲线程，也会创建一个新线程来执行新添加的任务； 如果线程池中的线程数量为 corePoolSize，并且缓冲队列 workQueue 未满，则将新添加的任务放到 workQueue 中，等待线程池中的空闲线程按照 FIFO 原则依次从队列中取出任务并执行； 如果线程池中的线程数量为 corePoolSize，并且缓冲队列 workQueue 已满，则创建新的线程（临时工）来执行新添加的任务，直到线程池中的线程数达到 maximumPoolSize； 如果线程池中的线程数量达到 maximumPoolSize，则按照饱和策略进行处理，默认为丢弃任务并抛出 RejectedExecutionException RT异常； 当（临时工）线程在线程池中的空闲时间超过 keepAliveTime 后，该（临时工）线程将被自动结束，移出线程池，直到线程数恢复到 corePoolSize； 预启动线程在创建了线程池后，默认情况下，线程池中并没有任何线程，而是等待有任务到来才创建线程去执行任务，除非调用 prestartAllCoreThreads() 和 prestartCoreThread() 方法，从方法名字可以看出，是预创建线程的意思，即在没有任务到来之前，就创建 corePoolSize 个线程或 1 个线程； keepAliveTime 超时默认情况下，keepAliveTime 只在线程数大于 corePoolSize 时才会生效；但是如果调用了allowCoreThreadTimeOut(true)方法，在线程池中的线程数不大于 corePoolSize 时，keepAliveTime 参数也会起作用，直到线程池中的线程数为 0； 阻塞队列阻塞队列用来存储等待执行的任务；该参数很重要，会对线程池的运行过程产生很大的影响，一般而言，有以下几种选择： ArrayBlockingQueue：基于数组结构的有界阻塞队列； LinkedBlockingQueue：基于链表结构的有界（默认为 Integer.MAX_VALUE）阻塞队列，吞吐量通常要高于 ArrayBlockingQueue； SynchronousQueue：不存储元素的无界阻塞队列；每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，反之亦然；吞吐量通常要高于 LinkedBlockingQueue； 线程池的状态线程池具有以下五种状态，当创建一个线程池时初始化状态为 RUNNING：RUNNING：允许提交并处理任务，线程池新创建时的状态；SHUTDOWN：不允许提交新的任务，调用 shutdown() 方法的状态；STOP：不允许提交新的任务并向池中线程发送中断信号，调用 shutdownNow() 方法的状态；TIDYING：所有任务都已执行完毕，池中工作的线程数为 0，等待执行 terminated() 钩子方法；TERMINATED：terminated() 钩子方法执行完毕，线程池已完全关闭的状态； 核心线程池的大小设置 IO密集型,一般设置核心数大小为CPU核心数*2,CPU密集型一般设置核心数为CPU核心数相同大小。 ScheduledExecutorService接口ScheduledExecutorService是并发包提供的计划任务执行器,在这之前一般使用java.util.Timer来执行计划任务。 Timer：优点是简单易用，但由于所有任务都是由同一个线程来调度，因此所有任务都是串行执行的，同一时间只能有一个任务在执行，前一个任务的延迟或异常都将会影响到之后的任务； ScheduledExecutorService：依赖于 JDK1.5 的线程池机制，其设计思想是，每一个被调度的任务都会由线程池中一个线程去执行，因此任务是并发执行的，相互之间不会受到干扰。不会因为上一个任务的延迟而延迟下一个任务。需要注意的是，只有当任务的执行时间到来时，ScheduedExecutor 才会真正启动一个线程，其余时间 ScheduledExecutor 都是在轮询任务的状态； ScheduledThreadPoolExecutor类实现了ScheduledExecutorService接口,是ThreadPoolExecutor的子类； Executors 工具类Executors 提供了一系列创建常见线程池的工厂方法，方便 Java 程序的编写； 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798/* * 固定线程数的线程池，适合 "计算密集型" 任务 * 因为 nCore 和 nMax 一样，因此不存在临时线程 * LinkedBlockingQueue 默认大小为 Integer.MAX_VALUE */public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125;// 指定线程工厂public static ExecutorService newFixedThreadPool(int nThreads, ThreadFactory threadFactory) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(), threadFactory);&#125;/* 一个线程的线程池，适合 "串行执行" 任务 */public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()));&#125;// 指定线程工厂public static ExecutorService newSingleThreadExecutor(ThreadFactory threadFactory) &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(), threadFactory));&#125;/* * 任意线程数的线程池，适合 "I/O 密集型" 任务 * 没有核心线程，临时线程数为 Integer.MAX_VALUE * 临时线程的空闲时间超过 60s 将会被线程池回收 * 使用的是 SynchronousQueue 无界阻塞队列(同步队列) */public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125;// 指定线程工厂public static ExecutorService newCachedThreadPool(ThreadFactory threadFactory) &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;(), threadFactory);&#125;/* 核心线程数为 1 的计划任务线程池，适合 "周期、计划" 任务 */public static ScheduledExecutorService newSingleThreadScheduledExecutor() &#123; return new DelegatedScheduledExecutorService (new ScheduledThreadPoolExecutor(1));&#125;// 指定线程工厂public static ScheduledExecutorService newSingleThreadScheduledExecutor(ThreadFactory threadFactory) &#123; return new DelegatedScheduledExecutorService (new ScheduledThreadPoolExecutor(1, threadFactory));&#125;/* 指定核心线程数的计划任务线程池，适合 "周期、计划" 任务 */public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) &#123; return new ScheduledThreadPoolExecutor(corePoolSize);&#125;// 指定线程工厂public static ScheduledExecutorService newScheduledThreadPool( int corePoolSize, ThreadFactory threadFactory) &#123; return new ScheduledThreadPoolExecutor(corePoolSize, threadFactory);&#125;/* 包装现有的线程池对象，返回配置不可修改的线程池 */public static ExecutorService unconfigurableExecutorService(ExecutorService executor) &#123; if (executor == null) throw new NullPointerException(); return new DelegatedExecutorService(executor);&#125;/* 包装现有的计划任务线程池对象，返回配置不可修改的线程池 */public static ScheduledExecutorService unconfigurableScheduledExecutorService(ScheduledExecutorService executor) &#123; if (executor == null) throw new NullPointerException(); return new DelegatedScheduledExecutorService(executor);&#125;/* * 创建一个默认线程工厂对象，线程命名： * pool-[线程池编号]-thread-[线程编号] */public static ThreadFactory defaultThreadFactory() &#123; return new DefaultThreadFactory();&#125;/* 包装 Runnable 任务为 Callable 任务 */public static &lt;T&gt; Callable&lt;T&gt; callable(Runnable task, T result); // Future.get() 返回 resultpublic static Callable&lt;Object&gt; callable(Runnable task); // Future.get() 返回 null CompletionService接口和ExecutorCompletionService当向Executor提交多个任务并且希望获得它们在完成之后的结果时候可以使用自定义Future集合以及CompletionService接口来获取多任务的执行结果,而ExecutorCompletionService是CompletionService接口的实现类用于包装一个Executor,其优缺点如下: 方式一：首先定义任务集合，然后定义 Future 集合用于存放执行结果，执行任务，最后遍历 Future 集合获取结果；优点：可以依次得到有序的结果；缺点：不能及时获取已完成的结果； 12345678910111213ExecutorService pool = Executors.newCachedThreadPool(); List&lt;Future&lt;String&gt;&gt; futures = new ArrayList&lt;&gt;(5); futures.add(pool.submit(new Task("Task-A"))); futures.add(pool.submit(new Task("Task-B"))); futures.add(pool.submit(new Task("Task-C"))); futures.add(pool.submit(new Task("Task-D"))); futures.add(pool.submit(new Task("Task-E"))); for (Future&lt;String&gt; future : futures) //阻塞获取,可以依次获取结果,不能及时获取已完成的结果 System.out.println("task result: " + future.get()); pool.shutdown(); 方式二：首先定义任务集合，通过 CompletionService 包装 Executor 来执行任务，然后调用其 take() 方法去取 Future 对象；优点：能及时得到已完成的结果；缺点：不能依次得到有序的结果； 123456789101112ExecutorService executor = Executors.newCachedThreadPool(); ExecutorCompletionService&lt;String&gt; executorCompletion = new ExecutorCompletionService&lt;&gt;(executor); executorCompletion.submit(new Task("Task-A")); executorCompletion.submit(new Task("Task-B")); executorCompletion.submit(new Task("Task-C")); executorCompletion.submit(new Task("Task-D")); executorCompletion.submit(new Task("Task-E")); for (int i = 0; i &lt; 5; i++) //能及时获取最先完成的结果,但不能知道完成的顺序 System.out.println("task result: " + executorCompletion.take().get()); executor.shutdown(); 在方式一中，从集合中遍历的每个 Future 对象并不一定处于完成状态，这时调用 get() 方法就会被阻塞住，所以后面的任务即使已完成也不能得到结果；而方式二中，CompletionService 的实现是维护一个保存 Future 对象的 BlockingQueue，只有当这个 Future 对象状态是结束的时候，才会加入到这个 Queue 中，所以调用 take() 能从阻塞队列中拿到最新的已完成任务的结果； Fork/Join 并行框架Fork/Join 框架是 Java7 提供的一个用于并行执行任务的框架，是一个把大任务分割成若干个小任务，最终汇总每个小任务结果后得到大任务结果的框架。 工作窃取算法:在线程池内干完当前线程活的线程去其他线程的队列里窃取一个任务来执行。而在这时它们会访问同一个队列，所以为了减少窃取任务线程和被窃取任务线程之间的竞争，通常会使用双端队列，被窃取任务线程永远从双端队列的头部拿任务执行，而窃取任务的线程永远从双端队列的尾部拿任务执行。 对于一般的 ForkJoin 任务，我们仅需重写 compute() 方法即可：RecursiveTask（用于有返回结果的任务）：protected abstract V compute()RecursiveAction（用于没有返回结果的任务）：protected abstract void compute() 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class science &#123; public static void main(String[] args) throws ExecutionException, InterruptedException &#123; int[] arr = new int[100_000_000]; // 该数组占用内存 381.46 MB Arrays.parallelSetAll(arr, // 使用随机数填充数组 i -&gt; ThreadLocalRandom.current().nextInt(100)); ForkJoinPool pool = new ForkJoinPool(); // CPU 核数个线程 long beg = System.nanoTime(); // 起始时间 Future&lt;Integer&gt; future = pool.submit(new SumTask(arr, 0, arr.length)); int result = future.get(); // 计算结果 long end = System.nanoTime(); // 结束时间 System.out.printf("计算结果: %d, 计算用时: %g ms\n", result, (end - beg) / 1000_000.0D); pool.shutdown(); // 关闭 ForkJoinPool 执行器 &#125;&#125;class SumTask extends RecursiveTask&lt;Integer&gt; &#123; private static final long serialVersionUID = -7073936093401677580L; private static final int THRESHOLD = 80000; // 阀值 private int[] arr; private int beg; private int end; public SumTask(int[] arr, int beg, int end) &#123; this.arr = arr; this.beg = beg; this.end = end; &#125; @Override protected Integer compute() &#123; int sum = 0; if (end - beg &lt;= THRESHOLD) &#123; // 如果小于阀值则直接计算 for (int i = beg; i &lt; end; i++) sum += arr[i]; &#125; else &#123; // 否则进行分割（递归） int mid = (beg + end) &gt;&gt; 1; // 取均值 SumTask left = new SumTask(arr, beg, mid); // 任务 1 SumTask right = new SumTask(arr, mid, end); // 任务 2 left.fork(); // 执行任务 1 right.fork(); // 执行任务 2 sum = left.join() + right.join(); // 合并任务 1、2 &#125; return sum; // 返回计算结果 &#125;&#125; Lock、Condition在 Java 5 中，专门提供了锁对象，利用锁可以方便的实现资源的封锁，用来控制对竞争资源并发访问的控制，这些内容主要集中在 java.util.concurrent.locks 包下面，里面有三个重要的接口 Lock、ReadWriteLock、Condition； Lock：互斥锁，Lock 提供了比 synchronized 方法和语句块更广泛、更细粒度的锁定操作； ReadWriteLock：读写锁，ReadWriteLock 分为读锁、写锁，它们是一个整体，读锁有任意多把，写锁只有一把，读锁和写锁不能同一时间锁定； Condition：条件变量，Condition 将 Object 监视器方法（wait、notify 和 notifyAll）分解成截然不同的对象，以便通过将这些对象与任意 Lock 实现组合使用； Lock 接口 12345678910111213141516171819202122232425262728293031323334353637383940/* * 不同于 synchronized，使用 Lock 对象需要显式释放锁，即调用 unlock()，一般形式如下： * Lock l = ...; * l.lock(); * try &#123; * // 访问由此锁保护的资源 * &#125; finally &#123; * l.unlock(); * &#125; */public interface Lock &#123; /* 类似 synchronized，如果尝试获取锁失败，则当前线程进入睡眠状态，直到锁被获取 */ void lock(); // 不可中断 void lockInterruptibly() throws InterruptedException; // 同上，但是可中断 /* * 尝试获取锁，如果锁立即可用则获取锁并返回 true，否则立即返回 false；一般形式如下： * Lock lock = ...; * if (lock.tryLock()) &#123; * try &#123; * // 访问由此锁保护的资源 * &#125; finally &#123; * lock.unlock(); * &#125; * &#125; else &#123; * // 执行未获取锁的动作 * &#125; */ boolean tryLock(); // 立刻返回 (总是非公平的抢占锁，即便是设置为公平锁) boolean tryLock(long time, TimeUnit unit) throws InterruptedException; // 等待指定时间 void unlock(); // 释放锁 /* * 获取与当前锁绑定的新的条件变量，类似 Object.notify/notifyAll * 调用 condition.await() 方法前，调用线程必须先持有与之关联的锁 * 执行 await() 方法后，会以原子方式释放锁，并在唤醒前重新获得锁 */ Condition newCondition();&#125; Condition接口 12345678910111213141516171819202122232425262728293031323334353637public interface Condition &#123; /** * 此调用将导致当前线程等待，直到它收到来自此条件变量的通知或被中断. * 同时与之关联的锁被自动释放，然后此线程进入休眠状态，直到发生以下四件事： * 1. 其它线程调用该条件变量的 signal() 方法，并且当前线程恰巧被选中为唤醒的线程； * 2. 其它线程调用该条件变量的 signalAll() 方法； * 3. 其它线程调用此线程的 interrupt() 方法，被中断； * 4. "虚假唤醒" 的发生。 * 以上事件之一发生后，当前线程保证在休眠唤醒之前获得与之关联的锁 * 因此在此调用前，当前线程必须先持有与之关联的锁，并且在调用返回后，需要释放与之关联的锁 */ void await() throws InterruptedException; // 可中断 void awaitUninterruptibly(); // 同上，除了不可中断 /** * 可中断的，并且可以指定纳秒精度的等待时间. * @param nanosTimeout 指定要等待的时长 * @return long nanosTimeout - 实际等待的时间，如果为 0 或负数则说明已超时 * @throws InterruptedException 收到中断时将清除中断标志位，并抛出此异常 */ long awaitNanos(long nanosTimeout) throws InterruptedException; // 指定纳秒精度的等待时长 boolean await(long time, TimeUnit unit) throws InterruptedException; // 同上，支持其它单位 boolean awaitUntil(Date deadline) throws InterruptedException; // 同上，直到某个绝对时间点 /* * Condition.await()、Object.wait() 必须先持有锁的原因： * 因为调用此方法后，调用线程会以原子方式释放与之关联的锁，并进入休眠状态；因此要求先获取锁； * 因为此调用返回前，调用线程必须先重新获得与之关联的锁，保证返回前持有锁；因此后面要释放锁。 * Condition.signal/signalAll()、Object.notify/notifyAll() 必须先持有锁的原因： * 因为调用线程在通知等待线程前，通常伴随着 "条件" 的改变，因此需要在锁的保护下进行； * 注意，这不是硬性要求，因为在逻辑上，调用线程完全可以在不获取锁的情况下进行 "通知"； * 但是，Java 语言层面上要求必须这么做，否则会抛出 IllegalMonitorStateException RT异常。 * 但是，在 C/C++ 的 pthread 库中，调用线程完全可以在不获取互斥锁的情况下通知等待线程。 */ void signal(); // 唤醒某个线程 void signalAll(); // 唤醒全部线程&#125; ReentrantLock类 1234567891011121314151617181920212223242526272829303132333435public class ReentrantLock implements Lock, java.io.Serializable &#123; /* 构造函数 */ /* * 什么公平锁？什么是非公平锁？ * 公平锁是指：严格按照先来先得的顺序排队等待去获取锁 * 非公平锁是指：每次获取锁时，先直接尝试获取锁，若获取不到再按照先来先得的顺序排队等待 * synchronized 和默认的 ReentrantLock() 构造函数都是非公平的，一般来说非公平锁吞吐量较高 */ public ReentrantLock(); // 默认为非公平锁 public ReentrantLock(boolean fair); // 如果为 true 则为公平锁 /* Lock 接口定义的方法 */ public void lock(); public void lockInterruptibly() throws InterruptedException; public boolean tryLock(); // 不具备公平性 public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException; public void unlock(); public Condition newCondition(); /* 锁状态查询 */ public final boolean isFair(); // 查询当前锁的公平性 public boolean isLocked(); // 查询当前锁是否已被任意线程持有 public boolean isHeldByCurrentThread(); // 查询当前线程是否持有锁 public int getHoldCount(); // 查询当前线程持有锁的重入计数 public final boolean hasQueuedThreads(); // 查询是否有线程正在等待这把锁 public final boolean hasQueuedThread(Thread thread); // 查询指定线程是否正在等待这把锁 public final int getQueueLength(); // 获取当前锁的等待队列长度，即等待线程数 public boolean hasWaiters(Condition condition); // 查询是否有线程正在等待与之相关的给定条件变量 public int getWaitQueueLength(Condition condition); // 获取与之关联的条件变量的等待队列长度 public String toString(); // 返回锁的状态描述字符串，"Unlocked" 或 "Locked by ThreadName"&#125; ReentrantReadWriteLock类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102/* * 读写锁实现了与 ReentrantLock 类似的语义，可重入读写锁有以下属性： * 1. 公平模式，读写锁支持公平锁、非公平锁两种构造模式，默认为非公平锁； * 2. 可重入，持有写锁的线程可同时持有读锁，但持有读锁的线程却不可能同时持有写锁； * 3. 锁降级，持有写锁的线程可继续持有读锁，然后释放写锁，从写锁降级为读锁；但读锁不能升级至写锁； * 4. 可中断，读锁和写锁在线程持有期间都会响应 Thread.interrupt() 中断信号； * 5. 条件变量，写锁支持 Lock.newCondition() 来获取一个与写锁关联的条件变量，读锁不支持，将抛出异常； * 6. 状态查询，与 ReentrantLock 一样，支持灵活的锁状态查询方法，用来监视系统状态（而不是用于同步控制）。 * * 下面是 JavaDoc 提供的一个锁降级示例： * class CachedData &#123; * Object data; * volatile boolean cacheValid; * final ReentrantReadWriteLock rwl = new ReentrantReadWriteLock(); * void processCachedData() &#123; * rwl.readLock().lock(); // 获取读锁 * if (!cacheValid) &#123; // 如果缓存无效 * // 获取写锁之前，必须先释放读锁，否则不可能成功 * rwl.readLock().unlock(); // 释放读锁 * rwl.writeLock().lock(); // 获取写锁 * try &#123; * // 重新检查缓存状态，因为其它线程可能对缓存状态做了更改 * if (!cacheValid) &#123; * data = ... * cacheValid = true; * &#125; * // 将写锁降级前，先获取读锁 * rwl.readLock().lock(); * &#125; finally &#123; * rwl.writeLock().unlock(); // 释放写锁，降级为读锁 * &#125; * &#125; * try &#123; * use(data); // 使用数据 * &#125; finally &#123; * rwl.readLock().unlock(); // 释放读锁 * &#125; * &#125; * &#125; * * 注意事项： * 此锁最多支持 65535 个递归写入锁定和 65535 个读取锁定；尝试超过这些限制会导致从锁定方法中引发错误。 */public class ReentrantReadWriteLock implements ReadWriteLock, java.io.Serializable&#123; /* 构造函数 */ public ReentrantReadWriteLock(); // 默认非公平 public ReentrantReadWriteLock(boolean fair); // true 公平、false 非公平 /* 获取写锁、读锁，写锁与读锁不可同时锁定（写锁在前的情况除外），写锁一把，读锁任意多把 */ public ReentrantReadWriteLock.WriteLock writeLock() &#123; return writerLock; &#125; public ReentrantReadWriteLock.ReadLock readLock() &#123; return readerLock; &#125; /* 静态内部类 - 读锁，实现了 Lock 接口 */ public static class ReadLock implements Lock, java.io.Serializable &#123; public void lock(); public void lockInterruptibly() throws InterruptedException; public boolean tryLock(); public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException; public void unlock(); public Condition newCondition(); // throw new UnsupportedOperationException() public String toString(); &#125; /* 静态内部类 - 写锁，实现了 Lock 接口 */ public static class WriteLock implements Lock, java.io.Serializable &#123; public void lock(); public void lockInterruptibly() throws InterruptedException; public boolean tryLock(); public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException; public void unlock(); public Condition newCondition(); public String toString(); /* JDK1.6 */ public boolean isHeldByCurrentThread(); // 查询当前线程是否持有写锁 public int getHoldCount(); // 查询当前线程持有写锁的重入计数 &#125; /* 锁状态查询 */ public final boolean isFair(); // 查询当前读写锁是否公平 public int getReadLockCount(); // 查询读锁的持有计数，即当前有多少把读锁 public int getReadHoldCount(); // 查询当前线程持有读锁的重入计数 (JDK1.6) public int getWriteHoldCount(); // 查询当前线程持有写锁的重入计数 public boolean isWriteLocked(); // 查询写锁是否已被锁定 public boolean isWriteLockedByCurrentThread(); // 查询当前线程是否持有写锁 public final boolean hasQueuedThreads(); // 查询是否有线程正在等待读锁或写锁 public final boolean hasQueuedThread(Thread thread); // 查询给定线程是否正在等待读锁或写锁 public final int getQueueLength(); // 查询正在等待读锁或写锁的线程数量 public boolean hasWaiters(Condition condition); // 查询是否有线程正在等待与写锁相关联的条件变量 public int getWaitQueueLength(Condition condition); // 查询正在等待与写锁相关联的条件变量的队列长度 public String toString(); // 获取当前读写锁的状态描述字符串&#125; synchronized实现原理以及优化 synchronized使用的锁是存放在Java对象头里面，具体位置是对象头里面的MarkWord，MarkWord里默认数据是存储对象的HashCode等信息，但是会随着对象的运行改变而发生变化，不同的锁状态对应着不同的记录存储方式 注意，启用偏向锁和未启用偏向锁时的对象头 Mark Word 初始状态是不一样的： 启用偏向锁：对象创建时 Mark Word 就是上图中的”偏向锁状态”，持有锁的线程 ID 为 0； 禁用偏向锁：对象创建时 Mark Word 就是上图中的”未锁定状态”，存储的是对象的哈希值。 启用偏向锁的情况下，如果 Mark Word 的锁状态为偏向锁，并且线程 ID 为 0，那么我们将其称为可偏向状态。 在 JDK1.6 之后（含），偏向锁默认启用，但是默认有 4000 毫秒的启动延迟（用于判断是否存在锁竞争）： 启用偏向锁：-XX:+UseBiasedLocking -XX:BiasedLockingStartupDelay=0（消除延迟）； 禁用偏向锁：-XX:-UseBiasedLocking（默认启用偏向锁）； 当禁用偏向锁时，锁状态根据竞争激烈程度从弱到强分别为：无锁状态 -&gt; 轻量级锁 -&gt; 重量级锁。当启用偏向锁时，锁状态根据竞争激烈程度从弱到强分别为：可偏向状态 -&gt; 偏向锁 -&gt; 轻量级锁 -&gt; 重量级锁； 偏向锁的获取过程 先检查是否为可偏向状态，即锁标志位为 01 且偏向锁标志位为 1； 如果是可偏向状态，则测试线程 ID 是否指向当前线程，如果是则执行步骤 5，否则执行步骤 3； 如果线程 ID 未指向当前线程，则尝试通过 CAS 置换为当前线程 ID，如果成功则执行步骤 5，否则执行步骤 4； 如果置换线程 ID 失败，说明此时已发生竞争，当到达全局安全点（safepoint）时获得偏向锁的线程将被挂起，偏向锁升级为轻量级锁，然后被挂起的线程继续执行剩下的同步代码（撤销偏向锁时发生 stop-the-world）； 此时当前线程已持有偏向锁，于是开始执行临界区的代码。 偏向锁的释放过程当线程持有偏向锁后，并不会主动去释放偏向锁，只有当其它线程尝试竞争锁时才会发生偏向锁撤销。具体的撤销细节在上面的步骤 4 中有说到。因为存在 STW，虽然很短暂，但是如果频繁出现，会对性能产生较大影响。 轻量级锁的获取过程 如果对象为无锁状态，即锁标志位为 01 且偏向锁标志位为 0；那么将在当前线程栈中创建锁记录（Lock Record）空间，用于存放当前对象头的 Mark Word 拷贝（称为 Displaced Mark Word）； 拷贝当前对象头的 Mark Word 字段至锁记录空间； 接着尝试使用 CAS 将当前对象头的锁记录指针指向当前线程栈中的锁记录空间，并将当前锁记录的 owner 指针指向对象头的 Mark Word，如果成功则执行步骤 4，否则执行步骤 5； 如果这个 CAS 置换动作成功了，那么当前线程就拥有了这个对象的锁，并且对象的 Mark Word 的锁标志位设为 00，表示此对象处于轻量级锁定状态； 如果这个 CAS 置换动作失败了，首先会检查对象的 Mark Word 的锁记录指针是否已指向当前线程栈中的锁记录空间，如果是则说明已获取锁，可以进入同步块；否则说明存在锁竞争，此时当前线程会自旋一段时间，如果获取到了锁则不进行锁升级，否则轻量级锁会膨胀为重量级锁。 轻量级锁的释放过程 通过 CAS 操作尝试把线程中复制的 Displaced Mark Word 替换对象当前的 Mark Word； 如果替换成功，整个同步过程就完成了； 如果替换失败，说明此时已不是轻量级锁定状态，已经膨胀为重量级锁；那就要在释放锁的同时，唤醒被挂起的线程。 轻量级锁什么情况下升级至重量级锁轻量级锁认为竞争存在，但是竞争的程度很轻，一般多个线程对于同一个锁的操作都会错开，或者说稍微等待一下（自旋），另一个线程就会释放锁。但是当自旋超过一定的次数，或者一个线程在持有锁，一个在自旋，又有第三个来访时，轻量级锁就会膨胀为重量级锁，重量级锁使除了拥有锁的线程以外的线程都阻塞，防止 CPU 空转。 偏向锁是为了在只有一个线程执行同步块时提高性能，轻量级锁是为了在多个线程交替执行同步块时提高性能。 重量级锁重量级锁是使用底层操作系统提供的 Mutex Lock 来实现的，当线程尝试获取锁失败时，该线程就会被挂起。线程之间的切换需要从用户态转换到内核态，这个成本非常高，状态之间的转换需要相对比较长的时间，这就是为什么 synchronized（JDK1.6 之前）效率低的原因。因此，我们将这种依赖于操作系统互斥量实现的锁称为”重量级锁”。JDK 中对 synchronized 做的种种优化，其核心都是为了减少这种重量级锁的使用。也就是使用我们前面说的”偏向锁”、”轻量级锁”，只有在不得已的情况下才会动用”重量级锁”。 synchronized 获取锁的过程 检测 Mark Word 里面是不是当前线程的 ID，如果是则表示当前线程处于偏向锁状态； 如果不是，则使用 CAS 将它置换为当前线程 ID，如果成功则表示当前线程获得偏向锁； 如果失败，则说明发生竞争，撤销偏向锁，进而升级为轻量级锁； 然后使用 CAS 将 Mark Word 的锁记录指针指向当前线程栈中的锁记录，如果成功，则获得轻量级锁； 如果失败，表示其它线程竞争锁，当前线程便尝试使用自旋来获取锁； 如果自旋成功则依然处于轻量级状态； 如果自旋失败，则升级为重量级锁。 JVM 的其它优化手段1、适应性自旋（Adaptive Spinning）：从轻量级锁获取的流程中我们知道，当线程在获取轻量级锁的过程中执行 CAS 操作失败时，是要通过自旋来获取轻量级锁的。问题在于，自旋是需要消耗 CPU 的，如果一直获取不到锁的话，那该线程就一直处在自旋状态，白白浪费 CPU 资源。因此 JDK 采用了聪明的方式 - 适应性自旋，基本认为一个线程上下文切换的时间是最佳的一个时间，同时 JVM 还会针对当前 CPU 的负荷情况做优化。 2、锁粗化（Lock Coarsening）：锁粗化的概念应该比较好理解，就是将多次连接在一起的加锁、解锁操作合并为一次，将多个连续的锁扩展成一个范围更大的锁。举个例子： 123456789public class StringBufferTest &#123; StringBuffer stringBuffer = new StringBuffer(); public void append() &#123; stringBuffer.append("a"); stringBuffer.append("b"); stringBuffer.append("c"); &#125;&#125; 因为 StringBuffer.append() 是同步方法，因此调用三次就意味着要连续加锁解锁三次，并且中间没有任何其它代码。如果 JVM 检测到有一系列连串的对同一个对象加锁和解锁操作，就会将其合并成一次范围更大的加锁和解锁操作，即在第一次 append() 方法时进行加锁，最后一次 append() 方法结束后进行解锁。 3、锁消除（Lock Elimination）：锁消除即删除不必要的加锁操作。根据代码逃逸技术，如果判断到一段代码中，堆上的数据不会逃逸出当前线程，那么可以认为这段代码是线程安全的，不必要加锁。看下面这段程序： 1234567public void vectorTest() &#123; Vector&lt;String&gt; vector = new Vector&lt;String&gt;(); for (int i = 0 ; i &lt; 10 ; i++) &#123; vector.add(i + ""); &#125; System.out.println(vector);&#125; 在运行这段代码时，JVM 可以明显检测到变量 vector 没有逃逸出方法 vectorTest() 之外（意思就是说在该方法外不可能拿到 vector 对象的引用），所以 JVM 可以大胆地将 vector 内部的加锁操作消除。 编码上的优化我们不能依赖 JVM 的锁优化手段，因为你不能保证 JVM 能理解你的烂代码而去采取优化手段，我们必须显式的帮助 JVM 去优化代码。 1、减少锁的持有时间：只在必要的时候使用锁，不要随意放大同步代码块的范围，比如： 123456789101112131415/* 优化前 */public synchronized void func() &#123; otherfunc1(); // 无需同步 mutexfunc(); // 需要同步 otherfunc2(); // 无需同步&#125;/* 优化后 */public void func() &#123; otherfunc1(); synchronized (this) &#123; mutexfunc(); &#125; otherfunc2();&#125; 2、避免频繁加/解同一把锁：当然大多数情况下我们自己是一清二楚的，是否存在竞争、变量是否逃逸等等，我们不会笨到去频繁加锁解锁。但是有时候这个不是我们能够控制的，在使用 Java 类库的时候，很多线程安全的类都存在隐式的加锁、解锁，比如 StringBuffer.append() 方法。这个只能交给 JVM 去发现了，我们无能为力。 3、锁分离：比如在读多写少的情况下考虑使用 J.U.C 的 ReadWriteLock 读写锁，来提高性能、吞吐量。当然读写锁不只用在表面的”读和写”，只要是操作互不影响，就可以利用读写分离思想。 三种内置锁的对比 锁类型 优点 缺点 适用场景 偏向锁 加锁和解锁过程不需要额外的消耗，和执行非同步代码块仅存在纳秒级别的差距 如果线程间存在锁竞争，会带来额外的锁撤销的消耗 适用于只有一个线程访问同步块的场景 轻量级锁 竞争的线程不会阻塞，而是采取自适应自旋的方式等待，提高了程序的响应速度 如果参与竞争的线程始终无法得到锁，那么自旋会白白浪费 CPU 资源 适用于追求响应时间，但要求同步块的执行速度非常快，避免因自旋导致 CPU 的持续空转 重量级锁 线程竞争不使用自旋，如果竞争不到锁，线程将会被挂起（休眠），并释放 CPU 资源 如果参与锁竞争失败则线程因为线程调度而挂起，但是频繁的上下文切换带来的开销很大且响应时间缓慢 适用于同步块的执行时间较长的情况 Synchronizer 同步器(以及实现原理)J.U.C 中的同步器主要用于协助线程同步，有以下四种：1) 闭锁 CountDownLatch2) 栅栏 CyclicBarrier3) 信号量 Semaphore4) 交换器 Exchanger CountDownLatch闭锁闭锁的作用:允许一个或多个线程等待,直到在其他线程中执行的一组操作完成。CountDownLatch 用给定的计数初始化，线程调用 await() 方法后将被阻塞，直到当前计数由于调用 countDown() 方法而达到零，在此之后所有等待的线程被释放，并且任何后续的调用立即返回。这是一次性现象，即计数不能被重置。 123456789101112131415161718192021222324252627282930313233343536373839final CountDownLatch latch = new CountDownLatch(3); final Random rand = new Random(); new Thread(() -&gt; &#123; System.out.println("爸爸: 我正在赶来的路上 ..."); try &#123; Thread.sleep(rand.nextInt(2501) + 500); // 500 ~ 3000 ms &#125; catch (InterruptedException e) &#123; // TODO &#125; System.out.println("爸爸: 我已经到了饭店。"); latch.countDown(); &#125;).start(); new Thread(() -&gt; &#123; System.out.println("妈妈: 我正在赶来的路上 ..."); try &#123; Thread.sleep(rand.nextInt(2501) + 500); // 500 ~ 3000 ms &#125; catch (InterruptedException e) &#123; // TODO &#125; System.out.println("妈妈: 我已经到了饭店。"); latch.countDown(); &#125;).start(); new Thread(() -&gt; &#123; System.out.println("我: 我正在赶来的路上 ..."); try &#123; Thread.sleep(rand.nextInt(2501) + 500); // 500 ~ 3000 ms &#125; catch (InterruptedException e) &#123; // TODO &#125; System.out.println("我: 我已经到了饭店。"); latch.countDown(); &#125;).start(); latch.await(); // 等待大家的到来 System.out.println("大家伙都到了，开饭咯。"); CyclicBarrier 栅栏栅栏是多个线程互相等待，直到全部线程都到齐，等待的线程才会继续运行。与CountDownLatch不同的是栅栏是可以被重置的可以重复利用，还有个不一样的是栅栏还支持一个可选的 Runnable 任务，该任务将会被最后一个到达的线程执行，执行完该任务后所有的线程才会被释放，这个特性对更新共享状态是很有用的。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879public static void main(String[] args) &#123; final CyclicBarrier barrier = new CyclicBarrier(5, () -&gt; System.out.println("大家都到了，此轮比赛结束")); final Random rand = new Random(); new Thread(() -&gt; &#123; System.out.println("[A]\t开始起跑"); try &#123; Thread.sleep(rand.nextInt(501) + 1000); &#125; catch (InterruptedException e) &#123; // TODO &#125; System.out.println("[A]\t到达终点"); try &#123; barrier.await(); &#125; catch (InterruptedException | BrokenBarrierException e) &#123; // TODO &#125; &#125;).start(); new Thread(() -&gt; &#123; System.out.println("[B]\t开始起跑"); try &#123; Thread.sleep(rand.nextInt(501) + 1000); &#125; catch (InterruptedException e) &#123; // TODO &#125; System.out.println("[B]\t到达终点"); try &#123; barrier.await(); &#125; catch (InterruptedException | BrokenBarrierException e) &#123; // TODO &#125; &#125;).start(); new Thread(() -&gt; &#123; System.out.println("[C]\t开始起跑"); try &#123; Thread.sleep(rand.nextInt(501) + 1000); &#125; catch (InterruptedException e) &#123; // TODO &#125; System.out.println("[C]\t到达终点"); try &#123; barrier.await(); &#125; catch (InterruptedException | BrokenBarrierException e) &#123; // TODO &#125; &#125;).start(); new Thread(() -&gt; &#123; System.out.println("[D]\t开始起跑"); try &#123; Thread.sleep(rand.nextInt(501) + 1000); &#125; catch (InterruptedException e) &#123; // TODO &#125; System.out.println("[D]\t到达终点"); try &#123; barrier.await(); &#125; catch (InterruptedException | BrokenBarrierException e) &#123; // TODO &#125; &#125;).start(); new Thread(() -&gt; &#123; System.out.println("[E]\t开始起跑"); try &#123; Thread.sleep(rand.nextInt(501) + 1000); &#125; catch (InterruptedException e) &#123; // TODO &#125; System.out.println("[E]\t到达终点"); try &#123; barrier.await(); &#125; catch (InterruptedException | BrokenBarrierException e) &#123; // TODO &#125; &#125;).start(); Exchanger 交换器用来给两个线程互换数据的交换器，可以理解为 SynchronousQueue 同步队列的双向形式 123456789public class Exchanger&lt;V&gt; &#123; /* 构造函数 */ public Exchanger(); /* 交换数据，x 为提供给对方的数据，返回由对方提供的数据 */ public V exchange(V x) throws InterruptedException; /* 交换数据，发生中断则抛出中断异常，发生超时则抛出超时异常 */ public V exchange(V x, long timeout, TimeUnit unit) throws InterruptedException, TimeoutException;&#125; Semaphore 计数信号量信号量拥有一套许可证。使用 acquire() 方法申请许可证，使用完后调用 release() 方法归还许可证。在 Semaphore 的构造函数中可以指定一个数值，表示可用的许可证数量。 如果许可证数量为 1，则可以作为互斥锁使用。我们把拥有一个许可证的信号量称为二进制信号量，因为它只有两个状态，资源可用，资源不可用。 信号量除了作为互斥锁使用，还常用于实现资源池，如数据库连接池、线程池。 1234567891011121314151617181920212223242526272829303132public class Semaphore implements java.io.Serializable &#123; /* 构造函数 */ public Semaphore(int permits); // 非公平 public Semaphore(int permits, boolean fair); // 可选公平 /* 申请资源 - 1 个 */ public void acquire() throws InterruptedException; // 可中断 public void acquireUninterruptibly(); // 不可中断 public boolean tryAcquire(); // [非公平] 立即获取，如果资源立即可用则返回 true，否则返回 false public boolean tryAcquire(long timeout, TimeUnit unit) throws InterruptedException; // 指定等待时间 /* 释放资源 - 1 个*/ public void release(); /* 申请资源 - N 个 */ public void acquire(int permits) throws InterruptedException; public void acquireUninterruptibly(int permits); public boolean tryAcquire(int permits); // [非公平] public boolean tryAcquire(int permits, long timeout, TimeUnit unit) throws InterruptedException; /* 释放资源 - N 个 */ public void release(int permits); /* 状态查询 */ public boolean isFair(); // 是否公平 public int availablePermits(); // 当前可用的资源数量 public int drainPermits(); // 获取当前立即可用的所有资源，返回获取的资源数 public final boolean hasQueuedThreads(); // 查询当前是否有线程正在等待获取资源 public final int getQueueLength(); // 获取正在等待资源的线程数目 public String toString(); // 字符串描述信息&#125; Atomic 原子变量原子变量主要是方便程序员在多线程环境下，无锁的进行原子操作。原子类是sun.misc.Unsafe类的包装类，其核心操作是 CAS 原子操作。 在 Atomic 包中一共有 12 个类（JDK1.8 中又增加了 4 个类，稍后介绍），四种原子更新方式，分别是原子更新基本类型，原子更新数组，原子更新引用和原子更新字段；Atomic 包里的类基本都是使用 Unsafe 实现的包装类； 原子更新基本类型 AtomicBoolean：布尔型； AtomicInteger：整型； AtomicLong：长整型； 原子更新数组 AtomicIntegerArray：整型数组； AtomicLongArray：长整型数组； AtomicReferenceArray&lt;E&gt;：引用类型数组（存在 ABA 问题）； 原子更新引用 AtomicReference&lt;V&gt;，存在 ABA 问题； AtomicStampedReference&lt;V&gt;，使用整型标记避免 ABA 问题； AtomicMarkableReference&lt;V&gt;，使用布尔标记避免 ABA 问题； 原子更新字段 AtomicIntegerFieldUpdater&lt;T&gt;，整型字段更新器； AtomicLongFieldUpdater&lt;T&gt;，长整型字段更新器； AtomicReferenceFieldUpdater&lt;T, V&gt;，引用字段更新器（存在 ABA 问题）； 被更新的字段须被volatile修饰，并且确保该字段的访问性，最好为public。 ABA问题 假设存在两个线程 T1、T2，线程 T1 先执行语句 (a)，将 1 置换为了 2，接着又执行语句 (b)，将 2 置换回 1；然后线程 T2 执行语句 (c)，发现当前的值为 1，于是又将 1 置换为 3。 从上面的描述中并未发现任何问题，是的，对于基本类型来说的确没有问题，因为我们关心的只是值本身而已。但是如果是引用类型就有问题了，因为 CAS 判断是仅仅是内存地址，如果这个地址被重用了呢，CAS 根本发现不了，地址还是那个地址，但是对象已经完全不同了（地址被重用是有可能发生的，一个内存被释放后，再分配，很有可能还是原来的地址）。 那么有什么办法解决 ABA 问题呢？利用 AtomicStampedReference、AtomicMarkableReference 原子类： AtomicStampedReference，从名字看的出来，每次使用 CAS 更新后，都给对象盖个戳（使用 int 来计数）； AtomicMarkableReference，从名字也看的出来，只要使用 CAS 更新过，就给对象打上布尔标记（如 false）。 JDK1.8 新增类在 Java 8 中，Doug Lea 大神又添加了LongAdder、LongAccumulator、DoubleAdder、DoubleAccumulator四个类。 LongAdder是 JDK1.8 提供的累加器，基于 Striped64 实现。它常用于状态采集、统计等场景。AtomicLong 也可以用于这种场景，但在线程竞争激烈的情况下，LongAdder 要比 AtomicLong 拥有更高的吞吐量，但会耗费更多的内存空间。LongAccumulator和LongAdder类似，也基于 Striped64 实现。但要比 LongAdder 更加灵活（要传入一个函数接口），LongAdder 相当于 LongAccumulator 的一种特例。 BlockingQueue 阻塞队列阻塞队列提供了可阻塞的入队和出队操作：如果队列满了，入队操作将阻塞直到有空间可用，如果队列空了，出队操作将阻塞直到有元素可用。阻塞队列的实现原理是利用ReentrantLock和Condition将复杂的await-signal语句隐藏在内部。 BlockingQueue是Queue的子接口，同时BlockingQueue还有两个子接口：BlockingDeque、TransferQueue；因此，它们三个都是 Java 集合框架的一员。 BlockingDeque同时还继承了Deque接口，也就是双端阻塞队列，可以当作 BlockingStack 阻塞栈来使用。 TransferQueue被称为传递队列；对于阻塞队列：当生产者向队列添加元素但队列已满时，生产者会被阻塞；当消费者从队列移除元素但队列为空时，消费者会被阻塞；而 TransferQueue 则更进一步，生产者会一直阻塞直到所添加到队列的元素被某一个消费者所消费（不仅仅是添加到队列里就完事）；新添加的 transfer() 方法用来实现这种约束。顾名思义，阻塞就是发生在元素从一个线程 transfer 到另一个线程的过程中，它有效地实现了元素在线程之间的传递（以建立 Java 内存模型中的 happens-before 关系的方式）。 阻塞队列的主要实现类有 7 个： ArrayBlockingQueue：基于数组结构的有界阻塞队列（长度不可变）； LinkedBlockingQueue：基于链表结构的有界阻塞队列（默认容量 Integer.MAX_VALUE）； LinkedTransferQueue：基于链表结构的无界阻塞/传递队列； LinkedBlockingDeque：基于链表结构的有界阻塞双端队列（默认容量 Integer.MAX_VALUE）； SynchronousQueue：不存储元素的阻塞/传递队列； PriorityBlockingQueue：支持优先级排序的无界阻塞队列； DelayQueue：支持延时获取元素的无界阻塞队列。 同步容器与并发容器同步容器在 JDK1.5 之前，Java 提供的主要同步容器有： Vector、Stack、Hashtable Collections.synchronizedXXX() 这些同步容器的线程安全是指单个操作是线程安全的，而复合操作不是线程安全的(例如迭代器)！而且方法使用synchronized同步锁竞争比较激烈,性能较差。 并发容器这里主要提这两种并发容器：ConcurrentHashMap、CopyOnWriteArrayList ConcurrentHashMap 在 Java7 中，采用分段锁机制，理论最大并发数与 Segment 个数相等。Java7 中的 ConcurrentHashMap 的底层数据结构仍然是数组和链表。与 HashMap 不同的是，ConcurrentHashMap最外层不是一个大的数组，而是一个 Segment 的数组。每个 Segment 包含一个与 HashMap 数据结构差不多的链表数组。整体数据结构如下图所示： 在 Java8 中，为了进一步提高性能，摒弃了分段锁机制，采用更高效的 CAS 操作。底层与同期的 HashMap 一样，都是”数组 + 链表 + 红黑树”。当链表长度超过一定阈值（8）时将链表（寻址时间复杂度为 O(N)）转换为红黑树（寻址时间复杂度为 O(log(N))）。整体数据结构如下图所示： CopyOnWriteArrayList copyOnWriteArrayList为写时复制即对于共享的同一个内容,当想要修改这个内容的时候,会把内容拷贝一份形成一个新的内容然后再更改,是一种延迟懒惰策略,jdk1.5并发包提供了CopyOnWriteArrayList 和 CopyOnWriteArraySet使用写时复制的机制实现的并发容器。 通俗的理解是当我们往一个容器添加元素的时候，不直接往当前容器添加，而是先将当前容器进行 Copy，复制出一个新的容器，然后往新的容器里添加元素，添加完元素之后，再将原容器的引用指向新的容器。这样做的好处是我们可以对 CopyOnWrite 容器进行并发的读，而不需要加锁，因为当前容器不会添加任何元素。所以 CopyOnWrite 容器也是一种读写分离的思想，读和写不同的容器。主要用于读多写少的并发场景。 CurrentMap接口实现子类ConcurrentNavigableMap 接口 ConcurrentNavigableMap 是 ConcurrentMap、NavigableMap 的子接口，支持一系列的导航方法，是一个有序的 Map。 ConcurrentHashMap 类 ConcurrentHashMap 不允许 null 键以及 null 值。HashMap 允许。 ConcurrentHashMap 的迭代器（iterators 和 spliterators）是”弱一致”的。 ConcurrentSkipListMap 类 与大多数并发集合一样，该类不允许 null 键或 null 值，因为一些 null 返回值的意义很不清晰。 ConcurrentSkipListMap 实现了 ConcurrentNavigableMap 接口，因此这是一个有序的 Map 映射。 ConcurrentSkipListMap 的迭代器（Iterators 和 spliterators）是”弱一致”的。 ConcurrentSkipListSet 类 ConcurrentSkipListSet 底层使用 ConcurrentSkipListMap 存储元素，同时实现了 NavigableSet 接口。 批量操作（addAll、removeAll、retainAll、containsAll、equals、toArray）不保证以原子方式执行。 与大多数并发集合一样，该类不允许使用 null 元素，因为对于某些 null 返回值的方法很难明确其意义。 ConcurrentSkipListSet 的迭代器（Iterators 和 spliterators）是”弱一致”的。 ConcurrentLinkedQueue 类 基于链表结构的大小无限制的线程安全队列（FIFO，先进先出），与其它并发集合一样，不允许 null 元素。 批量操作（addAll、removeAll、retainAll、containsAll、equals、toArray）不保证以原子方式执行。 ConcurrentLinkedQueue 的迭代器（Iterators 和 spliterators）是”弱一致”的。 ConcurrentLinkedDeque 类 基于链表结构的大小无限制的线程安全双端队列（可在两端进行插入和删除），与其它并发集合一样，不允许 null 元素。 批量操作（addAll、removeAll、retainAll、containsAll、equals、toArray）不保证以原子方式执行。 ConcurrentLinkedDeque 的迭代器（Iterators 和 spliterators）是”弱一致”的。 CopyOnWrite容器CopyOnWriteArrayList 类 ArrayList 的线程安全版本（不同于 Vector），所有的修改操作都是通过创建底层数组的新副本来实现的。 因为是 CopyOnWrite 机制，因此这类集合不适用于写多读少的场景，特别是底层数组很大的时候，特别的慢。 迭代器保证不抛出 ConcurrentModificationException，因为修改的数组和正在被遍历的数组不是同一个数组。 迭代器本身的元素更改操作（remove()、set()、add()）不受支持，会抛出 UnsupportedOperationException 异常。 与其它的并发容器不同，CopyOnWriteArrayList 允许存在包括 null 在内的所有元素。 CopyOnWriteArraySet 类 CopyOnWriteArraySet 内部使用 CopyOnWriteArrayList 存储元素，因此 CopyOnWriteArrayList 的特性在此依旧适用。 因为是写时复制型容器，因此只适用于读多写少的应用场景，毕竟每次修改操作都会进行一次 Copy，开销是比较昂贵的。 TimeUnit 枚举TimeUnit 表示给定粒度单位的持续时间，并提供跨设备转换的实用方法，可在这些时间单元中执行计时和延迟操作。 12345678910111213141516171819202122232425262728293031323334public enum TimeUnit &#123; /* 枚举常量 */ NANOSECONDS, // 纳秒 MICROSECONDS, // 微秒 MILLISECONDS, // 毫秒 SECONDS, // 秒 MINUTES, // 分 HOURS, // 时 DAYS; // 天 /* 单位转换 */ /* * 将给定的持续时间转换为当前单位 * 从较细粒度转换为较粗粒度将被截断导致精度损失；如将 999 毫秒转换为秒的结果是 0 秒，而不是 1 秒； * 从较粗粒度转换为较细粒度可能导致溢出，如果为负则为 Long.MIN_VALUE，如果为正则为 Long.MAX_VALUE； */ public long convert(long sourceDuration, TimeUnit sourceUnit); public long toNanos(long duration); // 转换为纳秒 public long toMicros(long duration); // 转换为微秒 public long toMillis(long duration); // 转换为毫秒 public long toSeconds(long duration); // 转换为秒 public long toMinutes(long duration); // 转换为分 public long toHours(long duration); // 转换为时 public long toDays(long duration); // 转换为天 /* 实用方法 */ public void timedWait(Object obj, long timeout) // Object.wait() throws InterruptedException; public void timedJoin(Thread thread, long timeout) // Thread.join() throws InterruptedException; public void sleep(long timeout) throws InterruptedException; // Thread.sleep()&#125; 呜谢Java中synchronized的实现原理与应用 java并发编程之CompletionService J.U.C包简介]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java内存模型]]></title>
    <url>%2F2019%2F02%2F18%2Fsenssic.github.io%2F201902%2Fjava%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[JMM是一种保证多线程通信中内存变量一致性的协议。定义了多线程之间通信和同步规则。 通信：不同线程对同一资源的并行访问 同步：不同线程对同一资源的顺序访问 硬件内存架构和JMM的基本模型现代计算机硬件包括,多CPU,CPU寄存器,高速缓存,内存,磁盘等其数据读写如下图: 由于多CPU和多寄存机以及多高速缓存共享内存,会导致在处理数据时的一些问题： 缓存不一致,当多个cpu同时涉及运算一块住内存区域时,可能导致各自的缓存数据不一致。 指令重排序,为了充分发挥处理器内部的计算单元,处理器可能会对代码进行乱序执行的优化。处理器只保证该结果与顺序执行结果一致,并不能保证中间结果的顺序性。 从硬件角度看JMM中定义的堆和栈 java内存模型与硬件架构之间存在差异性,硬件架构没有区分线程和堆,全部位于主内存中,部分线程和堆有时可能会出现在CPU缓存中和CPU内部的寄存器中。 从抽象的角度看JMM定义线程和主内存之间的抽象关系 线程之间的共享变量位于主内存中 每个线程都有一个本地内存,用于存放该线程的本身信息和该线程以读/写共享变量的拷贝副本 为了获取更好的运行速度,虚拟机和硬件系统,可能会让工作内存优先存储于寄存器和高速缓存中。 线程工作内存是对CPU的寄存器和高速缓存的抽象描述,而JMM只是对内存的物理划分,只局限在JVM的内存。 JMM模型基本特性线程通讯线程的通讯方式一般由两种,共享内存和消息传递。java并发采用的是共享内存模型,java线程之稿件的通信总是隐式进行,整个通讯过程对程序员完全透明。 原子操作根据工作内存和主内存交互协议,变量从主内存拷贝到工作内存与工作内存同步到主内存会经过下面八个原子操作。 lock 主存 作用于主内存的变量，它把一个变量标识为一条线程独占的状态。 unlock 主存 作用于主内存的变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。 read 主存 作用于主内存的变量，它把一个变量的值从主内存传输到线程的工作内存中，以便随后的load动作使用。 load 工作内存 作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中 use 工作内存 作用于工作内存的变量，它把工作内存中一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用到变量的值的字节码指令时将会执行这个操作 assign 工作内存 作用于工作内存的变量，它把一个从执行引擎接收到的值赋给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。 store 工作内存 作用于工作内存的变量，它把工作内存中一个变量的值传送到主内存中，以便随后的write操作使用。 write 主内存 作用于主内存的变量，它把store操作从工作内存中得到的变量的值放入主内存的变量中。 12345678910111213141516171819JMM规定如果要把一个变量从主内存复制到工作内存，那就要顺序地执行read和load操作，如果要把变量从工作内存同步回主内存，就要顺序地执行store和write操作。 注意，Java内存模型只要求上述两个操作必须按顺序执行，而没有保证是连续执行。也就是说，read与load之间、store与write之间是可插入其他指令的，如对主内存中的变量a、b进行访问时，一种可能出现顺序是read a、read b、load b、load a。 除了以上的顺序约束以外，还规定了其他的约束： a. 不允许read和load、store和write操作之一单独出现，即不允许一个变量从主内存读取了但工作内存不接受，或者从工作内存发起回写了但主内存不接受的情况出现。 b. 不允许一个线程丢弃它的最近的assign操作，即变量在工作内存中改变了之后必须把该变化同步回主内存。 c. 不允许一个线程无原因地（没有发生过任何assign操作）把数据从线程的工作内存同步回主内存中。 d. 一个新的变量只能在主内存中“诞生”，不允许在工作内存中直接使用一个未被初始化（load或assign）的变量，换句话说，就是对一个变量实施use、store操作之前，必须先执行过了assign和load操作。 e. 一个变量在同一个时刻只允许一条线程对其进行lock操作，但lock操作可以被同一条线程重复执行多次，多次执行lock后，只有执行相同次数的unlock操作，变量才会被解锁。 f. 如果对一个变量执行lock操作，那将会清空工作内存中此变量的值，在执行引擎使用这个变量前，需要重新执行load或assign操作初始化变量的值。 g. 如果一个变量事先没有被lock操作锁定，那就不允许对它执行unlock操作，也不允许去unlock一个被其他线程锁定住的变量。 对一个变量执行unlock操作之前，必须先把此变量同步回主内存中（执行store、write操作）。 指令重排序现代程序和计算机架构为了优化执行效率,可能会对语句或指令进行重排序,主要有 编译器重排序 不改变单线程程序语意的前提下,重新安排语句的执行顺序。 JMM编译器重排序规则会禁止特定的编译器重排序 处理器重排序 指令级并行重排序 将多条指令重叠排序,如果不存在数据依赖,处理器可以改变语句对应机器指令的执行顺序 内存系统重排序 处理器使用缓存和读写缓冲区，家族和存储操作看起来在乱序执行 JMM的处理器重排序规则会要求JAVA编译器在生成指令序列时插入特定的内存屏障指令来禁止特定类型处理器重排序。 volatile关键字就是java虚拟机提供的最轻量级的同步机制,当一个变量被定义成volatile之后此变量则对所有线程保持可见性,其实现原理是禁止指令重排序。 注意：volatile只是保证了变量对于所有线程的变化立即可见,但并非运算时原子操作,即volatile变量在多线程的并发运算操作也是不安全的。 三大特性(原子性,可见性,有序性)java内存模型是围绕并发过程中如何处理原子性,可见性,和有序性来建立的。 原子性 java内存模型直接保存原子性的变量操作包括read、load、assign、use、store和write. 如果应用场景需要一个更大范围的原子性保证（经常会遇到），Java内存模型还提供了lock和unlock操作来满足这种需求，尽管虚拟机未把lock和unlock操作直接开放给用户使用，但是却提供了更高层次的字节码指令monitorenter和monitorexit来隐式地使用这两个操作，这两个字节码指令反映到Java代码中就是同步块——synchronized关键字，因此在synchronized块之间的操作也具备原子性。 可见性 当一个线程修改共享变量的值,其他线程能够立即可见最新值。 除了volatile之外，Java还有两个关键字能实现可见性，即synchronized和final。同步块的可见性是由“对一个变量执行unlock操作之前，必须先把此变量同步回主内存中（执行store、write操作）”这条规则获得的，而final关键字的可见性是指：被final修饰的字段在构造器中一旦初始化完成，并且构造器没有把“this”的引用传递出去（this引用逃逸是一件很危险的事情，其他线程有可能通过这个引用访问到“初始化了一半”的对象），那在其他线程中就能看见final字段的值。 有序性 Java程序中天然的有序性可以总结为一句话：如果在本线程内观察，所有的操作都是有序的；如果在一个线程中观察另一个线程，所有的操作都是无序的。前半句是指“线程内表现为串行的语义”（Within-Thread As-If-Serial Semantics），后半句是指“指令重排序”现象和“工作内存与主内存同步延迟”现象。 Java语言提供了volatile和synchronized两个关键字来保证线程之间操作的有序性，volatile关键字本身就包含了禁止指令重排序的语义，而synchronized则是由“一个变量在同一个时刻只允许一条线程对其进行lock操作”这条规则获得的，这条规则决定了持有同一个锁的两个同步块只能串行地进入。 先行先发原则java语言中有一个先行先发原则(如果存在一个操作的执行结果需要对另一个操作可见,那么这两个操作之间必须要存在happens-before),根据这些操作原则我们可以很方便的从程序员角度去判断或解决并发环境下的冲突等问题。 程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作 锁定规则：一个unLock操作先行发生于后面对同一个锁额lock操作 volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作 传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C 线程启动规则：Thread对象的start()方法先行发生于此线程的每个一个动作 线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生 线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行 对象终结规则：一个对象的初始化完成先行发生于他的finalize()方法的开始 顺序一致性模型顺序一致性内存模型是一个被计算机科学家理想化了的理论参考模型,它为程序员提供了极强的内存可见性保证。顺序一致性内存模型有两大特性： 一个线程中的所有操作必须按照程序的顺序来执行。 （不管程序是否同步）所有线程都只能看到一个单一的操作执行顺序。在顺序一致性内存模型中，每个操作都必须原子执行且立刻对所有线程可见。 对于同步后的多线程并发,顺序一致性模型保证A线程执行一定位于B线程之前。即A1-&gt;A2-&gt;A3 对于未同步的多线程并发,顺序一致性模型虽然整体上无序,但保证对于每个线程都是顺序的,即每个操作都能立即对任意线程可见。 一个正确同步的多线程程序。根据 JMM 规范，该程序的执行结果将与该程序在顺序一致性模型中的执行结果相同。 一个未同步的多线程程序。根据JMM中不但不保证整体的执行顺序是无序的,而且所有线程看到的操作执行顺序也可能不一样。比如，在当前线程把写过的数据缓存在本地内存中，且还没有刷新到主内存之前，这个写操作仅对当前线程可见；从其他线程的角度来观察，会认为这个写操作根本还没有被当前线程执行。只有当前线程把本地内存中写过的数据刷新到主内存之后，这个写操作才能对其他线程可见。在这种情况下，当前线程和其它线程看到的操作执行顺序将不一致。 总结我们从现代计算机架构对并发编程的问题(缓存不一致,重排序)为起点,介绍了JMM对计算机架构的抽象,以及在这种架构方式对并发场景中的可见性和顺序性等保证。通过原子操作命令和内存屏障对可见性和顺序性的实现。通过as-if-serial和happens before 的JMM语义和原则给程序员视角提供了统一的可处理的并发编程模型。 呜谢内存模型与多线程设计-JMM模型 Java内存模型（JMM）总结]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>内存模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql索引原理]]></title>
    <url>%2F2019%2F02%2F17%2Fsenssic.github.io%2F201902%2FMySql%E7%B4%A2%E5%BC%95%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[在使用mysql索引的时候,会很好奇为什么一般都使用B+树作为索引，而不使用哈希表。非主键字段是怎么创建索引的,其索引内容是什么,怎么和对应行关联？为什么必须存在主键,为什么主键最好是自增的？ 带着这些问题,我们先了解一下B+树是什么,以及mysql的最左前缀原理。 B-tree和B+treeb树和B+树主要用于数据库索引的原因之一是因为数据库数据是存放在磁盘上的,虽然理论上二叉树的查找和比较次数都是最优的,但对于需要访问磁盘IO这种慢操作就不太适用了,使用B树可以使计算机在IO操作的时候基于局部原理和磁盘预读的页读取更少。进而使IO操作更少,每次都恰好读取到B树的一个节点数据。 B-tree的特点一个M阶的b树具有如下几个特征(M阶为每个节点最多包含M个孩子)：定义任意非叶子结点最多只有M个儿子，且M&gt;2； 根结点的儿子数为[2, M]； 除根结点以外的非叶子结点的儿子数为[M/2, M]，向上取整； 非叶子结点的关键字个数=儿子数-1； 所有叶子结点位于同一层； k个关键字把节点拆成k+1段，分别指向k+1个儿子，同时满足查找树的大小关系。 如图为一个M=4的B树 依次插入6 10 4 14 5 11 15 3 2 12 1 7 8 8 6 3 6 21 5 15 15 6 32 23 45 65 7 8 6 5 4B树的演示图片 B+tree的特点b+tree是b-tree的一种变形,在B树的基础上有如下新特点 有k个子结点的结点必然有k个关键码； 非叶结点仅具有索引作用，跟记录有关的信息均存放在叶结点中。 树的所有叶结点构成一个有序链表，可以按照关键码排序的次序遍历全部记录。 如图为一个M=4的B+树 B+树的插入演示 相较于B树,B+树的非叶子结点只包含导航信息,不包含实际的值,所有的叶子结点和相连的节点使用链表相连，便于区间查找和遍历。但B树的每一个节点都包含key和value，因此经常访问的元素可能离根节点更近，因此访问也更迅速。 MyISAM的索引和InnoDB索引一 、MyISAM的索引MyISAM的索引方式是“非聚集”索引。MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址。MyISAM引擎使用B+Tree作为索引结构，叶节点的data域存放的是*数据记录的地址*。 1. MyISam主索引 如图一共有三列，假设我们以Col1为主键，以col1构造B+树。B+树的叶子节点上保存的是该记录的地址，可以理解为该行数据的物理存储位置。 2. MyISam辅助索引在MyISAM中，主索引和辅助索引（Secondary key）在结构上没有任何区别，只是主索引要求key是唯一的，而辅助索引的key可以重复。 如图，在col2上建立辅助索引，则以col2构造B+树，B+树的叶子节点上保存的是该记录的地址。 二、InnoDB索引在InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。 1. InnoDB主索引因为InnoDB的数据文件本身要按主键聚集，所以InnoDB要求表必须有主键（MyISAM可以没有），如果没有显式指定，则MySQL系统会自动选择一个可以唯一标识数据记录的列作为主键，如果不存在这种列，则MySQL自动为InnoDB表生成一个隐含字段作为主键，这个字段长度为6个字节，类型为长整形. 如图，主键是col1，则根据col1构造B+树,整个数据行其实就存在B+树的叶子上。 2. InnoDB的辅助索引InnoDB的辅助索引data域存储相应记录主键的值而不是地址。 如图在col3上建立辅助索引，则根据col3构造B+树，B+树的叶节点存的是该行的主键，即col1的值。 在Innodb中，聚集索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录。 最左前匹配原则在mysql建立联合索引时会遵循最左前缀匹配的原则，即最左优先，在检索数据时从联合索引的最左边开始匹配，示例：对列col1、列col2和列col3建一个联合索引 1KEY test_col1_col2_col3 on test(col1,col2,col3); 联合索引 test_col1_col2_col3 实际建立了(col1)、(col1,col2)、(col,col2,col3)三个索引。 1SELECT * FROM test WHERE col1=“1” AND clo2=“2” AND clo4=“4” 上面这个查询语句执行时会依照最左前缀匹配原则，检索时会使用索引(col1,col2)进行数据匹配。 SELECT FROM test WHERE clo2=“2”*会触发索引么,答案是会的,只是触发的类型为index,表示msql会对整个索引进行扫描,只要是索引或者某个联合索引的一部分,mysql会从索引中的一个数据一个个查找到最后一个数据,直到找到符合判断条件的某个索引。 12EXPLAIN SELECT * FROM test WHERE col2=2; --type=indexEXPLAIN SELECT * FROM test WHERE col1=1; --type=ref index：Full Index Scan，index与ALL区别为index类型只遍历索引树 ref：表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值 对于Explain中Type字段的说明 typetype显示的是访问类型，是较为重要的一个指标，结果值从好到坏依次是：system &gt; const &gt; eq_ref &gt; ref &gt; fulltext &gt; ref_or_null &gt; index_merge &gt; unique_subquery &gt; index_subquery &gt; range &gt; index &gt; ALL ，一般来说，得保证查询至少达到range级别，最好能达到ref。 类型 说明 All 最坏的情况,全表扫描 index 和全表扫描一样。只是扫描表的时候按照索引次序进行而不是行。主要优点就是避免了排序, 但是开销仍然非常大。如在Extra列看到Using index，说明正在使用覆盖索引，只扫描索引的数据，它比按索引次序全表扫描的开销要小很多 range 范围扫描，一个有限制的索引扫描。key 列显示使用了哪个索引。当使用=、 &lt;&gt;、&gt;、&gt;=、&lt;、&lt;=、IS NULL、&lt;=&gt;、BETWEEN 或者 IN 操作符,用常量比较关键字列时,可以使用 range ref 一种索引访问，它返回所有匹配某个单个值的行。此类索引访问只有当使用非唯一性索引或唯一性索引非唯一性前缀时才会发生。这个类型跟eq_ref不同的是，它用在关联操作只使用了索引的最左前缀，或者索引不是UNIQUE和PRIMARY KEY。ref可以用于使用=或&lt;=&gt;操作符的带索引的列。 eq_ref 最多只返回一条符合条件的记录。使用唯一性索引或主键查找时会发生 （高效） const 当确定最多只会有一行匹配的时候，MySQL优化器会在查询前读取它而且只读取一次，因此非常快。当主键放入where子句时，mysql把这个查询转为一个常量（高效） system 这是const连接类型的一种特例，表仅有一行满足条件。 Null 意味说mysql能在优化阶段分解查询语句，在执行阶段甚至用不到访问表或索引（高效） 结果值从好到坏依次是：system &gt; const &gt; eq_ref &gt; ref &gt; fulltext &gt; ref_or_null &gt; index_merge &gt; unique_subquery &gt; index_subquery &gt; range &gt; index &gt; ALL 回顾通过上面的了解,我们可以大概明白开始的几个问题,对于常用的InnoDB的索引,不建议使用过长的字段作为主键,因为对于InnoDB所有辅助索引的子节点数据都是引用主索引,若主索引过大会令辅助索引变得过大,十分占用索引文件。而一般用自增是因为InnoDB数据文件本身是一个B+树,非单调的主键会造成在插入新记录的时候为维持B+tree的数据单调而频繁的移动位置和页分裂调整。 参考Mysql联合索引最左匹配原则 MySQL索引背后的数据结构及算法原理]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java多线程]]></title>
    <url>%2F2019%2F02%2F02%2Fsenssic.github.io%2F201902%2Fjava%E5%A4%9A%E7%BA%BF%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[java多线程编程进程与线程 进程是资源分配的最小单位,线程是程序执行的最小单位。 进程:进程是程序执行的一个实例，系统进行资源分配和调度的一个独立单位，是担当资源分配的最小单位； 线程:线程是进程的一个执行流,是CPU调度和分派的基本单位。一个线程就是一个独立的栈结构，每个进程至少有一个线程。 1) New新建状态：当程序使用 new 关键字创建了一个线程后，该线程就处于新建状态，此时线程还未启动（此时还是一个普通的对象）； 2) Runnable就绪状态：一个新创建的线程并不自动开始运行，要执行线程，必须调用线程的 start() 方法（这时才是一个真正的线程而不是普通对象）；当线程对象调用 start() 方法即启动了线程，start() 方法创建线程运行的系统资源，并调度线程运行 run() 方法；当 start() 方法返回后，线程就处于就绪状态；处于就绪状态的线程并不一定立即运行 run() 方法，线程还必须同其它线程竞争 CPU 时间，只有获得 CPU 时间才可以运行线程；因为在单 CPU 的计算机系统中，不可能同时运行多个线程，一个时刻仅有一个线程处于运行状态；因此此时可能有多个线程处于就绪状态；对多个处于就绪状态的线程是由 Java 运行时系统的线程调度程序来调度的； 3) Running运行状态：当线程获得 CPU 时间后，它才进入运行状态，真正开始执行 run() 方法（此时线程获得 CPU 时间片，真正开始运行）； 4) Block阻塞状态：线程运行过程中，可能由于各种原因进入阻塞（等待）状态： 线程通过调用 sleep() 方法进入睡眠状态；线程通过调用 suspend() 方法而被挂起；线程调用一个在 I/O 上被阻塞的操作；线程试图得到一个锁，而该锁正被其它线程持有；线程在等待某个触发条件（条件变量）；所谓阻塞状态是正在运行的线程没有运行结束，暂时让出 CPU，这时其它处于就绪状态的线程就可以获得 CPU 时间，进入运行状态； 5) Dead死亡状态：有两个原因会导致线程死亡： run() 方法正常退出而自然死亡；一个未捕获的异常终止了 run() 方法而使线程猝死；为了确定线程在当前是否存活着（就是要么是可运行的，要么是被阻塞了），需要使用 isAlive() 方法，如果还存活则返回 true；如果试图对一个已经死亡的线程调用 start() 方法，那么在程序运行期间将会抛出 IllegalThreadStateException 运行时异常。 睡眠、挂起、阻塞 睡眠，即调用线程的 sleep() 方法，主动行为，不过因为睡眠有一个时长，时间到了就会自动苏醒；挂起，可以是主动（调用线程的 suspend() 方法）也可以是被动（被线程调度程序挂起），手动挂起需要手动恢复（调用线程的 resume() 方法）；阻塞，被动，是线程在等待某种事件或者资源（如等待对象锁、等待条件变量、等待 I/O 操作完成）的表现，一旦获得所需资源或者事件信息就自动回到就绪态。睡眠和挂起是两种行为，阻塞则是一种状态；睡眠和挂起的结果就是变成阻塞状态。 线程交互线程的交互可以理解为线程之间的通信，通过 Object 类的 wait()、notify()、notifyAll() 方法进行线程通信； 竞态条件 &amp; 临界区当两个线程竞争同一资源时，如果对资源的访问顺序敏感，就称存在竞态条件；导致竞态条件发生的代码区称作临界区； 线程死锁所谓死锁，是指多个线程在运行过程中因争夺资源而造成的一种僵局(DeadlyEmbreace)，即互相等待的现象，当线程处于这种僵持状态时，若无外力作用，它们都将无法向前推进； 典型的例子：线程 A 获得了锁 1，线程 B 获得了锁 2；这时线程 A 调用 lock 试图获得锁 2，结果是需要挂起等待线程 B 释放锁 2，而这时线程 B 也调用 lock 试图获得锁 1，结果是需要挂起等待线程 A 释放锁 1，于是线程 A 和 B 都永远处于挂起状态了； 产生死锁的必要条件虽然线程在运行过程中可能发生死锁，但死锁的发生也必须具备一定的条件：1) 互斥条件：指线程对所分配的资源进行排它性使用，即在一段时间内某资源只由一个线程占用；如果此时还有其它线程请求该资源，则请求者只能等待，直至占有该资源的线程释放；2) 请求和保持条件：指线程已经保持了至少一个资源，但又提出了新的资源请求，而该资源又被其它线程占有，或者已经拥有了该资源却又再次请求，此时请求线程阻塞，但又对自己已获得的资源保持不放；3) 不剥夺条件：指线程在已获得的资源，在未使用完之前，不能被剥夺，只能在使用完时由自己释放；4) 环路等待条件：指在发生死锁时，必然存在一个 线程–资源 的环形链，即线程集合{P0, P1, P2, ... Pn}中的 P0 正在等待 P1 占用的资源；P1 正在等待 P2 占用的资源，……，Pn 正在等待已被 P0 占用的资源； 处理死锁的基本方法为保证系统中诸线程的正常运行，应事先采取必要的措施，来预防发生死锁；在系统中已经出现死锁后，则应及时检测到死锁的发生，并应采取适当的措施来解除死锁；目前，处理死锁的方法可归结为以下四种： 1) 预防死锁：这是一种较简单和直观的方法；该方法是通过设置某些限制条件，去破坏产生死锁的四个必要条件中的一个或几个，来预防发生死锁；但由于所施加的限制条件往往太严格，因而会导致系统资源利用率和系统吞吐量低； 2) 避免死锁：该方法同样是属于事先预防的策略，但它并不须事先采取各种限制措施去破坏产生死锁的四个必要条件，而是在资源的动态分配过程中，用某种方法去防止系统进入不安全状态，从而避免发生死锁；这种方法只需事先施加较弱的限制条件，便可获得较高的资源利用率及系统吞吐量，但在事实上有一定的难度；目前在较完善的系统中常用此方法来避免发生死锁； 3) 检测死锁：这种方法并不须事先采取任何限制性措施，也不必检查系统是否已经进入不安全区，而是允许系统在运行过程中发生死锁；但可通过系统所设置的检测机构，及时的检测出死锁的发生，并精确地确定与死锁有关的线程和资源；然后采取适当措施，从系统中将已发生的死锁清除掉； 4) 解除死锁：这是与检测死锁相配套的一种措施；当检测到系统中已发生死锁时，须将线程从死锁状态中解脱出来；常用的实施方法是撤销或挂起一些线程，以便回收一些资源，再将这些资源分配给已处于阻塞状态的线程，是之转为就绪状态，以继续运行；死锁的检测和解除措施有可能使系统获得较好的资源利用率和吞吐量，但在实现上难度也最大； ThreadLocalThreadLocal 是一个泛型类，位于 java.lang 包。ThreadLocal，看名字就知道，”线程本地变量”、”线程局部变量”。 ThreadLocal 的作用是提供线程内的局部变量，这种变量在线程的生命周期内起作用，减少同一个线程内多个函数或者组件之间一些公共变量的传递的复杂度。 synchronized：以时间换空间，只提供一份变量，让不同的线程排队访问；ThreadLocal：以空间换时间，为每个线程都创建一个变量副本，因此可以同时访问而互不影响。 synchronized 用于线程间的数据共享，而 ThreadLocal 则用于线程间的数据隔离。 ThreadLocal 实现原理 每个 Thread 对象中都有一个ThreadLocal.ThreadLocalMap threadLocals = null成员，ThreadLocalMap 就是一个普通的 Map，Key 为 ThreadLocal 类，Value 则为 Object 类；因此每个线程可以同时维护多个 ThreadLocal - Object 键值对。 ThreadLocalMap 的 Key 是弱引用对象（如果一个对象只存在弱引用，那么它随时都会被 GC）；而 Value 则是强引用的；为了避免内存泄漏，在get()、set()、remove()方法内部会自动清理所有 Key 为 null 的 Value；当然还是建议使用 remove() 来显式的释放。 ThreadLocal 使用建议 ThreadLocal 应定义为静态成员变量； 能通过传值传递的参数，不要通过 ThreadLocal 存储，以免造成 ThreadLocal 的滥用； 在使用线程池的情况下，当业务周期处理完成时，最好显式的调用 remove() 方法，清空旧值。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker的maven插件使用]]></title>
    <url>%2F2019%2F01%2F06%2Fsenssic.github.io%2F201901%2Fdocker%E7%9A%84maven%E6%8F%92%E4%BB%B6%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[搭建docker私有仓库创建私有仓库 拉取仓库镜像 docker pull registry 启动仓库镜像 docker run ‐di ‐‐name=registry ‐p 5000:5000 registry 修改daemon.json,让docker信任私有仓库地址 vi /etc/docker/daemon.json 添加 {&quot;insecure‐registries&quot;:[&quot;127.0.0.1:5000&quot;]} 重启docker服务 systemctl restart docker 镜像上传到私有仓库为了验证私有仓库搭建以及能正常上传到私有仓库,新建tag并尝试push镜像 标记此镜像为私有仓库的镜像 docker tag java:8 127.0.0.1:5000/jdk1.8 注意:java:8为本身已经存在的镜像 再次启动私服容器 docker start registry 上传标记的镜像 docker push 127.0.0.1:5000/jdk1.8 从私有仓库拉取pull的时候记得带”主机IP:5000”,不然还是去Docker hub上下载而不是私有仓库下载 docker pull 127.0.0.1:5000/xxx/xxx Docker 私有仓库安装配置 (Registry v2) docker的maven插件使用生成TLS认证远程访问 Docker需要生成三种证书类型: CA 证书用来生成客户端和服务端证书 远端Docker使用的客户端生疏 服务端使用的Docker daemon证书 服务端配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263# 生成 CA 私钥$ openssl genrsa -aes256 -out ca-key.pem 4096# 需要输入两次密码(自定义)# 生成 CA 公钥$ openssl req -new -x509 -days 365 -key ca-key.pem -sha256 -out ca.pem# 输入上一步中设置的密码，然后需要填写一些信息# 下面是服务器证书生成# 生成服务器私钥$ openssl genrsa -out server-key.pem 4096# 用私钥生成证书请求文件$ openssl req -subj &quot;/CN=localhost&quot; -sha256 -new -key server-key.pem -out server.csr$ echo subjectAltName = DNS:localhost,DNS:www.khs1994.com,DNS:tencent,IP:192.168.199.100,IP:192.168.57.110,IP:127.0.0.1 &gt;&gt; extfile.cnf# 允许服务端哪些 IP 或 host 能被客户端连接，下文会进行测试。# DNS 我也不是很理解，这里配置 localhost ，公共 DNS 解析的域名，/etc/hosts 文件中的列表进行测试。$ echo extendedKeyUsage = serverAuth &gt;&gt; extfile.cnf# 用 CA 来签署证书$ openssl x509 -req -days 365 -sha256 -in server.csr -CA ca.pem -CAkey ca-key.pem \ -CAcreateserial -out server-cert.pem -extfile extfile.cnf# 再次输入第一步设置的密码# 下面是客户端证书文件生成# 生成客户端私钥$ openssl genrsa -out key.pem 4096# 用私钥生成证书请求文件 $ openssl req -subj &apos;/CN=client&apos; -new -key key.pem -out client.csr$ echo extendedKeyUsage = clientAuth &gt;&gt; extfile.cnf# 用 CA 来签署证书$ openssl x509 -req -days 365 -sha256 -in client.csr -CA ca.pem -CAkey ca-key.pem \ -CAcreateserial -out cert.pem -extfile extfile.cnf# 再次输入第一步设置的密码# 删除文件，更改文件权限$ rm -v client.csr server.csr$ chmod -v 0400 ca-key.pem key.pem server-key.pem$ chmod -v 0444 ca.pem server-cert.pem cert.pem 把 ca.pem server-cert.pem server-key.pem 三个文件移动到 /etc/docker/ 文件夹中。 在远端配置Docker配置/etc/docker/daemon.json文件如下,注意,镜像地址与本文无关,可不配置 1234567&quot;insecure-registries&quot;:[&quot;127.0.0.1:5000&quot;], &quot;tlsverify&quot;: true, &quot;tlscacert&quot;: &quot;/etc/docker/ca.pem&quot;, &quot;tlscert&quot;: &quot;/etc/docker/server-cert.pem&quot;, &quot;tlskey&quot;: &quot;/etc/docker/server-key.pem&quot;, &quot;hosts&quot;: [&quot;tcp://0.0.0.0:2376&quot;,&quot;unix:///var/run/docker.sock&quot;]&#125; CoreOS 官方文档的方法首先需要修改 /etc/systemd/system/docker-tcp.socket 文件内容 12345ListenStream=2375# 修改为ListenStream=2376 重新启动服务器 1234$ sudo systemctl daemon-reload$ sudo systemctl stop docker$ sudo systemctl restart docker-tcp.socket$ sudo systemctl restart docker 将 ca.pem cert.pem key.pem下载到客户端,放置到~/.docker目录下 运行测试命令 docker –tlsverify -H=tcp://207.246.117.90:2376 info Maven插件自动部署步123456789101112131415161718192021&lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;docker-maven-plugin&lt;/artifactId&gt; &lt;version&gt;0.4.13&lt;/version&gt; &lt;configuration&gt; &lt;imageName&gt;127.0.0.1:5000/$&#123;docker.image.prefix&#125;/$&#123;project.artifactId&#125; &lt;/imageName&gt; &lt;baseImage&gt;java:8&lt;/baseImage&gt; &lt;entryPoint&gt;["java", "-jar", "/$&#123;project.build.finalName&#125;.jar"]&lt;/entryPoint&gt; &lt;!--&lt;dockerDirectory&gt;$&#123;project.basedir&#125;/src/main/docker&lt;/dockerDirectory&gt;--&gt; &lt;resources&gt; &lt;resource&gt; &lt;targetPath&gt;/&lt;/targetPath&gt; &lt;directory&gt;$&#123;project.build.directory&#125;&lt;/directory&gt; &lt;include&gt;$&#123;project.build.finalName&#125;.jar&lt;/include&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;dockerHost&gt;http://207.246.117.90:2375&lt;/dockerHost&gt; &lt;dockerCertPath&gt;/Users/senssic/.docker/&lt;/dockerCertPath&gt; &lt;/configuration&gt;&lt;/plugin&gt; 可以看到执行成功 123456789101112131415Step 1/3 : FROM java:8 ---&gt; d23bdf5b1b1bStep 2/3 : ADD /sc-whorl-web-1.0.1-SNAPSHOT.jar // ---&gt; 274070714038Step 3/3 : ENTRYPOINT [&quot;java&quot;, &quot;-jar&quot;, &quot;/sc-whorl-web-1.0.1-SNAPSHOT.jar&quot;] ---&gt; Running in bff8020fa0f3Removing intermediate container bff8020fa0f3 ---&gt; 1f1b1b0ca7a5ProgressMessage&#123;id=null, status=null, stream=null, error=null, progress=null, progressDetail=null&#125;Successfully built 1f1b1b0ca7a5Successfully tagged 127.0.0.1:5000/sc-whorl/sc-whorl-web:latest[INFO] Built 127.0.0.1:5000/sc-whorl/sc-whorl-web 参考： Docker 远程连接 – dockerd 命令详解]]></content>
      <categories>
        <category>插件</category>
      </categories>
      <tags>
        <tag>maven</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[杂记文档]]></title>
    <url>%2F2018%2F10%2F15%2Fsenssic.github.io%2F201901%2F%E6%9D%82%E8%AE%B0%E6%96%87%E6%A1%A3%2F</url>
    <content type="text"><![CDATA[缓存队列相关1.为什么使用mq？mq的优点？解耦,异步,削峰(可以限流发送或接收) 2.mq的缺点有哪些？系统可用性降低(mq挂掉),数据丢失问题,一致性问题,消息顺序问题,消息积压,消息重复问题等需要考虑，导致系统复杂性增加。 3.主流MQ框架的对比 特性 ActiveMQ RabbitMQ RocketMQ Kafka 单机吞吐量 万级，吞吐量比RocketMQ和Kafka要低了一个数量级 万级，吞吐量比RocketMQ和Kafka要低了一个数量级 10万级，RocketMQ也是可以支撑高吞吐的一种MQ 10万级别，这是kafka最大的优点，就是吞吐量高。 一般配合大数据类的系统来进行实时数据计算、日志采集等场景 topic数量对吞吐量的影响 topic可以达到几百，几千个的级别，吞吐量会有较小幅度的下降 这是RocketMQ的一大优势，在同等机器下，可以支撑大量的topic topic从几十个到几百个的时候，吞吐量会大幅度下降 所以在同等机器下，kafka尽量保证topic数量不要过多。如果要支撑大规模topic，需要增加更多的机器资源 时效性 ms级 微秒级，这是rabbitmq的一大特点，延迟是最低的 ms级 延迟在ms级以内 可用性 高，基于主从架构实现高可用性 高，基于主从架构实现高可用性 非常高，分布式架构 非常高，kafka是分布式的，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用 消息可靠性 有较低的概率丢失数据 经过参数优化配置，可以做到0丢失 经过参数优化配置，消息可以做到0丢失 功能支持 MQ领域的功能极其完备 基于erlang开发，所以并发能力很强，性能极其好，延时很低 MQ功能较为完善，还是分布式的，扩展性好 功能较为简单，主要支持简单的MQ功能，在大数据领域的实时计算以及日志采集被大规模使用，是事实上的标准 优劣势总结 非常成熟，功能强大，在业内大量的公司以及项目中都有应用 偶尔会有较低概率丢失消息 而且现在社区以及国内应用都越来越少，官方社区现在对ActiveMQ 5.x维护越来越少，几个月才发布一个版本 而且确实主要是基于解耦和异步来用的，较少在大规模吞吐的场景中使用 erlang语言开发，性能极其好，延时很低； 吞吐量到万级，MQ功能比较完备 而且开源提供的管理界面非常棒，用起来很好用 社区相对比较活跃，几乎每个月都发布几个版本分 在国内一些互联网公司近几年用rabbitmq也比较多一些 但是问题也是显而易见的，RabbitMQ确实吞吐量会低一些，这是因为他做的实现机制比较重。 而且erlang开发，国内有几个公司有实力做erlang源码级别的研究和定制？如果说你没这个实力的话，确实偶尔会有一些问题，你很难去看懂源码，你公司对这个东西的掌控很弱，基本职能依赖于开源社区的快速维护和修复bug。 而且rabbitmq集群动态扩展会很麻烦，不过这个我觉得还好。其实主要是erlang语言本身带来的问题。很难读源码，很难定制和掌控。 接口简单易用，而且毕竟在阿里大规模应用过，有阿里品牌保障 日处理消息上百亿之多，可以做到大规模吞吐，性能也非常好，分布式扩展也很方便，社区维护还可以，可靠性和可用性都是ok的，还可以支撑大规模的topic数量，支持复杂MQ业务场景 而且一个很大的优势在于，阿里出品都是java系的，我们可以自己阅读源码，定制自己公司的MQ，可以掌控 社区活跃度相对较为一般，不过也还可以，文档相对来说简单一些，然后接口这块不是按照标准JMS规范走的有些系统要迁移需要修改大量代码 还有就是阿里出台的技术，你得做好这个技术万一被抛弃，社区黄掉的风险，那如果你们公司有技术实力我觉得用RocketMQ挺好的 kafka的特点其实很明显，就是仅仅提供较少的核心功能，但是提供超高的吞吐量，ms级的延迟，极高的可用性以及可靠性，而且分布式可以任意扩展 同时kafka最好是支撑较少的topic数量即可，保证其超高吞吐量 而且kafka唯一的一点劣势是有可能消息重复消费，那么对数据准确性会造成极其轻微的影响，在大数据领域中以及日志采集中，这点轻微影响可以忽略 这个特性天然适合大数据实时计算以及日志收集 不过现在确实越来越多的公司，会去用RocketMQ，确实很不错，但是我提醒一下自己想好社区万一突然黄掉的风险，对自己公司技术实力有绝对自信的，我推荐用RocketMQ，否则回去老老实实用RabbitMQ吧，人是活跃开源社区，绝对不会黄 所以中小型公司，技术实力较为一般，技术挑战不是特别高，用RabbitMQ是不错的选择；大型公司，基础架构研发实力较强，用RocketMQ是很好的选择 如果是大数据领域的实时计算、日志采集等场景，用Kafka是业内标准的，绝对没问题，社区活跃度很高，绝对不会黄，何况几乎是全世界这个领域的事实性规范 4.mq的高可用模式 RabbitMQ的高可用性 rabbitmq有三种模式：单机模式，普通集群模式，镜像集群模式 单机模式 一般就是你本地启动了玩玩儿的，没人生产用单机模式 普通集群模式 在多台机器上启动多个rabbitmq实例，每个机器启动一个。但是你创建的queue，只会放在一个rabbtimq实例上，但是每个实例都同步queue的元数据。消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从queue所在实例上拉取数据过来。 这种方式非真正的集群,没有高可用,实例节点挂掉mq就会不可用,只是提高了连接的吞吐量,而且由于数据位于不同的实例上,当访问不在连接的实例上会有很多这样的mq内部通讯。 镜像集群模式 真正的rabbitmq的高可用模式，跟普通集群模式不一样的是，创建的queue，无论元数据还是queue里的消息都会存在于多个实例上，每次写消息到queue的时候，都会自动把消息到多个实例的queue里进行消息同步。 坏处在于，第一，性能开销也大，消息同步所有机器，导致网络带宽压力和消耗很重！第二，就没有扩展性可言了，如果某个queue负载很重，加机器，新增的机器也包含了这个queue的所有数据，并没有办法线性扩展的queue kafka的高可用性 kafka一个最基本的架构认识：多个broker组成，每个broker是一个节点；创建一个topic，这个topic可以划分为多个partition，每个partition可以存在于不同的broker上，每个partition就放一部分数据。 这是天然的分布式消息队列，就是说一个topic的数据，是分散放在多个机器上的，每个机器就放一部分数据。 实际上rabbitmq之类的，并不是分布式消息队列，他就是传统的消息队列，只不过提供了一些集群、HA的机制，因为无论怎么玩，rabbitmq一个queue的数据都是放在一个节点里的，镜像集群下，也是每个节点都放这个queue的完整数据。 kafka 0.8以前，是没有HA机制的，就是任何一个broker宕机了，那个broker上的partition就废了，没法写也没法读，没有什么高可用性可言。 kafka 0.8以后，提供了HA机制，就是replica副本机制。每个partition的数据都会同步到其他机器上，形成自己的多个replica副本。然后所有replica会选举一个leader出来，那么生产和消费都跟这个leader打交道，然后其他replica就是follower。写的时候，leader会负责把数据同步到所有follower上去，读的时候就直接读leader上数据即可。只能读写leader？很简单，要是你可以随意读写每个follower，那么就要care数据一致性的问题，系统复杂度太高，很容易出问题。kafka会均匀的将一个partition的所有replica分布在不同的机器上，这样才可以提高容错性。如果某个broker宕机了，没事儿，那个broker上面的partition在其他机器上都有副本的，如果这上面有某个partition的leader，那么此时会重新选举一个新的leader出来，大家继续读写那个新的leader即可。这就有所谓的高可用性了。 写数据的时候，生产者就写leader，然后leader将数据落地写本地磁盘，接着其他follower自己主动从leader来pull数据。一旦所有follower同步好数据了，就会发送ack给leader，leader收到所有follower的ack之后，就会返回写成功的消息给生产者。（当然，这只是其中一种模式，还可以适当调整这个行为） 消费的时候，只会从leader去读，但是只有一个消息已经被所有follower都同步成功返回ack的时候，这个消息才会被消费者读到。 5.消息重复的处理​ 一般mq是不保证发送消息的重复,有极低的概率可能会消息重复.需要靠业务自己保证幂性的,一般使用数据库,redis等来判断幂等。 6.消息丢失情况分析 rabbitmq 生产者弄丢数据 因为网络或其他通讯原因,数据半路可能丢失,一般通过 开启事务（channel.txSelect），然后发送消息，如果消息没有成功被rabbitmq接收到，那么生产者会收到异常报错，此时就可以回滚事务（channel.txRollback），然后重试发送消息；如果收到了消息，那么可以提交事务（channel.txCommit）。但是问题是，rabbitmq事务机制一搞，基本上吞吐量会下来，因为太耗性能。 开启confirm模式，每次写的消息都会分配一个唯一的id，然后如果写入了rabbitmq中，rabbitmq会给你回传一个ack消息，告诉你说这个消息ok了。如果rabbitmq没能处理这个消息，会回调你一个nack接口，告诉你这个消息接收失败，你可以重试。因为确认模式是异步的,所以一般发送端消息丢失都是使用开启confirm模式进行处理避免消息丢失。 rabbitmq弄丢了数据 一般必须开始rabbitmq持久化,这样就算mq挂了,也可以读取之前存储的数据,一般不会丢失,当然也有极其罕见的情况数据还未写入磁盘mq挂了导致的数据丢失,这种概率极低。 设置持久化有两个步骤 第一个是创建queue的时候将其设置为持久化的，这样就可以保证rabbitmq持久化queue的元数据，但是不会持久化queue里的数据； 第二个是发送消息的时候将消息的deliveryMode设置为2，就是将消息设置为持久化的，此时rabbitmq就会将消息持久化到磁盘上去。必须要同时设置这两个持久化才行，rabbitmq哪怕是挂了，再次重启，也会从磁盘上重启恢复queue，恢复这个queue里的数据。 而且持久化可以跟生产者那边的confirm机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者ack了，所以哪怕是在持久化到磁盘之前，rabbitmq挂了，数据丢了，生产者收不到ack，你也是可以自己重发的。 消费端弄丢了数据 一般使用rabbitmq提供的手动ack机制,未被ack的消息,mq会重复进行投递(死信队列). kafka 消费者丢失数据 如果设置为消费者自动提交offset,此时你刚接到消息还未处理,此消息可能就丢失了,一般的做法是关闭自动提交offset，在处理完之后自己手动提交offset，就可以保证数据不会丢。 kafka数据丢失 kafka某个broker宕机，然后重新选举partiton的leader时。此时其他的follower刚好还有些数据没有同步，结果此时leader挂了，然后选举某个follower成leader之后，就少了一些数据。 此时一般是要求起码设置如下4个参数： 给这个topic设置replication.factor参数：这个值必须大于1，要求每个partition必须有至少2个副本 在kafka服务端设置min.insync.replicas参数：这个值必须大于1，这个是要求一个leader至少感知到有至少一个follower还跟自己保持联系，没掉队，这样才能确保leader挂了还有一个follower吧 在producer端设置acks=all：这个是要求每条数据，必须是写入所有replica之后，才能认为是写成功了 在producer端设置retries=MAX（很大很大很大的一个值，无限次重试的意思）：这个是要求一旦写入失败，就无限重试，卡在这里了 这样配置之后，至少在kafka broker端就可以保证在leader所在broker发生故障，进行leader切换时，数据不会丢失 生产者不会丢数据 如果按照上述的思路设置了ack=all，一定不会丢，你的leader接收到消息，所有的follower都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者会自动不断的重试，重试无限次。 7.保证消息的顺序性​ 场景：比如下单操作，下单成功之后，会发布创建订单和扣减库存消息，但扣减库存消息执行会先于创建订单消息，也就说前者执行成功之后，才能执行后者。 ​ 在 MQ 层面支持消息的顺序处理开销太大，为了极少量的需求，增加整体上的复杂度得不偿失。 所以，还是在应用层面处理比较好，或者业务逻辑进行处理。 应用层解决方式： 1. 消息实体中增加：版本号 &amp; 状态机 &amp; msgid &amp; parent_msgid，通过 parent_msgid 判断消息的顺序（需要全局存储，记录消息的执行状态）。当处理完后更新parent_msgid然后触发mq重试机制,继续其他消费 2. “同步执行”：当一个消息执行完之后，再发布下一个消息。 3.确保只有一个消费者消费,消费者内部使用队列,然后启动多个线程消费队列。 8.处理消息积压​ 由于某些业务场景导致有些队列没有被消费(消费者挂了,或者消费能力弱),一般处理的方式有如下方式. 消费者积极扩容,当发现百万级的消息积压,首先是先把消费者逻辑处理给修正,想办法临时扩容消费者,加大消费者的处理吞吐量 1）先修复consumer的问题，确保其恢复消费速度，然后将现有cnosumer都停掉 2）新建一个topic，partition是原来的10倍，临时建立好原先10倍或者20倍的queue数量 3）然后写一个临时的分发数据的consumer程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的10倍数量的queue 4）接着临时征用10倍的机器来部署consumer，每一批consumer消费一个临时queue的数据 5）这种做法相当于是临时将queue资源和consumer资源扩大10倍，以正常的10倍速度来消费数据 6）等快速消费完积压数据之后，得恢复原先部署架构，重新用原先的consumer机器来消费消息 对于一些消息已被超时丢弃(一般线上不允许设置小时超时),只能通过补录丢失的消息了,在高峰期过后,一点点的将业务数据查询出来,在低谷的时候写个程序模拟生产消息。 这里还是要提醒,要有主动监控消息积压的流程,当发生消息积压的初期就及时处理,如果发现对业务不影响的消息还可以直接删除。 分布式搜索引擎es的基础知识 倒排索引 也常被称为反向索引、置入档案或反向档案，是一种索引方法，被用来存储在全文搜索下某个单词在一个文档或者一组文档中的存储位置的映射。它是文档检索系统中最常用的数据结构。 ES索引 ES一些概念和数据库进行对比 Relational DB -&gt; Databases -&gt; Tables -&gt; Rows -&gt; Columns Elasticsearch -&gt; Index -&gt; Types -&gt; Documents -&gt; Fields es分布式结构 一个索引可以拆分成多个shard,每个shard存储部分数据。就是说每个shard都有一primary shard，负责写入数据，还有一个或多个replica shard。primary shard写入数据之后,会将数据同步到其他replica shard上去。 es分布式master节点 es集群多个节点,会自动选举一个节点为master节点,主要负责管理工作,维护索引元数据拉,切换primary shard和replica shard身份之类。要是master节点宕机了,会重新选举一个节点为master节点。 es分布式非master master节点会让宕机节点上的primary shard的身份转移到其他一个机器上的replica shard。宕机节点重启之后,master节点会控制将缺失的replica shard分配过去,同步后续修改的数据,让集群恢复正常。 es的工作原理 es写数据过程 1）客户端选择一个node发送请求过去,这个node就被称作coordinating node（协调节点） 2）coordinating node,对document进行路由,将请求转发给对应的node（有primary shard） 3）实际的node上的primary shard处理请求,然后将数据同步到replica node 4）coordinating node,如果发现primary node和所有replica node都处理好之后,就返回响应结果给客户端 es读数据过程 当es写入一个docment时候,会自动给你分配一个全局唯一的doc id,同时es也是根据doc id进行hash路由到对应的primary shard上面去 1）客户端发送请求到任意一个node，成为coordinate node 2）coordinate node对document进行路由，将请求转发到对应的node，此时会使用round-robin随机轮询算法，在primary shard以及其所有replica中随机选择一个，让读请求负载均衡 3）接收请求的node返回document给coordinate node 4）coordinate node返回document给客户端 es搜索数据过程 1）客户端发送请求到一个coordinate node 2）协调节点将搜索请求转发到所有的shard对应的primary shard或replica shard也可以 3）query phase：每个shard将自己的搜索结果（其实就是一些doc id），返回给协调节点，由协调节点进行数据的合并、排序、分页等操作，产出最终结果 4）fetch phase：接着由协调节点，根据doc id去各个节点上拉取实际的document数据，最终返回给客户端 写数据底层原理 1）先写入buffer,在buffer里的时候数据是搜索不到的;同时将数据写入translog日志文件 2）如果buffer快满了,或者到一定时间,就会将buffer数据refresh到一个新的segment file中,但是此时数据不是直接进入segment file的磁盘文件的,而是先进入os cache的,这个过程就是refresh。每隔1秒钟，es将buffer中的数据写入一个新的segment file,每秒钟会产生一个新的磁盘文件,segment file,这个segment file中就存储最近1秒内buffer中写入的数据,但是如果buffer里面此时没有数据,不会执行refresh操作,每秒创建换一个空的segment file,如果buffer里面有数据,默认1秒钟执行一次refresh操作,刷入一个新的segment file中,操作系统里面,磁盘文件其实都有一个东西,叫做os cache,操作系统缓存,就是说数据写入磁盘文件之前,会先进入os cache,先进入操作系统级别的一个内存缓存中去,只要buffer中的数据被refresh操作,刷入os cache中，就代表这个数据就可以被搜索到了,内存 buffer 生成一个新的 segment，刷到文件系统缓存中，Lucene 即可检索这个新 segment,此时segment位于文件内存缓存中,为什么叫es是准实时的？NRT，near real-time,准实时。默认是每隔1秒refresh一次的,所以es是准实时的,因为写入的数据1秒之后才能被看到。可以通过es的restful api或者java api，手动执行一次refresh操作，就是手动将buffer中的数据刷入os cache中，让数据立马就可以被搜索到。只要数据被输入os cache中，buffer就会被清空了，因为不需要保留buffer了，数据在translog里面已经持久化到磁盘去一份了 3）只要数据进入os cache,此时就可以让这个segment file的数据对外提供搜索了 4）重复1~3步骤，新的数据不断进入buffer和translog,不断将buffer数据写入一个又一个新的segment file中去，每次refresh完buffer清空，translog保留。随着这个过程推进，translog会变得越来越大。当translog达到一定长度的时候，就会触发commit操作。buffer中的数据，每隔1秒就被刷到os cache中去，然后这个buffer就被清空了。所以说这个buffer的数据始终是可以保持住不会填满es进程的内存的。每次一条数据写入buffer,同时会写入一条日志到translog日志文件中去,所以这个translog日志文件是不断变大的,当translog日志文件大到一定程度的时候，就会执行commit操作。 5）commit操作发生第一步，就是将buffer中现有数据refresh到os cache中去，清空buffer 6）将一个commit point写入磁盘文件，里面标识着这个commit point对应的所有os cache内存segment file 7）强行将os cache中目前所有的数据都fsync到磁盘文件中去,translog日志文件的作用是什么？就是在你执行commit操作之前，数据要么是停留在buffer中，要么是停留在os cache中，无论是buffer还是os cache都是内存，一旦这台机器死了，内存中的数据就全丢了。所以需要将数据对应的操作写入一个专门的日志文件，translog日志文件中，一旦此时机器宕机，再次重启的时候，es会自动读取translog日志文件中的数据，恢复到内存buffer和os cache中去。 commit操作： 1、写commit point； 2、将os cache数据fsync强刷到磁盘上去； 3、清空translog日志文件 8）将现有的translog清空，然后再次重启启用一个translog，此时commit操作完成。默认每隔30分钟会自动执行一次commit，但是如果translog过大，也会触发commit。整个commit的过程，叫做flush操作。我们可以手动执行flush操作，就是将所有os cache数据刷到磁盘文件中去。不叫做commit操作，flush操作。es中的flush操作，就对应着commit的全过程。我们也可以通过es api，手动执行flush操作，手动将os cache中的数据fsync强刷到磁盘上去，记录一个commit point，清空translog日志文件。 9）translog其实也是先写入os cache的，默认每隔5秒刷一次到磁盘中去，所以默认情况下，可能有5秒的数据会仅仅停留在buffer或者translog文件的os cache中，如果此时机器挂了，会丢失5秒钟的数据。但是这样性能比较好，最多丢5秒的数据。也可以将translog设置成每次写操作必须是直接fsync到磁盘，但是性能会差很多。其实es第一是准实时的，数据写入1秒后可以搜索到；可能会丢失数据的，你的数据有5秒的数据，停留在buffer、translog os cache、segment file os cache中，有5秒的数据不在磁盘上，此时如果宕机，会导致5秒的数据丢失。如果你希望一定不能丢失数据的话，你可以设置个参数每次写入一条数据，都是写入buffer，同时写入磁盘上的translog，但是这会导致写性能、写入吞吐量会下降一个数量级。 Elasticsearch 2.0 新加入的特性。为了保证不丢数据，每次 index、bulk、delete、update 完成的时候，一定触发刷新 translog 到磁盘上，才给请求返回 200 OK。这个改变在提高数据安全性的同时当然也降低了一点性能。 10）如果是删除操作，commit的时候会生成一个.del文件，里面将某个doc标识为deleted状态，那么搜索的时候根据.del文件就知道这个doc被删除了 11）如果是更新操作，就是将原来的doc标识为deleted状态，然后新写入一条数据 12）buffer每次refresh一次，就会产生一个segment file，所以默认情况下是1秒钟一个segment file，segment file会越来越多，此时会定期执行merge 13）每次merge的时候，会将多个segment file合并成一个，同时这里会将标识为deleted的doc给物理删除掉，然后将新的segment file写入磁盘，这里会写一个commit point，标识所有新的segment file，然后打开segment file供搜索使用，同时删除旧的segment file。 es里的写流程，有4个底层的核心概念，refresh、flush、translog、merge,当segment file多到一定程度的时候，es就会自动触发merge操作，将多个segment file给merge成一个segment file。 es搜索的性能优化(几十亿)es搜索优化不是银弹,关键的底层性能影响就是内存的es缓存(filesystem cache) 增加filesystem cache的值设置足够大,确保es机器内存足够大,如果es未命中filesystem cache数据,会到磁盘中读取十分影响读取的性能。(filesystem cache尽量足够大) 尽量少的字段存放到es这样filesystem cache能更大存放es数据,真正大的数据存放到外部mysql或hbase中通过es中的关键字段到外置存储中查询。(filesystem cache尽量保留关键) 数据预热,如果实在是有数据被存放在了磁盘中,对于经常访问的数据,可以定时查询一下,保证filesystem cache中的都基本是热数据,提升体验。(filesystem cach尽量多存放热数据) 冷热分离,将热数据和冷数据尽量水平拆分,这样可以保证尽可能多的热数据位于filesystem cache中。(filesystem cach尽量多存放热数据) 优化document模型设计,对于原始数据有关联的结果,尽量在写入的时候就将结果写入,尽量避免使用复杂关联的查询。复杂的计算尽量在程序中做。(es尽量少的计算合并读取) 分页的优化,es的分页,分页深度越大越慢,因为是分布式存储数据,分页深度大的情况下,协调节点依然会将pagesize*pageindex的量的数据查询出来然后做合并排序等操作,再取出分页的数据。 对于不需要跳转,只需要一页一页下翻的分页,可以使用scroll api,其原理是使用了es数据快照,将查询出来的数据进行快照,然后通过游标一页一页的展示,缺点是无法指定页数以及页跳转。 分布式缓存为什么用缓存缓存缺点 一般用缓存是为了高并发或高性能 缓存的缺点 缓存击穿 缓存雪崩 缓存与数据库双写不一致 缓存并发竞争 redis缓存相关知识redis和memcache主要区别 redis支持丰富的数据类型,memcache只支持简单的key-value存储模式 redis是单线程对于小数据有很高的效率,memcache是多线程对于大数据存储可能效率高些 redis支持原生的集群高可用,而memcache没有高可用可能需要依赖客户端的分片写入 redis线程模型Redis 基于 Reactor 模式开发了自己的网络事件处理器[文件事件处理器(file event handler)] 文件事件处理器使用 I/O 多路复用（multiplexing）程序来同时监听多个套接字, 并根据套接字目前执行的任务来为套接字关联不同的事件处理器。当被监听的套接字准备好执行连接应答（accept）、读取（read）、写入（write）、关闭（close）等操作时， 与操作相对应的文件事件就会产生, 这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件。虽然文件事件处理器以单线程方式运行, 但通过使用 I/O 多路复用程序来监听多个套接字,文件事件处理器既实现了高性能的网络通信模型，,又可以很好地与 redis 服务器中其他同样以单线程方式运行的模块进行对接,保持了 Redis 内部单线程设计的简单性。 Redis 线程模型 redis单线程模型 BIO,NIO,AIO redis单线程模型高性能原因 纯内存操作 单线程避免多线程的上下文切换消耗 多路IO非阻塞模型,不同环境使用实现不一样(Solaries 10,linux epoll,mac os kqueue,select等) redis数据类型以及使用场景 string hash list set sorted set HyperLogLog-基数统计,有偏差 redis的过期策略和淘汰机制 过期策略,定期删除+惰性删除 redis检查过期key是通过定期随机检查[100ms,随机是因为如果是量很大的话100ms检测一遍会很消耗CPU所以使用随机定量key进行检测]和惰性检测[当再次访问key时判断是否过期] 淘汰机制,当reids内存存放的key很多很大的时候,会触发redis删除一些key[内存淘汰] 1）noeviction：当内存不足以容纳新写入数据时，新写入操作会报错，这个一般没人用 2）allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key（这个是最常用的） 3）allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key，这个一般没人用吧，为啥要随机，肯定是把最近最少使用的key给干掉啊 4）volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key（这个一般不太合适） 5）volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key 6）volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除 ​ redis高并发和高可用[现在可以直接使用redis集群进行读写的水平扩展]redis单机一般可支持5w~10w的QPS,再高的话就会有单机瓶颈,一般可以使用redis读写分离来水平扩展redis的读性能,master负责写入和同步多个slave数据,多个slave负责读取,这样的主从架构可以随时水平扩展进而可以支持高于10w的QPS。如果采用了主从架构必须开启master node的持久化, redis读写分离架构中的master和slave数据复制[现在一般不用这种架构而是使用redis集群架构]1、复制的完整流程 （1）slave node启动，仅仅保存master node的信息，包括master node的host和ip，但是复制流程没开始 master host和ip是从哪儿来的，redis.conf里面的slaveof配置的 （2）slave node内部有个定时任务，每秒检查是否有新的master node要连接和复制，如果发现，就跟master node建立socket网络连接（3）slave node发送ping命令给master node（4）口令认证，如果master设置了requirepass，那么salve node必须发送masterauth的口令过去进行认证（5）master node第一次执行全量复制，将所有数据发给slave node（6）master node后续持续将写命令，异步复制给slave node 2、数据同步相关的核心机制 就是第一次slave连接msater的时候，执行的全量复制，那个过程里面一些细节的机制 （1）master和slave都会维护一个offset master会在自身不断累加offset，slave也会在自身不断累加offsetslave每秒都会上报自己的offset给master，同时master也会保存每个slave的offset,master和slave都要知道各自的数据的offset，才能知道互相之间的数据不一致的情况 （2）backlog master node有一个backlog，默认是1MB大小master node给slave node复制数据时，也会将数据在backlog中同步写一份backlog主要是用来做全量复制中断候的增量复制的 （3）master run id info server，可以看到master run id如果根据host+ip定位master node，是不靠谱的，如果master node重启或者数据出现了变化，那么slave node应该根据不同的run id区分，run id不同就做全量复制如果需要不更改run id重启redis，可以使用redis-cli debug reload命令 （4）psync 从节点使用psync从master node进行复制，psync runid offsetmaster node会根据自身的情况返回响应信息，可能是FULLRESYNC runid offset触发全量复制，可能是CONTINUE触发增量复制 3、全量复制 （1）master执行bgsave，在本地生成一份rdb快照文件（2）master node将rdb快照文件发送给salve node，如果rdb复制时间超过60秒（repl-timeout），那么slave node就会认为复制失败，可以适当调节大这个参数（3）对于千兆网卡的机器，一般每秒传输100MB，6G文件，很可能超过60s（4）master node在生成rdb时，会将所有新的写命令缓存在内存中，在salve node保存了rdb之后，再将新的写命令复制给salve node（5）client-output-buffer-limit slave 256MB 64MB 60，如果在复制期间，内存缓冲区持续消耗超过64MB，或者一次性超过256MB，那么停止复制，复制失败（6）slave node接收到rdb之后，清空自己的旧数据，然后重新加载rdb到自己的内存中，同时基于旧的数据版本对外提供服务（7）如果slave node开启了AOF，那么会立即执行BGREWRITEAOF，重写AOF rdb生成、rdb通过网络拷贝、slave旧数据的清理、slave aof rewrite，很耗费时间 如果复制的数据量在4G~6G之间，那么很可能全量复制时间消耗到1分半到2分钟 4、增量复制 （1）如果全量复制过程中，master-slave网络连接断掉，那么salve重新连接master时，会触发增量复制（2）master直接从自己的backlog中获取部分丢失的数据，发送给slave node，默认backlog就是1MB（3）msater就是根据slave发送的psync中的offset来从backlog中获取数据的 5、heartbeat 主从节点互相都会发送heartbeat信息 master默认每隔10秒发送一次heartbeat，salve node每隔1秒发送一个heartbeat 6、异步复制 master每次接收到写命令之后，现在内部写入数据，然后异步发送给slave node redis高可用架构1、哨兵sentinal 哨兵是redis集群架构中非常重要的一个组件，主要功能如下 （1）集群监控，负责监控redis master和slave进程是否正常工作（2）消息通知，如果某个redis实例有故障，那么哨兵负责发送消息作为报警通知给管理员（3）故障转移，如果master node挂掉了，会自动转移到slave node上（4）配置中心，如果故障转移发生了，通知client客户端新的master地址 哨兵本身也是分布式的，作为一个哨兵集群去运行，互相协同工作 （1）故障转移时，判断一个master node是宕机了，需要大部分的哨兵都同意才行，涉及到了分布式选举的问题（2）即使部分哨兵节点挂掉了，哨兵集群还是能正常工作的，因为如果一个作为高可用机制重要组成部分的故障转移系统本身是单点的,本身就不能高可用 （3）哨兵至少需要三个才能故障转移,因为如果只有两个哨兵其中一个挂掉后不满足2的majority=2,不会允许执行故障转移。 4、经典的3节点哨兵集群 Master,Sentinal1 Slave1,Sentinal2 Slave2,Sentinal3 Configuration: quorum = 2 如果M1所在机器宕机了，那么三个哨兵还剩下2个，S2和S3可以一致认为master宕机，然后选举出一个来执行故障转移同时3个哨兵的majority是2，所以还剩下的2个哨兵运行着，就可以允许执行故障转移。 redis持久化方式[AOF,RDB]以及优缺点1、RDB和AOF两种持久化机制的介绍 RDB持久化机制，对redis中的数据执行周期性的持久化 AOF机制对每条写入命令作为日志，以append-only的模式写入一个日志文件中，在redis重启的时候，可以通过回放AOF日志中的写入指令来重新构建整个数据集 通过RDB或AOF，都可以将redis内存中的数据给持久化到磁盘上面来,如果同时使用RDB和AOF两种持久化机制，那么在redis重启的时候，会使用AOF来重新构建数据，因为AOF中的数据更加完整 2、RDB持久化机制的优点 （1）RDB会生成多个数据文件，每个数据文件都代表了某一个时刻中redis的数据，这种多个数据文件的方式，非常适合做冷备，以预定好的备份策略来定期备份redis中的数据 （2）RDB对redis对外提供的读写服务，影响非常小，可以让redis保持高性能，因为redis主进程只需要fork一个子进程，让子进程执行磁盘IO操作来进行RDB持久化即可 （3）相对于AOF持久化机制来说，直接基于RDB数据文件来重启和恢复redis进程，更加快速 3、RDB持久化机制的缺点 （1）如果想要在redis故障时，尽可能少的丢失数据，那么RDB没有AOF好。一般来说，RDB数据快照文件，都是每隔5分钟，或者更长时间生成一次，这个时候就得接受一旦redis进程宕机，那么会丢失最近5分钟的数据 （2）RDB每次在fork子进程来执行RDB快照数据文件生成的时候，如果数据文件特别大，可能会导致对客户端提供的服务暂停数毫秒，或者甚至数秒 4、AOF持久化机制的优点 （1）AOF可以更好的保护数据不丢失，一般AOF会每隔1秒，通过一个后台线程执行一次fsync操作，最多丢失1秒钟的数据 （2）AOF日志文件以append-only模式写入，所以没有任何磁盘寻址的开销，写入性能非常高，而且文件不容易破损，即使文件尾部破损，也很容易修复 （3）AOF日志文件即使过大的时候，出现后台重写操作，也不会影响客户端的读写。因为在rewrite log的时候，会对其中的指导进行压缩，创建出一份需要恢复数据的最小日志出来。再创建新日志文件的时候，老的日志文件还是照常写入。当新的merge后的日志文件ready的时候，再交换新老日志文件即可。 （4）AOF日志文件的命令通过非常可读的方式进行记录，这个特性非常适合做灾难性的误删除的紧急恢复。比如某人不小心用flushall命令清空了所有数据，只要这个时候后台rewrite还没有发生，那么就可以立即拷贝AOF文件，将最后一条flushall命令给删了，然后再将该AOF文件放回去，就可以通过恢复机制，自动恢复所有数据 5、AOF持久化机制的缺点 （1）对于同一份数据来说，AOF日志文件通常比RDB数据快照文件更大 （2）AOF开启后，支持的写QPS会比RDB支持的写QPS低，因为AOF一般会配置成每秒fsync一次日志文件，当然，每秒一次fsync，性能也还是很高的 （3）以前AOF发生过bug，就是通过AOF记录的日志，进行数据恢复的时候，没有恢复一模一样的数据出来。所以说，类似AOF这种较为复杂的基于命令日志/merge/回放的方式，比基于RDB每次持久化一份完整的数据快照文件的方式，更加脆弱一些，容易有bug。不过AOF就是为了避免rewrite过程导致的bug，因此每次rewrite并不是基于旧的指令日志进行merge的，而是基于当时内存中的数据进行指令的重新构建，这样健壮性会好很多。 6、RDB和AOF到底该如何选择 （1）不要仅仅使用RDB，因为那样会导致你丢失很多数据 （2）也不要仅仅使用AOF，因为那样有两个问题，第一，你通过AOF做冷备，没有RDB做冷备，来的恢复速度更快; 第二，RDB每次简单粗暴生成数据快照，更加健壮，可以避免AOF这种复杂的备份和恢复机制的bug （3）综合使用AOF和RDB两种持久化机制，用AOF来保证数据不丢失，作为数据恢复的第一选择; 用RDB来做不同程度的冷备，在AOF文件都丢失或损坏不可用的时候，还可以使用RDB来进行快速的数据恢复 redis cluster集群(数据会分片到相应的redis master-slave主从架构)如果你的数据量很少，主要是承载高并发高性能的场景，比如你的缓存一般就几个G，单机足够了使用单master进行读写分离就行了replication，一个mater，多个slave，要几个slave跟你的要求的读吞吐量有关系，然后自己搭建一个sentinal集群，去保证redis主从架构的高可用性。 redis cluster，主要是针对海量数据+高并发+高可用的场景，海量数据，如果你的数据量很大，那么建议就用redis cluster。 redis cluster数据分布算法 hash算法 -&gt; 一致性hash算法（memcached） -&gt; redis cluster，hash slot算法 用不同的算法，就决定了在多个master节点的时候，数据如何分布到这些节点上去，解决这个问题 1、redis cluster介绍 redis cluster （1）自动将数据进行分片，每个master上放一部分数据（2）提供内置的高可用支持，部分master不可用时，还是可以继续工作的 在redis cluster架构下，每个redis要放开两个端口号，比如一个是6379，另外一个就是加10000的端口号，比如16379 16379端口号是用来进行节点间通信的，也就是cluster bus的东西，集群总线。cluster bus的通信，用来进行故障检测，配置更新，故障转移授权 cluster bus用了另外一种二进制的协议，主要用于节点间进行高效的数据交换，占用更少的网络带宽和处理时间 2、最老土的hash算法和弊端（大量缓存重建） 3、一致性hash算法（自动缓存迁移）+虚拟节点（自动负载均衡） 4、redis cluster的hash slot算法 redis cluster有固定的16384个hash slot，对每个key计算CRC16值，然后对16384取模，可以获取key对应的hash slot redis cluster中每个master都会持有部分slot，比如有3个master，那么可能每个master持有5000多个hash slot hash slot让node的增加和移除很简单，增加一个master，就将其他master的hash slot移动部分过去，减少一个master，就将它的hash slot移动到其他master上去 移动hash slot的成本是非常低的 客户端的api，可以对指定的数据，让他们走同一个hash slot，通过hash tag来实现 节点间的内部通讯机制 一、节点间的内部通信机制 1、基础通信原理 （1）redis cluster节点间采取gossip协议进行通信 跟集中式不同，不是将集群元数据（节点信息，故障，等等）集中存储在某个节点上，而是互相之间不断通信，保持整个集群所有节点的数据是完整的 维护集群的元数据用得，集中式，一种叫做gossip 集中式(如zookeeper)：好处在于，元数据的更新和读取，时效性非常好，一旦元数据出现了变更，立即就更新到集中式的存储中，其他节点读取的时候立即就可以感知到; 不好在于，所有的元数据的跟新压力全部集中在一个地方，可能会导致元数据的存储有压力 gossip：好处在于，元数据的更新比较分散，不是集中在一个地方，更新请求会陆陆续续，打到所有节点上去更新，有一定的延时，降低了压力; 缺点，元数据更新有延时，可能导致集群的一些操作会有一些滞后 我们刚才做reshard，去做另外一个操作，会发现说，configuration error，达成一致 （2）10000端口 每个节点都有一个专门用于节点间通信的端口，就是自己提供服务的端口号+10000，比如7001，那么用于节点间通信的就是17001端口 每隔节点每隔一段时间都会往另外几个节点发送ping消息，同时其他几点接收到ping之后返回pong （3）交换的信息 故障信息，节点的增加和移除，hash slot信息，等等 2、gossip协议 gossip协议包含多种消息，包括ping，pong，meet，fail，等等 meet: 某个节点发送meet给新加入的节点，让新节点加入集群中，然后新节点就会开始与其他节点进行通信 redis-trib.rb add-node 其实内部就是发送了一个gossip meet消息，给新加入的节点，通知那个节点去加入我们的集群 ping: 每个节点都会频繁给其他节点发送ping，其中包含自己的状态还有自己维护的集群元数据，互相通过ping交换元数据 每个节点每秒都会频繁发送ping给其他的集群，ping，频繁的互相之间交换数据，互相进行元数据的更新 pong: 返回ping和meet，包含自己的状态和其他信息，也可以用于信息广播和更新 fail: 某个节点判断另一个节点fail之后，就发送fail给其他节点，通知其他节点，指定的节点宕机了 3、ping消息深入 ping很频繁，而且要携带一些元数据，所以可能会加重网络负担 每个节点每秒会执行10次ping，每次会选择5个最久没有通信的其他节点 当然如果发现某个节点通信延时达到了cluster_node_timeout / 2，那么立即发送ping，避免数据交换延时过长，落后的时间太长了 比如说，两个节点之间都10分钟没有交换数据了，那么整个集群处于严重的元数据不一致的情况，就会有问题 所以cluster_node_timeout可以调节，如果调节比较大，那么会降低发送的频率 每次ping，一个是带上自己节点的信息，还有就是带上1/10其他节点的信息，发送出去，进行数据交换 至少包含3个其他节点的信息，最多包含总节点-2个其他节点的信息 二、面向集群的jedis内部实现原理 开发，jedis，redis的java client客户端，redis cluster，jedis cluster api jedis cluster api与redis cluster集群交互的一些基本原理 1、基于重定向的客户端 redis-cli -c，自动重定向 （1）请求重定向 客户端可能会挑选任意一个redis实例去发送命令，每个redis实例接收到命令，都会计算key对应的hash slot 如果在本地就在本地处理，否则返回moved给客户端，让客户端进行重定向 cluster keyslot mykey，可以查看一个key对应的hash slot是什么 用redis-cli的时候，可以加入-c参数，支持自动的请求重定向，redis-cli接收到moved之后，会自动重定向到对应的节点执行命令 （2）计算hash slot 计算hash slot的算法，就是根据key计算CRC16值，然后对16384取模，拿到对应的hash slot 用hash tag可以手动指定key对应的slot，同一个hash tag下的key，都会在一个hash slot中，比如set mykey1:{100}和set mykey2:{100} （3）hash slot查找 节点间通过gossip协议进行数据交换，就知道每个hash slot在哪个节点上 2、smart jedis （1）什么是smart jedis 基于重定向的客户端，很消耗网络IO，因为大部分情况下，可能都会出现一次请求重定向，才能找到正确的节点 所以大部分的客户端，比如java redis客户端，就是jedis，都是smart的 本地维护一份hashslot -&gt; node的映射表，缓存，大部分情况下，直接走本地缓存就可以找到hashslot -&gt; node，不需要通过节点进行moved重定向 （2）JedisCluster的工作原理 在JedisCluster初始化的时候，就会随机选择一个node，初始化hashslot -&gt; node映射表，同时为每个节点创建一个JedisPool连接池 每次基于JedisCluster执行操作，首先JedisCluster都会在本地计算key的hashslot，然后在本地映射表找到对应的节点 如果那个node正好还是持有那个hashslot，那么就ok; 如果说进行了reshard这样的操作，可能hashslot已经不在那个node上了，就会返回moved 如果JedisCluter API发现对应的节点返回moved，那么利用该节点的元数据，更新本地的hashslot -&gt; node映射表缓存 重复上面几个步骤，直到找到对应的节点，如果重试超过5次，那么就报错，JedisClusterMaxRedirectionException jedis老版本，可能会出现在集群某个节点故障还没完成自动切换恢复时，频繁更新hash slot，频繁ping节点检查活跃，导致大量网络IO开销 jedis最新版本，对于这些过度的hash slot更新和ping，都进行了优化，避免了类似问题 （3）hashslot迁移和ask重定向 如果hash slot正在迁移，那么会返回ask重定向给jedis jedis接收到ask重定向之后，会重新定位到目标节点去执行，但是因为ask发生在hash slot迁移过程中，所以JedisCluster API收到ask是不会更新hashslot本地缓存 已经可以确定说，hashslot已经迁移完了，moved是会更新本地hashslot-&gt;node映射表缓存的 三、高可用性与主备切换原理 redis cluster的高可用的原理，几乎跟哨兵是类似的 1、判断节点宕机 如果一个节点认为另外一个节点宕机，那么就是pfail，主观宕机 如果多个节点都认为另外一个节点宕机了，那么就是fail，客观宕机，跟哨兵的原理几乎一样，sdown，odown 在cluster-node-timeout内，某个节点一直没有返回pong，那么就被认为pfail 如果一个节点认为某个节点pfail了，那么会在gossip ping消息中，ping给其他节点，如果超过半数的节点都认为pfail了，那么就会变成fail 2、从节点过滤 对宕机的master node，从其所有的slave node中，选择一个切换成master node 检查每个slave node与master node断开连接的时间，如果超过了cluster-node-timeout * cluster-slave-validity-factor，那么就没有资格切换成master 这个也是跟哨兵是一样的，从节点超时过滤的步骤 3、从节点选举 哨兵：对所有从节点进行排序，slave priority，offset，run id 每个从节点，都根据自己对master复制数据的offset，来设置一个选举时间，offset越大（复制数据越多）的从节点，选举时间越靠前，优先进行选举 所有的master node开始slave选举投票，给要进行选举的slave进行投票，如果大部分master node（N/2 + 1）都投票给了某个从节点，那么选举通过，那个从节点可以切换成master 从节点执行主备切换，从节点切换为主节点 4、与哨兵比较 整个流程跟哨兵相比，非常类似，所以说，redis cluster功能强大，直接集成了replication和sentinal的功能 没有办法去给大家深入讲解redis底层的设计的细节，核心原理和设计的细节，那个除非单独开一门课，redis底层原理深度剖析，redis源码 对于咱们这个架构课来说，主要关注的是架构，不是底层的细节，对于架构来说，核心的原理的基本思路，是要梳理清晰的 缓存穿透和缓存雪崩 缓存雪崩 缓存雪崩是指在我们设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到DB，DB瞬时压力过重雪崩。 事前：redis高可用，主从+哨兵，redis cluster，避免全盘崩溃 事中：本地ehcache缓存 + hystrix限流&amp;降级，避免MySQL被打死 事后：redis持久化，快速恢复缓存数据 缓存穿透 缓存穿透是指查询一个一定不存在的数据,由于缓存一般是命中后才写入缓存,如果有大量这样的查询请求(黑客攻击,恶意请求),会全部打到DB上,导致DB宕机 解决方式: ​ 1,使用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被 这个bitmap拦截掉 ​ 2,如果查询未命中将未命中的key仍然写入缓存,value为UNKONW等,过期时间为5到10分钟来冲抵短时恶意攻击 缓存击穿 对于一些设置了过期时间的key，如果这些key可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。和缓存雪崩的区别在于这里针对某一key缓存，前者则是很多key。 1.使用互斥锁(mutex key),推荐使用 ​ 就是在缓存失效的时候（判断拿出来的值为空），不是立即去load db，而是先使用缓存工具的某些带成功操作返回值的操作（比如Redis的SETNX或者Memcache的ADD）去set一个mutex key，当操作返回成功时，再进行load db的操作并回设缓存；否则，就重试整个get缓存的方法。 2.热点key设置不过期,或者使用快过期时预热key 3.采用netflix的hystrix,抵挡冲击 缓存数据库双写不一致 先更新数据库,再更新缓存 这种操作太费时费力一般不使用 先更新数据库，再删除缓存这种策略比较多平台使用，如：Facebook。但是这种策略也存在一些问题，如：一、脏数据造成脏数据的原因主要由并发引起，如： 用户A请求数据A 数据A缓存失效 用户A从数据库中得到旧数据数据A 用户B更新了数据A（新数据） 用户B删除了缓存 用户A将查到旧数据写入了缓存 此时就产生了脏数据，虽然这种概率非常小，但对于更新不频繁的网站来说，此时的脏数据就是个很严重的错误。 二、缓存删除失败 用户A更新了数据A 用户A删除数据A的缓存失败 用户B读到数据A缓存的旧数据 此时就产生了数据不一致的问题。 解决方案 置缓存的有效时间（最简单的方案）优点:易操作 缺点:会存在短时间内的旧数据,如果数据量太多，缓存有效时间短，容易发生一段时间内缓存大量失效，此时的数据库压力突然剧增，引发缓存雪崩现象（缓存有效时间为随机值减少发生缓存雪崩的可能性） 消息队列（比较复杂，需要引入消息队列系统） 步骤： 更新数据库； 删除缓存失败； 将需要删除的Key发送到消息队列； 隔断时间从消息队列中拉取要删除的key； 继续删除，直至成功为止。 优点：不会引发缓存雪崩,只删除需要删除的缓存 缺点：引入了消息系统（增加了系统的复杂性） 先删除缓存，推荐使用，但是也会出现脏数据的问题： 用户A删除缓存失败 用户A成功更新了数据 或者 用户A删除了缓存； 用户B读取缓存，缓存不存在； 用户B从数据库拿到旧数据； 用户B更新了缓存； 用户A更新了数据。 以上两种情况都能造成脏数据的产生。 解决方式同上 redis并发竞争问题一般使用分布式锁(zookeeper)保证统一时间只有一个实例获取到锁 使用版本控制和锁重试机制来处理并发的竞争顺序 分布式系统​ 分布式系统一般使用RPC框架相互调用,RPC一般提供了负载,超时重试,自动感知上下线.等如果不使用RPC框架就需要自己处理这些复杂的问题。 dubbo工作原理注册中心挂了可以继续通讯么1.dubbo工作原理 第一层：service层，接口层，给服务提供者和消费者来实现的 第二层：config层，配置层，主要是对dubbo进行各种配置的 第三层：proxy层，服务代理层，透明生成客户端的stub和服务单的skeleton 第四层：registry层，服务注册层，负责服务的注册与发现 第五层：cluster层，集群层，封装多个服务提供者的路由以及负载均衡，将多个实例组合成一个服务 第六层：monitor层，监控层，对rpc接口的调用次数和调用时间进行监控 第七层：protocol层，远程调用层，封装rpc调用 第八层：exchange层，信息交换层，封装请求响应模式，同步转异步 第九层：transport层，网络传输层，抽象mina和netty为统一接口 第十层：serialize层，数据序列化层 工作流程： 1）第一步，provider向注册中心去注册 2）第二步，consumer从注册中心订阅服务，注册中心会通知consumer注册好的服务 3）第三步，consumer调用provider 4）第四步，consumer和provider都异步的通知监控中心 2.注册中心挂了可以继续通信吗？ ​ 可以,因为刚开始初始化的时候,消费者会将提供者的地址等信息拉取到本地缓存,所以注册中心挂了可以继续通信,但是因为信息是旧的如果服务方挂了无法感知。 dubbo的通讯协议以及序列化协议1、dubbo协议 Dubbo缺省协议采用单一长连接和NIO异步通讯，适合于小数据量大并发的服务调用，以及服务消费者机器数远大于服务提供者机器数的情况。 12345678缺省协议，使用基于mina1.1.7+hessian3.2.1的tbremoting交互。连接个数：单连接连接方式：长连接传输协议：TCP传输方式：NIO异步传输序列化：Hessian二进制序列化适用范围：传入传出参数数据包较小（建议小于100K），消费者比提供者个数多，单一消费者无法压满提供者，尽量不要用dubbo协议传输大文件或超大字符串。适用场景：常规远程服务方法调用 123456789101112131415161718192021为什么要消费者比提供者个数多：因dubbo协议采用单一长连接，假设网络为千兆网卡(1024Mbit=128MByte)，根据测试经验数据每条连接最多只能压满7MByte(不同的环境可能不一样，供参考)，理论上1个服务提供者需要20个服务消费者才能压满网卡。为什么不能传大包：因dubbo协议采用单一长连接，如果每次请求的数据包大小为500KByte，假设网络为千兆网卡(1024Mbit=128MByte)，每条连接最大7MByte(不同的环境可能不一样，供参考)，单个服务提供者的TPS(每秒处理事务数)最大为：128MByte / 500KByte = 262。单个消费者调用单个服务提供者的TPS(每秒处理事务数)最大为：7MByte / 500KByte = 14。如果能接受，可以考虑使用，否则网络将成为瓶颈。为什么采用异步单一长连接：因为服务的现状大都是服务提供者少，通常只有几台机器，而服务的消费者多，可能整个网站都在访问该服务，比如Morgan的提供者只有6台提供者，却有上百台消费者，每天有1.5亿次调用，如果采用常规的hessian服务，服务提供者很容易就被压跨，通过单一连接，保证单一消费者不会压死提供者，长连接，减少连接握手验证等，并使用异步IO，复用线程池，防止C10K问题。 2、RMI RMI协议采用JDK标准的java.rmi.*实现，采用阻塞式短连接和JDK标准序列化方式 12345678Java标准的远程调用协议。连接个数：多连接连接方式：短连接传输协议：TCP传输方式：同步传输序列化：Java标准二进制序列化适用范围：传入传出参数数据包大小混合，消费者与提供者个数差不多，可传文件。适用场景：常规远程服务方法调用，与原生RMI服务互操作 3、hessian Hessian协议用于集成Hessian的服务，Hessian底层采用Http通讯，采用Servlet暴露服务，Dubbo缺省内嵌Jetty作为服务器实现 123456789基于Hessian的远程调用协议。连接个数：多连接连接方式：短连接传输协议：HTTP传输方式：同步传输序列化：Hessian二进制序列化适用范围：传入传出参数数据包较大，提供者比消费者个数多，提供者压力较大，可传文件。适用场景：页面传输，文件传输，或与原生hessian服务互操作 4、http 采用Spring的HttpInvoker实现 123456789基于http表单的远程调用协议。连接个数：多连接连接方式：短连接传输协议：HTTP传输方式：同步传输序列化：表单序列化（JSON）适用范围：传入传出参数数据包大小混合，提供者比消费者个数多，可用浏览器查看，可用表单或URL传入参数，暂不支持传文件。适用场景：需同时给应用程序和浏览器JS使用的服务。 5、webservice 基于CXF的frontend-simple和transports-http实现 1234567基于WebService的远程调用协议。连接个数：多连接连接方式：短连接传输协议：HTTP传输方式：同步传输序列化：SOAP文本序列化适用场景：系统集成，跨语言调用。 6、thrif Thrift是Facebook捐给Apache的一个RPC框架，当前 dubbo 支持的 thrift 协议是对 thrift 原生协议的扩展，在原生协议的基础上添加了一些额外的头信息，比如service name，magic number等。 dubbo负载均衡Random LoadBalance 随机，按权重设置随机概率。 在一个截面上碰撞的概率高，但调用量越大分布越均匀，而且按概率使用权重后也比较均匀，有利于动态调整提供者权重。 RoundRobin LoadBalance 轮询，按公约后的权重设置轮询比率。 存在慢的提供者累积请求的问题，比如：第二台机器很慢，但没挂，当请求调到第二台时就卡在那，久而久之，所有请求都卡在调到第二台上。 LeastActive LoadBalance 最少活跃调用数，相同活跃数的随机，活跃数指调用前后计数差。 使慢的提供者收到更少请求，因为越慢的提供者的调用前后计数差会越大。 ConsistentHash LoadBalance 一致性 Hash，相同参数的请求总是发到同一提供者。 当某一台提供者挂时，原本发往该提供者的请求，基于虚拟节点，平摊到其它提供者，不会引起剧烈变动。 分布式幂等1.数据库乐观锁 2.分布式锁(redis,zookeeper) 3.token机制，防止页面重复提交 http://825635381.iteye.com/blog/2276077 分布式请求顺序性一般不建议保证分布式的顺序性,因为复杂度太高,如果实在是需要可以使用维护内存队列。 zookeeper的使用场景1、负载均衡 在分布式系统中，负载均衡是一种普遍的技术。ZooKeeper作为一个集群，负责数据的存储以及一系列分布式协调。所有的请求，会通过ZooKeeper通过一些调度策略去协调调度哪一台服务器。 2、分布式协调/通知 分布式协调/通知服务是分布式系统中将不同的分布式组件结合起来。通常需要一个协调者来控制整个系统的运行流程，这个协调者便于将分布式协调的职责从应用中分离出来，从而可以大大减少系统之间的耦合性，而且能够显著提高系统的可扩展性。 ZooKeeper中特有的Watcher注册与异步通知机制，能够很好地实现分布式环境下不同机器，甚至是不同系统之间的协调与通知，从而实现对数据变更的实时处理。基于ZooKeeper实现分布式协调与通知功能，通常的作坊式不同的客户端对ZooKeeper上同一个数据节点进行Watcher注册，监听数据节点的变化，如果数据节点发生变化，那么所有订阅的客户端都能够接受到相应的Watcher通知，并作出相应的处理。 3、集群管理 集群管理包括集群监控和集群控制。前者侧重对集群运行状态的收集，后者则是对集群进行操作与控制。在传统的基于Agent的分布式管理体系中，都是通过在集群中每台机器上部署一个Agent，由这个Agent负责主动向指定的一个监控中心系统汇报自己所在机器的状态。在集群规模适中的场景下，这确实是一种在生产实践中广泛使用的解决方案，但一旦系统的业务场景增多，这种方案就不好了。大规模升级困难，统一的Agent无法满足多样的需求等问题。 4、分布式锁 分布式锁是控制分布式系统之间同步访问共享资源的一种方式。如果不同的系统或是同一个系统的不同主机之间共享一个或一组资源，那么访问这些资源的时候，往往需要通过一些互斥手段来防止彼此之间的干扰，以保证一致性，在这种情况下，需要使用分布式锁。 分布式锁1.基于redis 2.基于zookeeper(推荐) 分布式session的处理 tomcat+redis Tomcat RedisSessionManager的东西，让所有我们部署的tomcat都将session数据存储到redis即可。 在tomcat的配置文件中，配置一下 12345678910111213141516171819202122&lt;Valve className="com.orangefunction.tomcat.redissessions.RedisSessionHandlerValve" /&gt; &lt;Manager className="com.orangefunction.tomcat.redissessions.RedisSessionManager" host="&#123;redis.host&#125;" port="&#123;redis.port&#125;" database="&#123;redis.dbnum&#125;" maxInactiveInterval="60"/&gt;-- 哨兵模式&lt;Valve className="com.orangefunction.tomcat.redissessions.RedisSessionHandlerValve" /&gt;&lt;Manager className="com.orangefunction.tomcat.redissessions.RedisSessionManager" sentinelMaster="mymaster" sentinels="&lt;sentinel1-ip&gt;:26379,&lt;sentinel2-ip&gt;:26379,&lt;sentinel3-ip&gt;:26379" maxInactiveInterval="60"/&gt; 还可以用上面这种方式基于redis哨兵支持的redis高可用集群来保存session数据 spring session + redis 不仅可以使用redis spring session还可以基于数据库等其他存储 spring session 分布式事务 两阶段提交(效率低下不推荐) TCC(需要自己写大量的回滚逻辑复杂不推荐) 1）Try阶段：对各个服务的资源做检测以及对资源进行锁定或者预留 2）Confirm阶段：各个服务中执行实际的操作 3）Cancel阶段：如果任何一个服务的业务方法执行出错，就需要进行补偿，就是执行已经执行成功的业务逻辑的回滚操作 本地消息表(严重依赖于数据库的消息表,高并发场景无法扩展,比较少用) 1）A系统在自己本地一个事务里操作同时，插入一条数据到消息表 2）A系统将这个消息发送到MQ中去 3）B系统接收到消息之后，在一个事务里，往自己本地消息表里插入一条数据，同时执行其他的业务操作，如果这个消息已经被处理过了，那么此时这个事务会回滚，这样保证不会重复处理消息 4）B系统执行成功之后，就会更新自己本地消息表的状态以及A系统消息表的状态 5）如果B系统处理失败了，那么就不会更新消息表状态，那么此时A系统会定时扫描自己的消息表，如果有没处理的消息，会再次发送到MQ中去，让B再次处理 6）这个方案保证了最终一致性，哪怕B事务失败了，但是A会不断重发消息，直到B那边成功为止 可靠消息最终一致性 基于MQ来实现事务 1）A系统先发送一个prepared消息到mq，如果这个prepared消息发送失败那么就直接取消操作别执行了 2）如果这个消息发送成功过了，那么接着执行本地事务，如果成功就告诉mq发送确认消息，如果失败就告诉mq回滚消息 3）如果发送了确认消息，那么此时B系统会接收到确认消息，然后执行本地的事务 4）mq会自动定时轮询所有prepared消息回调你的接口，询问这个消息是不是本地事务处理失败了，这里你就可以查下数据库看之前本地事务是否执行，如果回滚了，那么这里也回滚吧。这个就是避免可能本地事务执行成功了，别确认消息发送失败了。 5）要是系统B的事务失败了，自动不断重试直到成功，如果实在是不行，要么就是针对重要的资金类业务进行回滚，比如B系统本地回滚后，想办法通知系统A也回滚；或者是发送报警由人工来手工回滚和补偿 最大努力通知 1）系统A本地事务执行完之后，发送个消息到MQ 2）有个专门消费MQ的最大努力通知服务，这个服务会消费MQ然后写入数据库中记录下来，或者是放入个内存队列也可以，接着调用系统B的接口 3）要是系统B执行成功就ok了；要是系统B执行失败了，那么最大努力通知服务就定时尝试重新调用系统B，反复N次，最后还是不行就放弃 ​ 别严格的场景，用的是TCC来保证强一致性；然后其他的一些场景基于了MQ或最大通知来实现了分布式事务,一般很少使用事务,一般是快速发现问题修复数据。 分库分表分库分表参考 分库分表中间件 cobar(不推荐) 阿里b2b团队开发和开源的,属于proxy层方案,功能简单且没人维护了 TDDL(不推荐) 淘宝团队开发的,属于client层方案,功能简单,基本没人使用和维护了且安装需要依赖淘宝的diamond配置管理系统比较麻烦。 atlas(不推荐) 360开源的,属于proxy层方案,功能简单且没人维护了 sharding-jdbc(推荐,小公司) 当当开源的,属于client层方案,功能较多,社区活跃,推荐使用。 mycat(推荐,大公司) 基于cobar改造的,属于proxy层方案,社区活跃。 分库分表拆分方式 水平拆分 range来分(数据连续依据时间划分) 扩容很容易,可以依据月份写到新库中； 缺点容易产生热点问题,大量的流量都请求在最新的数据上 ​ hash分法(依据订单hash划分库) 可以平均分配没给库的数据量和请求压力； 坏处在于扩容起来比较麻烦,会有数据迁移的过程 垂直拆分 分库分表方案 停机迁移方案 双写迁移方案 在写入的时候同时写入老库和新的基于中间件的分库,启动迁移程序,不断的读取老库中的数据通过中间件写到新的分库中,在写的时候先查询一下如果不存在或者修改时间比新库中的新才写入,写完后可能数据还不一致,需要继续跑几遍才可能一致,直到老库和新库中的数据一致才算完成,随后将写老库的代码下线。 动态扩容和缩容https://my.oschina.net/u/1859679/blog/1577049 https://kefeng.wang/2018/07/22/mysql-sharding/ 分库分表后全局id的获取 myqsl自动增长列(新建一台mysql服务) 全局ID映射表 在全局 Redis 中为每张数据表创建一个 ID 的键，记录该表当前最大 ID；每次申请 ID 时，都自增 1 并返回给应用；Redis 要定期持久至全局数据库。 UUID(128位) 优点：简单，全球唯一； 缺点：存储和传输空间大，无序，性能欠佳。 COMB(组合) 组合 GUID(10字节) 和时间(6字节)，达到有序的效果，提高索引性能。 Snowflake(雪花) 算法 Snowflake 是 Twitter 开源的分布式 ID 生成算法，其结果为 long(64bit) 的数值。其特性是各节点无需协调、按时间大致有序、且整个集群各节点单不重复。 8种通讯协议对比 dubbo中文官网]]></content>
      <categories>
        <category>杂记</category>
      </categories>
      <tags>
        <tag>记录</tag>
        <tag>杂记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jvm内存排查]]></title>
    <url>%2F2018%2F10%2F01%2Fsenssic.github.io%2F201901%2Fjvm%E5%86%85%E5%AD%98%E6%8E%92%E6%9F%A5%2F</url>
    <content type="text"><![CDATA[一般线上JVM问题属于比较紧急的情况,需要立即保留现场信息,并及时回复生产。 保留现场 打印堆栈信息 jstack java进程id dump堆内存 jmap -dump:format=b,file=./jvmdump java进程id 打印至少30秒的jvm垃圾回收情况 jstat -gcutil java进程id 1000 查看堆内存占用情况 jmap -histo java进程id,或jmap -histo:live java进程id |head -n 30 查看堆情况 jmap -heap java进程id 查询系统日志/var/log/messages 一般java进程突然消失,可以到这个里面查看信息 查看JVM参数 jinfo -flag PID eg:jinfo -flag UseCompressedClassPointers 3212080返回-XX:-UseCompressedClassPointers说明UseCompressedClassPointers参数为false打印所有 XX 参数java -XX:+PrintFlagsFinal 有事在tomcat的jvm配置时候需要添加一些额外参数,这样在系统宕机之前可以保留一些关键的信息 ​ -XX:+PrintGCDetails ​ -XX:+PrintGCDateStamps ​ -XX:+HeapDumpOnOutOfMemoryError ​ -XX:HeapDumpPath=/usr/temp/dump ​ -Xloggc:/usr/temp/dump/heap_trace.txt [确保/usr/temp目录存在] 一般问题原因 持续发生Full GC，但是系统不抛出OOM错误 堆内存溢出：java.lang.OutOfMemoryError：Java heap space 持久带溢出:java.lang.OutOfMemoryError： PermGen Space (jdk8已移除) 线程过多：java.lang.OutOfMemoryError：unable to create new native thread JAVA进程退出,一般JVM设置过大导致内存不够用也会导致,JVM一般设置为内存的65% CPU占用过高 JIT编译导致load过高 堆内存分析使用到的工具 MAT Jprofile Btrace tomcat配置文件优化连接器优化在$CATALINA_HOME/conf/server.xml配置文件中的Connetctor节点，和连接数相关的参数配置和优化。 maxThreads Tomcat使用线程来处理接收的每个请求。这个值表示Tomcat可创建的最大的线程数。默认值200。 可以根据机器的时期性能和内存大小调整，一般可以在400-500。最大可以在800左右。 acceptCount 指定当所有可以使用的处理请求的线程数都被使用时，可以放到处理队列中的请求数，超过这个数的请求将不予处理。默认值10。 minSpareThreads Tomcat初始化时创建的线程数。默认值4。 maxSpareThreads 一旦创建的线程超过这个值，Tomcat就会关闭不再需要的socket线程。默认值50。 enableLookups 是否反查域名，默认值为true。为了提高处理能力，应设置为false connnectionTimeout 网络连接超时，默认值20000，单位：毫秒。设置为0表示永不超时，这样设置有隐患的。通常可设置为30000毫秒。(本系统由于与后台系统接口超时时间较长，使用设置为60000) maxKeepAliveRequests 保持请求数量，默认值100。 bufferSize 输入流缓冲大小，默认值2048 bytes。 compression 压缩传输，取值on/off/force，默认值off。 其中和最大连接数相关的参数为maxThreads和acceptCount。如果要加大并发连接数，应同时加大这两个参数。web server允许的最大连接数还受制于操作系统的内核参数设置，通常Windows是2000个左右，Linux是1000个左右。 如果tomcat假死一般和maxThreads,acceptCount以及connnectionTimeout有关系,需要配置合理。 配置实例修改配置文件：$CATALINA_HOME/conf/server.xml AJP的连接 1234&lt;Connector port="8009" maxTreads="500" minSpareThreads="10" maxSpareThreads="50" acceptCount="50" connectionTimeout="60000" enableLookups="false" redirectPort="8443" protocol="AJP/1.3" /&gt; 通用连接 12345678&lt;Connector port="8080" maxTreads="500" minSpareThreads="10" maxSpareThreads="50" acceptCount="50" connectionTimeout="60000" enableLookups="false" redirectPort="8443" protocol="AJP/1.3" compression="on" compressionMinSize="2048" noCompressionUserAgents="gozilla, traviata" compressableMimeType="text/html,text/xml"/&gt; 主机和应用配置 12345&lt;Host name="localhost" appBase="" unpackWARs="true" autoDeploy="true" xmlValidation="false" xmlNamespaceAware="false"&gt; &lt;Context path="" docBase="/www/xxxx/site/web" reloadable="true" debug="0"/&gt;&lt;/Host&gt; 基于linux的IPv4的网络优化查看当前linux网络状态1netstat -n | awk &apos;/^tcp/ &#123;++S[$NF]&#125; END&#123;for(a in S) print a, S[a]&#125;&apos; CLOSED：无活动的或正在进行的连接。 LISTEN：服务器正在等待进入呼叫。 SYN_RECV：一个连接请求已经到达，等待确认。 SYN_SENT：应用已经开始，打开一个连接。 ESTABLISHED：正常数据传输状态。 FIN_WAIT1：应用说它已经完成。 FIN_WAIT2：另一边已同意释放。 ITMED_WAIT：等待所有分组死掉。 CLOSING：两边尝试同时关闭。 TIME_WAIT：另一边已初始化一个释放,若过高会造成卡死等，关注设置超时时间。 LAST_ACK：等待所有分组死掉。 两种修改内核参数方法 使用echo value方式直接追加到文件里如echo “1” &gt;/proc/sys/net/ipv4/tcp_syn_retries，但这种方法设备重启后又会恢复为默认值 把参数添加到/etc/sysctl.conf中，然后执行sysctl -p使参数生效，永久生效。 不同的生产环境需要优化的参数基本差不多，只是值有相应的变化。具体优化值要参考应用场景，这儿所列只是常用优化参数，是否适合，可在上面查看该参数描述，理解后，再根据自己生产环境而设。 生产中常用的参数： 123456789101112131415161718192021222324252627282930313233343536373839404142#在内核放弃建立连接之前发送SYN包的数量。net.ipv4.tcp_syn_retries = 1#对于远端的连接请求SYN，内核会发送SYN ＋ ACK数据报，以确认收到上一个 SYN连接请求包。net.ipv4.tcp_synack_retries = 1#表示当keepalive起用的时候，TCP发送keepalive消息的频度。缺省是2小时，改为30分钟。net.ipv4.tcp_keepalive_time = 600#如果对方不予应答，探测包的发送次数net.ipv4.tcp_keepalive_probes = 3#keepalive探测包的发送间隔net.ipv4.tcp_keepalive_intvl =15#在丢弃激活(已建立通讯状况)的TCP连接之前﹐需要进行多少次重试。net.ipv4.tcp_retries2 = 5#表示如果套接字由本端要求关闭，这个参数决定了它保持在FIN-WAIT-2状态的时间。net.ipv4.tcp_fin_timeout = 2#表示系统同时保持TIME_WAIT套接字的最大数量net.ipv4.tcp_max_tw_buckets = 36000#表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭net.ipv4.tcp_tw_recycle = 1#表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭；net.ipv4.tcp_tw_reuse = 1#系统所能处理不属于任何进程的TCP sockets最大数量。net.ipv4.tcp_max_orphans = 32768#只有在内核编译时选择了CONFIG_SYNCOOKIES时才会发生作用。当出现syn等候队列出现溢出时象对方发送syncookies。net.ipv4.tcp_syncookies = 1#表示SYN队列长度，默认1024，改成16384，可以容纳更多等待连接的网络连接数。net.ipv4.tcp_max_syn_backlog = 16384为自动调优定义每个 socket 使用的内存。#第一个值是为 socket 的发送缓冲区分配的最少字节数。#第二个值是默认值（该值会被 wmem_default 覆盖），缓冲区在系统负载不重的情况下可以增长到这个值。#第三个值是发送缓冲区空间的最大字节数（该值会被 wmem_max 覆盖）。net.ipv4.tcp_wmem = 8192 131072 16777216#与 tcp_wmem 类似，不过它表示的是为自动调优所使用的接收缓冲区的值。net.ipv4.tcp_rmem = 32768 131072 16777216#确定 TCP 栈应该如何反映内存使用；每个值的单位都是内存页（通常是 4KB）。#第一个值是内存使用的下限。#第二个值是内存压力模式开始对缓冲区使用应用压力的上限。#第三个值是内存上限。在这个层次上可以将报文丢弃，从而减少对内存的使用。对于较大的 BDP 可以增大这些值（但是要记住，其单位是内存页，而不是字节）。net.ipv4.tcp_mem = 786432 1048576 1572864#表示用于向外连接的端口范围。缺省情况下很小：32768到61000，改为1024到65000。net.ipv4.ip_local_port_range = 1024 65000#该参数决定了，网络设备接收数据包的速率比内核处理这些包的速率快时，允许送到队列的数据包的最大数目。net.core.netdev_max_backlog = 16384 linux网络默认配置和建议优化值 /proc/sys/net目录所有的TCP/IP参数都位于/proc/sys/net目录下（请注意，对/proc/sys/net目录下内容的修改都是临时的，任何修改在系统重启后都会丢失），例如下面这些重要的参数： 参数（路径**+**文件） 描述 默认值 优化值 /proc/sys/net/core/rmem_default 默认的TCP数据接收窗口大小（字节）。 229376 256960 /proc/sys/net/core/rmem_max 最大的TCP数据接收窗口（字节）。 131071 513920 /proc/sys/net/core/wmem_default 默认的TCP数据发送窗口大小（字节）。 229376 256960 /proc/sys/net/core/wmem_max 最大的TCP数据发送窗口（字节）。 131071 513920 /proc/sys/net/core/netdev_max_backlog 在每个网络接口接收数据包的速率比内核处理这些包的速率快时，允许送到队列的数据包的最大数目。 1000 2000 /proc/sys/net/core/somaxconn 定义了系统中每一个端口最大的监听队列的长度，这是个全局的参数。 128 2048 /proc/sys/net/core/optmem_max 表示每个套接字所允许的最大缓冲区的大小。 20480 81920 /proc/sys/net/ipv4/tcp_mem 确定TCP栈应该如何反映内存使用，每个值的单位都是内存页（通常是4KB）。第一个值是内存使用的下限；第二个值是内存压力模式开始对缓冲区使用应用压力的上限；第三个值是内存使用的上限。在这个层次上可以将报文丢弃，从而减少对内存的使用。对于较大的BDP可以增大这些值（注意，其单位是内存页而不是字节）。 94011 125351 188022 131072 262144 524288 /proc/sys/net/ipv4/tcp_rmem 为自动调优定义socket使用的内存。第一个值是为socket接收缓冲区分配的最少字节数；第二个值是默认值（该值会被rmem_default覆盖），缓冲区在系统负载不重的情况下可以增长到这个值；第三个值是接收缓冲区空间的最大字节数（该值会被rmem_max覆盖）。 4096 87380 4011232 8760 256960 4088000 /proc/sys/net/ipv4/tcp_wmem 为自动调优定义socket使用的内存。第一个值是为socket发送缓冲区分配的最少字节数；第二个值是默认值（该值会被wmem_default覆盖），缓冲区在系统负载不重的情况下可以增长到这个值；第三个值是发送缓冲区空间的最大字节数（该值会被wmem_max覆盖）。 4096 16384 4011232 8760 256960 4088000 /proc/sys/net/ipv4/tcp_keepalive_time TCP发送keepalive探测消息的间隔时间（秒），用于确认TCP连接是否有效。 7200 1800 /proc/sys/net/ipv4/tcp_keepalive_intvl 探测消息未获得响应时，重发该消息的间隔时间（秒）。 75 30 /proc/sys/net/ipv4/tcp_keepalive_probes 在认定TCP连接失效之前，最多发送多少个keepalive探测消息。 9 3 /proc/sys/net/ipv4/tcp_sack 启用有选择的应答（1表示启用），通过有选择地应答乱序接收到的报文来提高性能，让发送者只发送丢失的报文段，（对于广域网通信来说）这个选项应该启用，但是会增加对CPU的占用。 1 1 /proc/sys/net/ipv4/tcp_fack 启用转发应答，可以进行有选择应答（SACK）从而减少拥塞情况的发生，这个选项也应该启用。 1 1 /proc/sys/net/ipv4/tcp_timestamps TCP时间戳（会在TCP包头增加12个字节），以一种比重发超时更精确的方法（参考RFC 1323）来启用对RTT 的计算，为实现更好的性能应该启用这个选项。 1 1 /proc/sys/net/ipv4/tcp_window_scaling 启用RFC 1323定义的window scaling，要支持超过64KB的TCP窗口，必须启用该值（1表示启用），TCP窗口最大至1GB，TCP连接双方都启用时才生效。 1 1 /proc/sys/net/ipv4/tcp_syncookies 表示是否打开TCP同步标签（syncookie），内核必须打开了CONFIG_SYN_COOKIES项进行编译，同步标签可以防止一个套接字在有过多试图连接到达时引起过载。 1 1 /proc/sys/net/ipv4/tcp_tw_reuse 表示是否允许将处于TIME-WAIT状态的socket（TIME-WAIT的端口）用于新的TCP连接 。 0 1 /proc/sys/net/ipv4/tcp_tw_recycle 能够更快地回收TIME-WAIT套接字。 0 1 /proc/sys/net/ipv4/tcp_fin_timeout 对于本端断开的socket连接，TCP保持在FIN-WAIT-2状态的时间（秒）。对方可能会断开连接或一直不结束连接或不可预料的进程死亡。 60 30 /proc/sys/net/ipv4/ip_local_port_range 表示TCP/UDP协议允许使用的本地端口号 32768 61000 1024 65000 /proc/sys/net/ipv4/tcp_max_syn_backlog 对于还未获得对方确认的连接请求，可保存在队列中的最大数目。如果服务器经常出现过载，可以尝试增加这个数字。 2048 2048 /proc/sys/net/ipv4/tcp_low_latency 允许TCP/IP栈适应在高吞吐量情况下低延时的情况，这个选项应该禁用。 0 /proc/sys/net/ipv4/tcp_westwood 启用发送者端的拥塞控制算法，它可以维护对吞吐量的评估，并试图对带宽的整体利用情况进行优化，对于WAN 通信来说应该启用这个选项。 0 /proc/sys/net/ipv4/tcp_bic 为快速长距离网络启用Binary Increase Congestion，这样可以更好地利用以GB速度进行操作的链接，对于WAN通信应该启用这个选项。 1 MAT使用进阶 jstat命令详解 JVM问题分析处理手册 jmap命令详解 jvm性能调优 Linux系统日志及日志分析]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>jvm</tag>
        <tag>内存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java并发编程]]></title>
    <url>%2F2018%2F09%2F15%2Fsenssic.github.io%2F201901%2Fjava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[并发编程的挑战上下文切换​ CPU会给每个线程分配时间片用于分配给各个线程执行和占用资源,所以在多线程执行的情况下需要对执行上下文不停切换,会消耗CPU资源,所以在某些特定情况下单线程会比多线程消耗时间少。我们要尽可能的减少上下文切换。 无锁并发编程；多线程的锁竞争会引起上下文切换,处理数据时尽量避免使用锁。例如hash取模,CAS算法等。 使用最少线程；避免创建不需要的线程,不然会导致大量线程等待。 协程；单线程实现多任务调度,并支持多个任务间切换,而避免发生上下文切换。 死锁​ 锁在多线程编程中处理共享资源有很大的作用,但是在使用锁的时候极有可能在多线程环境中发生死锁,从而导致系统不可用,所以我们应避免死锁的发生,避免死锁的基本方法和注意点。 避免一个线程同时获取多个锁,线程获取多个锁资源等会导致资源处理复杂且容易与其他线程发生资源互等待 避免一个线程在锁内同时占用多个资源,尽量保证每个锁只占用一个资源。 使用定时锁或超时锁,这样当获取锁超时会自动退出锁等待释放资源。 对于数据库锁,加锁和解锁必须在一个数据库链接里,否则会出现解锁失败的情况。 资源限制​ 资源限制是指在进行并发编程时,程序的执行速度受限于计算机硬件资源或软件资源。突破资源限制方式 硬件解决方式,可以使用很多廉价的硬件组合编程集群 软件解决的方式,可以使资源进行并发的执行提高效率 java并发机制的底层实现volatile关键字​ Java编程语言允许线程访问共享变量，为了 确保共享变量能被准确和一致地更新，线程应该确保通过排他锁单独获得这个变量,java内存模型确保所有线程看到这个变量的值是一致的。 ​ volatile实现原理是通过JVM在volatile变量进行写操作后JVM会向处理器发送一条lock的前缀指令,CPU指令lock指令在多核处理器会按照如下方式执行。 将当前处理器缓存行的数据写回到系统内存。 写回内存的操作会使在其他CPU内缓存了该内存地址的数据无效。(CPU缓存一致性,每个处理器探测到中线上传播的数据来检查自己缓存的值是否过期,发现自己缓存行对应的内存地址呗修改,就会将当期处理器的缓存行设置成无效状态,当处理器对这个数据进行修改操作的时候,会重新重系统内存中把数据读到处理器缓存里) synchronized关键字​ synchronized是较少进入java进行多线程同步锁处理的关键字,在JDK1.6之前直接通过锁对象实现,获取和释放锁消耗代价都比较大,之后引用了偏向锁,轻量级锁等,其性能有较大的提升。 ​ java每个对象都可以作为锁对象,synchronized对不同的地方使用有不同的锁对象。 对于普通同步方法，锁是当前实例对象。 对于静态同步方法，锁是当前类的Class对象。 对于同步方法块，锁是Synchonized括号里配置的对象。 synchronized关键字的方法和代码同步是通过Monitor对象实现的。对于代码块的同步是编译器将monitorenter插入到同步代码块开始的位置,而monitorexit插入到方法结束和异常处。JVM保证每个monitorenter必须有一个对应的monitorexit,任何synchronized锁对象都有一个monitor与之关联,线程通过对monitor对象的持有进行互斥,使用monitorenter和monitorexit进行锁的获取和释放。 原子操作的实现​ 原子操作意为不可被中断的一个或一系列操作,一般处理器是通过对缓存和总线加锁的方式实现多处理器之间的原子操作。 通过总线锁保证原子性 通过处理器提供的LOCK#信号,当处理器在总线上输出此信号,其他处理器的请求将被阻塞,该处理器可以独占共享内存。 使用缓存锁保证原子性 一般原子操作我们只需要保证对某个地址的操作是原子性的即可,但是总线锁吧CPU和内存之间的通信锁定了,其他处理器不能操作其他内存数据,开销大。使用缓存锁是如果内区域被缓存在外处理器的缓存行中,并且在lock操作期间被锁定,当执行行锁操作回写内存时不是声明LOCK#信号,而是修改内部内存地址,使用缓存一致性保证原子性。 java实现原子操作 使用循环CAS实现原子操作;利用处理器提供的CMPXCHG指令实现,循环进行CAS操作直到成功为止。CAS能基本保证java的原子操作,但是也会有很多缺点 ABA问题 循环时间长开销大 只能保证一个共享变量的原子操作 使用锁机制实现原子同步;只有获得锁的线程才能够操作锁定的内存区域。JVM锁机制有偏向锁,轻量级锁和互斥锁等。除了偏向锁,JVM实现锁的方式都用了循环 CAS,即当一个线程想进入同步块的时候使用循环CAS的方式来获取锁,当它退出同步块的时候使用循环CAS释放锁。 java内存模型​ 在并发编程中,线程之间通讯和线程之间的同步是关键问题。 ​ 线程间的通讯一般使用共享内存和消息传递。在共享内存的并发模型中,通过写-读内存中的公共状态进行隐式通讯。在消息传递的并发模型里,线程之间没有内存公共状态,必须通过显式发送消息进行通讯。 ​ 线程同步是指程序中不同线程之间操作发生相对顺序控制机制。在共享内存中,同步是显式进行的,必须指定摸个方法或代码段在线程之间互斥。在消息传递模型中,同步是隐式进行的,因为发送必须在消息的接收之前。 ​ java的并发使用的共享内存模型,所以线程通讯总是隐式进行的,而同步需要显式指定需要互斥的方法或者代码段。 java内存模型的抽象结构​ java所有实例域,静态域,和数组都存储在堆内存中,线程之间共享。而局部变量,方法定义参数,异常处理器参数不会再线程之间共享,不会有内存可见性问题。 ​ java线程之间的共享变量存储在主内存中,每个线程都有一个私有的本地内存,内存内存存储该线程读/写共享变量的副本。所以A线程和B线程如故需要通讯,需要经历类似如下流程,A线程把本地内存副本共享变量A1刷新到主内存中,线程B线程到主内存中去读线程A之前更新过的共享变量。 ​ JMM控制一个线程对共享变量的写入何时对另一个线程可见,JMM通过控制住内存与每个线程的本地内存之间的交互,为java程序员提供内存可见性保证。 指令序列的重排序​ 在程序执行时,为了提高性能,编译器和处理器有时会对执行做重排序。一般分为编译器优化重排序,指令执行重排序,内存系统重排序。其中指令和内存重排序属于处理器重排序,编译器优化属于编译器重排序。JMM对于编译器重排序使用禁止特定类型的编译器重排序,对于处理器重排序使用插入特定类型的内存屏障禁止特定类型的处理器重排序来为程序员提供一致性内存可见的保证。 内存屏障 现在处理器使用写缓冲区临时保存箱内存写入的数据,写缓冲区可以保证指令流水线持续执行,避免由于处理器停顿下来等待向内存写入数据而产生的延迟。可以批处理的方式刷新写缓冲区,以及合并写缓冲区对同一内存的多次写,减少对内存总线的占用。每个处理器上的写缓冲区仅对它所在的处理器可见。 为了保证内存可见性,java编译器在生成指令序列的适当位置会插入内存屏障指令来禁止特定类型的处理器重排序。JMM把内存屏障指令分为4类。 happens-before 在JMM中,如果一 个操作执行的结果需要对另一个操作可见,那么这两个操作之间必须要存在happens-before关系.这里提到的两个操作既可以是在一个线程之内,也可以是在不同线程之间。一般主要的happens-befor规则有以下几种: 程序顺序规则;一个线程中的每个操作,happens-before于该线程中的任意后续操作。 监视器锁规则;对一个锁的解锁,happens-before于随后对这个锁的加锁。 volatile变量规则;对一个volatile域的写,happens-before于任意后续对这个volatile域的读。 传递性;如果A happens-before B,且B happens-before C,那么A happens-before C。 start()规则：如果线程A执行操作ThreadB.start()（启动线程B），那么A线程的 ThreadB.start()操作happens-before于线程B中的任意操作。 join()规则：如果线程A执行操作ThreadB.join()并成功返回，那么线程B中的任意操作 happens-before于线程A从ThreadB.join()操作成功返回。 happens-before规则简单易懂,避免了程序员为了理解JMM提供的内存可见性保证而去学习复杂的重排序规则以及这些规则的具体实现方法 JMM的内存可见性保证 通过对内存屏障以及happens-before的了解,JMM为程序员提供了JVM的内存可见性保证,具体可以分为如下三种: 1.单线程程序;单线程程序不会出现内存可见性问题,编译器、runtime和处理器会共同确保单线程程序的执行结果与该程序在顺序一致性模型中的执行结果相同。 2.正确同步的多线程程序;正确同步的多线程程序的执行将具有顺序一致性(程序的执行 结果与该程序在顺序一致性内存模型中的执行结果相同),JMM通过限 制编译器和处理器的重排序来为程序员提供内存可见性保证。 3.未同步/未正确同步的多线程程序;JMM为它们提供了最小安全性保障:线程执行时读取到的值,要么是之前某个线程写入的值,要么是默认值(0、null、false)。 java并发的基础线程简介线程是操作系统调度的最小单元,在一个进程里可以创建多个线程,这些线程都拥有各自的计数器,堆栈和局部变量等属性,并且能够访问共享的内存变量。处理器在这些线程上高速切换,让用户感觉这些线程在同时执行。 为什么使用多线程​ 多线程在某些特定的条件下并不一定比单线程执行效率高。但是在正确的使用多线程可以显著为程序员和用户带来好处。 更多的处理器核心;随着处理器的核心数越来越多,现代计算机更擅长并行计算,能更大效率的使用计算机处理器。 更快的响应时间;能极大的利用处理器的效率,在宏观下能并行处理多个任务线,给用户更快的响应时间。 更好的编程模型;是开发人员更加专注问题的解决,为问题简历合适的模型,而不是考虑如何将其多线程化。 线程的状态​ 在java线程的生命周期中有6种不同的状态,在给定的时刻线程只能处于其中的一个状态: NEW;初始状态,线程被构建,但是还没有调用start()方法。 RUNNABLE;运行状态,java线程将操作系统中的就绪和运行两种状态笼统的称为”运行中“ BLOCKED;阻塞状态,表示线程阻塞于锁 WAITING;等待状态,表示线程进入等待状态,进入等待状态表示当前线程需要等待其他线程做出一些特定动作(通知或中断) TIME_WAITING;超时等待状态,该状态不同于WAITING,它是可以再指定的时间自行返回的。 TERMINATED;终止状态,表示当前线程已执行完毕 java线程间的通讯 Volatile和synchronized关键字 java支持多线程同时访问一个对象或对象的成员变量,由于每个线程拥有这个变量的拷贝,所以在程序的执行过程中,一个线程锁访问的共享变量不一定是最新的。volatile变量能保证所有线程对变量访问都是最新的。即保证共享变量对所有线程的可见性,但有时我们需要控制方法或代码段的同步,这时候就需要使用synchronized关键字来修饰了,他保证在多线程在同一时刻,只有一个线程处于同步方法或同步块中,即保证了同步块访问的可见性和排他性。 等待/通知机制 一个线程A调用了对象O的wait()方法进入等待状态,另一个线程B调用了对象的notify()或者notifyAll()方法,线程A收到通知后从对象O的wait()方法返回,进而执行后续操作。上述两个线程通过对象O来完成交互,而对象上的wait()和notify()/notifyAll()的关系就如同开关信号,用来完成等待方和通知方之间的交互工作。 1）使用wait()、notify()和notifyAll()时需要先对调用对象加锁。 2）调用wait()方法后，线程状态由RUNNING变为WAITING，并将当前线程放置到对象的 等待队列。 3）notify()或notifyAll()方法调用后，等待线程依旧不会从wait()返回，需要调用notify()或 notifAll()的线程释放锁之后，等待线程才有机会从wait()返回。 4）notify()方法将等待队列中的一个等待线程从等待队列中移到同步队列中，而notifyAll() 方法则是将等待队列中所有的线程全部移到同步队列，被移动的线程状态由WAITING变为 BLOCKED。 5）从wait()方法返回的前提是获得了调用对象的锁。 管道输入/输出流 管道输入/输出流和普通的文件输入/输出流或者网络输入/输出流不同之处在于，它主要 用于线程之间的数据传输，而传输的媒介为内存。 管道输入/输出流主要包括了如下4种具体实现:PipedOutputStream、PipedInputStream、 PipedReader和PipedWriter，前两种面向字节，而后两种面向字符。 java中的锁​ 锁用来控制多个线程访问共享资源的方式,防止其数据或状态出现不可控的变化。 使用volatilejava提供了volatile关键字,在多个处理器中可以立即读到最新的值,即一个线程修改值后另一个线程立即能获取到更新后的值。 使用synchronized为了减少锁获取和释放带来的开销在JSE1.6版本锁的状态达到了四个,级别从低到高依次为 无锁状态&lt;偏向锁状态&lt;轻量级锁状态&lt;重量级锁状态随着竞争激烈程度依次递增。synchronize不支持锁的降级,这种策略是为了提高获取和释放锁的效率。 Lock接口​ Lock接口的实现基本都是 通过聚合了一个同步器(AQS)的子类来完成线程访问控制的。 队列同步器(AQS的介绍)​ AQS是JDK下提供的一套用于实现基于FIFO等待队列的阻塞锁或相关的同步组件的一个同步框架。实现原理是内部通过一个volatile的int类型成功变量表示同步状态,通过CAS进行原子的状态设置,内置的FIFO双向队列来完成获取锁线程的排队工作。 getState():获取当前同步状态。 setState(int newState):设置当前同步状态。 compareAndSetState(int expect,int update):使用CAS设置当前状态，该方法能够保证状态 设置的原子性。 重入锁​ 就是支持重进入的锁,它表示该锁能够支持一个线程对资源的重复加锁。除此之外,该锁的还支持获取锁时的公平和非公平性选择。在线程获取到锁之后能够再次获取该锁而不会被锁阻塞,重入锁实现原理: 1）线程再次获取锁;锁需要去识别获取锁的线程是否为当前占据锁的线程,如果是,则再 次成功获取。 2）锁的最终释放;线程重复n次获取了锁,随后在第n次释放该锁后,其他线程能够获取到该锁。锁的最终释放要求锁对于获取进行计数自增,计数表示当前锁被重复获取的次数,而锁被释放时,计数自减,当计数等于0时表示锁已经成功释放。 synchronized和reentrantLock等都是可重入锁。 公平与非公平锁的区别,公平性针对获取锁而言,如果一个锁是公平的,那么锁的获取顺序就应该符合请求的绝对时间顺序。 读写锁(ReentrantReadWriteLock)​ 读写锁在同一时刻可以允许多个读线程访问,但是在写线程访问时,所有的读线程和其他写线程均被阻塞。读写锁维护了一对锁,一个读锁和一个写锁,通过分离读锁和写锁,使得并发性相比一般的排他锁有了很大提升。 写锁的获取与释放 写锁是一个支持重进入的排它锁,如果当前线程已经获取了写锁,则增加写状态。如果当 前线程在获取写锁时,读锁已经被获取(读状态不为0)或者该线程不是已经获取写锁的线程, 则当前线程进入等待状态。 读锁的获取与释放 读锁是一个支持重进入的共享锁,它能够被多个线程同时获取,在没有其他写线程访问(或者写状态为0)时，读锁总会被成功地获取,而所做的也只是(线程安全的)增加读状态。如 果当前线程已经获取了读锁,则增加读状态。如果当前线程在获取读锁时,写锁已被其他线程 获取,则进入等待状态。 锁降级 锁降级指的是写锁降级成为读锁。如果当前线程拥有写锁,然后将其释放,最后再获取读锁,这种分段完成的过程不能称之为锁降级。锁降级是指把持住(当前拥有的)写锁,再获取到读锁,随后释放(先前拥有的)写锁的过程。 ​ RentrantReadWriteLock不支持锁升级(把持读锁、获取写锁,最后释放读锁的过程)。目的也是保证数据可见性,如果读锁已被多个线程获取,其中任意线程成功获取了写锁并更新了数据,则其更新对其他获取到读锁的线程是不可见的。 LockSupport工具​ 当需要阻塞或唤醒一个线程的时候,都会使用LockSupport工具类来完成相应 工作。LockSupport定义了一组的公共静态方法,这些方法提供了最基本的线程阻塞和唤醒功 能,而LockSupport也成为构建同步组件的基础工具。 Condition接口​ 任意一个Java对象,都拥有一组监视器方法(定义在java.lang.Object上),主要包括wait()、 wait(long timeout)、notify()以及notifyAll()方法,这些方法与synchronized同步关键字配合,可以 实现等待/通知模式。Condition接口也提供了类似Object的监视器方法,与Lock配合可以实现等 待/通知模式。 java并发容器和框架ConcurrentHashMap​ concurrentHashMap能在即保证并发环境下的安全又能保证高效的读写,其原理是将数据分成一段一段地存 储,然后给每一段数据配一把锁,当一个线程占用锁访问其中一个段数据的时候,其他段的数据也能被其他线程访问。 ​ ConcurrentHashMap是由Segment数组结构和HashEntry数组结构组成。Segment是一种可重 入锁(ReentrantLock)在ConcurrentHashMap里扮演锁的角色;HashEntry则用于存储键值对数据。一个ConcurrentHashMap里包含一个Segment数组。Segment的结构和HashMap类似,是一种 数组和链表结构。一个Segment里包含一个HashEntry数组,每个HashEntry是一个链表结构的元素,每个Segment守护着一个HashEntry数组里的元素,当对HashEntry数组的数据进行修改时,必须首先获得与它对应的Segment锁。 ConcurrentLinkedQueue​ ConcurrentLinkedQueue是一个基于链接节点的无界线程安全队列,它采用先进先出的规则对节点进行排序,当我们添加一个元素的时候,它会添加到队列的尾部;当我们获取一个元素时,它会返回队列头部的元素。 阻塞队列​ 阻塞队列(BlockingQueue)是一个支持两个附加操作的队列。这两个附加的操作支持阻塞的插入和移除方法。 支持阻塞的插入方法:意思是当队列满时,队列会阻塞插入元素的线程,直到队列不 满。 支持阻塞的移除方法:意思是在队列为空时,获取元素的线程会等待队列变为非空。 阻塞队列常用于生产者和消费者的场景,生产者是向队列里添加元素的线程,消费者是从队列里取元素的线程。阻塞队列就是生产者用来存放元素、消费者用来获取元素的容器。 JDK 7提供了7个阻塞队列 ArrayBlockingQueue:一个由数组结构组成的有界阻塞队列。 LinkedBlockingQueue:一个由链表结构组成的有界阻塞队列。 PriorityBlockingQueue:一个支持优先级排序的无界阻塞队列。 DelayQueue:一个使用优先级队列实现的无界阻塞队列。 SynchronousQueue:一个不存储元素的阻塞队列。 LinkedTransferQueue:一个由链表结构组成的无界阻塞队列。 LinkedBlockingDeque:一个由链表结构组成的双向阻塞队列。 阻塞队列是使用通知模式实现。所谓通知模式,就是当生产者往满的队列里添加元素时会阻塞住生产者,当消费者消费了一个队列中的元素后,会通知生产者当前队列可用。 Fork/Join框架​ Fork/Join框架是Java 7提供的一个用于并行执行任务的框架,是一个把大任务分割成若干个小任务,最终汇总每个小任务结果后得到大任务结果的框架。 java中的原子操作类AtomicBoolean：原子更新布尔类型AtomicInteger：原子更新整型AtomicLong：原子更新长整型AtomicIntegerArray：原子更新整型数组里的元素AtomicLongArray：原子更新长整型数组里的元素AtomicReferenceArray：原子更新引用类型数组里的元素AtomicIntegerArray类主要是提供原子的方式更新数组里的整型AtomicReference：原子更新引用类型AtomicReferenceFieldUpdater：原子更新引用类型里的字段AtomicMarkableReference：原子更新带有标记位的引用类型AtomicIntegerFieldUpdater：原子更新整型的字段的更新器AtomicLongFieldUpdater：原子更新长整型字段的更新器AtomicStampedReference：原子更新带有版本号的引用类型 java中的并发工具类多线程完成的CountDownLatch​ CountDownLatch允许一个或多个线程等待其他线程完成操作。 同步屏障CyclicBarrier​ CyclicBarrier的字面意思是可循环使用(Cyclic)的屏障(Barrier)它要做的事情是,让一 组线程到达一个屏障(也可以叫同步点)时被阻塞,直到最后一个线程到达屏障时,屏障才会 开门,所有被屏障拦截的线程才会继续运行。 ​ CountDownLatch的计数器只能使用一次,而CyclicBarrier的计数器可以使用reset()方法重置。所以CyclicBarrier能处理更为复杂的业务场景。例如,如果计算发生错误,可以重置计数 器,并让线程重新执行一次。 控制并发线程数的Semaphore​ Semaphore（信号量）是用来控制同时访问特定资源的线程数量，它通过协调各个线程，以 保证合理的使用公共资源。 线程交换数据的Exchanger​ Exchanger(交换者)是一个用于线程间协作的工具类。Exchanger用于进行线程间的数据交 换。它提供一个同步点,在这个同步点,两个线程可以交换彼此的数据。这两个线程通过 exchange方法交换数据,如果第一个线程先执行exchange()方法,它会一直等待第二个线程也 执行exchange方法,当两个线程都到达同步点时,这两个线程就可以交换数据,将本线程生产出来的数据传递给对方。 线程池线程池的处理流程如下 线程池判断核心线程池里的线程是否都在执行任务。如果不是，则创建一个新的工作 线程来执行任务。如果核心线程池里的线程都在执行任务，则进入下个流程。 线程池判断工作队列是否已经满。如果工作队列没有满，则将新提交的任务存储在这 个工作队列里。如果工作队列满了，则进入下个流程。 线程池判断线程池的线程是否都处于工作状态。如果没有，则创建一个新的工作线程 来执行任务。如果已经满了，则交给饱和策略来处理这个任务。 Executor框架Executor框架的主要接口 Executor是一个接口，它是Executor框架的基础，它将任务的提交与任务的执行分离开 ThreadPoolExecutor是线程池的核心实现类，用来执行被提交的任务。 ScheduledThreadPoolExecutor是一个实现类，可以在给定的延迟后运行命令，或者定期执 行命令ScheduledThreadPoolExecutor比Timer更灵活，功能更强大。 Future接口和实现Future接口的FutureTask类，代表异步计算的结果。 Runnable接口和Callable接口的实现类，都可以被ThreadPoolExecutor或ScheduledThreadPoolExecutor执行。 java并发编程]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>并发编程</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[哈希表_散列表]]></title>
    <url>%2F2018%2F08%2F20%2Fsenssic.github.io%2F201901%2F%E5%93%88%E5%B8%8C%E8%A1%A8-%E6%95%A3%E5%88%97%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[哈希表介绍哈希表(也称散列表,hash table),是根据键值直接访问其对应的数据存储位置的一种数据结构。若使用数组或者链表来存储元素则在比较某个元素时,数组或链表需要循环进行比较,而通过哈希表只需要计算出对应的哈希位置取出对应的值进行比较或判断在否。 其有以下几种特性: 若关键字为k,则其值存放在f(k)[散列函数]的存储位置上。 对不同的关键字可能得到同一散列地址，即k1≠k2而f(k1)=f(k2),这种现象称为冲突。 若对于关键字集合中的任一个关键字，经散列函数映象到地址集合中任何一个地址的概率是相等的，则称此类散列函数为均匀散列函数,以便减少冲突。 构造哈希函数的方法一个好的哈希函数能够提升查找效率减少哈希地址冲突带来的额外处理开销,常用的哈希函数有以下几种: 直接地址 H(key) = key 或 H(key) = a*key + b，其中a和b为常数 平方取中法 先计算出关键字值的平方，然后取平方值中间几位作为散列地址。假如有以下关键字序列{421，423，436}，平方之后的结果为{177241，178929，190096}，那么可以取中间的两位数{72，89，00}作为Hash地址。 折叠法 将关键字拆分成几部分，然后将这几部分组合在一起，以特定的方式进行转化形成Hash地址。假如知道图书的ISBN号为8903-241-23，可以将address(key)=89+03+24+12+3作为Hash地址。 除留取余法 如果知道Hash表的最大长度为m，可以取不大于m的最大质数p，然后对关键字进行取余运算，address(key)=key%p。在这里p的选取非常关键，p选择的好的话，能够最大程度地减少冲突，p一般取不大于m的最大质数。当关键字是整数时候比较好的避免冲突。 数字分析法 假设关键字是以r为基的数，并且哈希表中可能出现的关键字都是事先知道的，则可取关键字的若干数位组成哈希地址。 随机数法 选择一个随机函数，把关键字的随机函数值作为它的哈希值,通常当关键字的长度不等时用这种方法。当关键字是小数的时候比较好的避免地址冲突。 解决哈希冲突基于哈希的数据结构有着接近常量的时间即0(1)[基于数据]的时间复杂度,对于大量数据的查询效率极为高效。哈希的查找效率因数基本和哈希函数是否均匀,处理冲突的方法,哈希表的加载因子有关。 开放地址法 当发生冲突时,从当前位置向后按某种策略遍历哈希表。当发现可用的空间的时候,则插入元素。开放地址有一次探测(hs=(h(key)+i) ％ m,0 ≤ i ≤ m-1)、二次探测(hi=(h(key)+i*i) ％ m，0 ≤ i ≤ m-1)和双重哈希(hs=(h(key)+i*h1(key)) ％ m,0 ≤ i ≤ m-1)。 一次探测 探查时从地址 d 开始，首先探查 T[d]，然后依次探查 T[d+1]，…，直到 T[m-1]，此后又循环到 T[0]，T[1]，…，直到探查到 有空余地址 或者到 T[d-1]为止。 二次探测 探查时从地址 d 开始，首先探查 T[d]，然后依次探查 T[d+1^2]，T[d+2^2]，T[d+3^2],…，等，直到探查到 有空余地址 或者到 T[d-1]为止。缺点是无法探查到整个散列空间。 双重哈希 探查时从地址 d 开始，首先探查 T[d]，然后依次探查 T[d+h1(d)], T[d + 2*h1(d)]，…，等。该方法使用了两个散列函数 h(key) 和 h1(key)，故也称为双散列函数探查法。定义 h1(key) 的方法较多，但无论采用什么方法定义，都必须使 h1(key) 的值和 m 互素，才能使发生冲突的同义词地址均匀地分布在整个表中，否则可能造成同义词地址的循环计算。该方法是开放定址法中最好的方法之一。 开放定址在解决当前冲突的情况下同时可能会导致新的冲突，而开链不会有这种问题。 链地址法(又开链法) 开链的思想是哈希表中的每个元素都是一个类似链表或者其他数据结构的 head。当出现冲突时，我们就在链表后面添加元素。这也就意味着，如果某一个位置冲突过多的话，插入的时间复杂段将退化为 O(N)。 开链相比于开放定址局部性较差，在程序运行过程中可能引起操作系统的缺页中断，从而导致系统颠簸。 ​ 再哈希法 Hi=RH1（key） i=1，2，…，k 当哈希地址Hi=RH1（key）发生冲突时，再计算Hi=RH2（key）……，直到冲突不再产生。这种方法不易产生聚集，但增加了计算时间。很多语言或者工具包再哈希的内部实现是使用了两个数组，其中一个作为备用。如果当前哈希表的负载因子（元素个数/哈希表容量大小）过大或者过小时，就将数据切换到备用数组里。 建立一个公共溢出区 假设哈希函数的值域为[0,m-1],则设向量HashTable[0..m-1]为基本表，另外设立存储空间向量OverTable[0..v]为溢出表用以存储发生冲突的记录。，凡是和基本表发生冲突的元素，一律填入溢出表。 一次性哈希算法在分布式的系统中我们希望能把数据进行分布式存储,这样能极大的提升整体性能,但是需要保证相同的缓存key请求总是能被负载到同一台机器。我们可以使用简单的hash算法,对于每次访问，可以按如下算法计算其哈希值： h = Hash(key) % n 字符串到正整数的哈希映射函数。这样，如果我们将服务器数量n分别编号为0、1、2，那么就可以根据上式和key计算出服务器编号h，然后去访问。 这样做虽然能解决问题,但是存在扩展性不好的缺点,如果增加或删除一台机器势必需要哈希值得重新计算导致大量的key会被重定位到不同的服务器从而造成大量的缓存不命中。 ​ 简单来说，一致性哈希将整个哈希值空间组织成一个虚拟的圆环，如假设某哈希函数H的值空间为0 - 232-1（即哈希值是一个32位无符号整形）,整个空间按顺时针方向组织。0和232-1在零点中方向重合。将数据key使用相同的函数H计算出哈希值h，通根据h确定此数据在环上的位置，从此位置沿环顺时针“行走”，第一台遇到的服务器就是其应该定位到的服务器。一致性哈希算法对于节点的增减都只需重定位环空间中的一小部分数据，具有较好的容错性和可扩展性。 虚拟节点​ 一致性哈希算法在服务节点太少时，容易因为节点分部不均匀而造成数据倾斜问题。使得大量数据会访问到同一台机器上,为了解决这种数据倾斜问题，一致性哈希算法引入了虚拟节点机制，即对每一个服务节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点。数据定位算法不变，只是多了一步虚拟节点到实际节点的映射。 哈希表的实现(1) 一次性了解哈希相关概念：哈希 哈希函数 冲突解决 哈希表 聊一聊哈希表 [一致性哈希算法及其在分布式系统中的应用]]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>哈希表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java锁相关]]></title>
    <url>%2F2018%2F08%2F16%2Fsenssic.github.io%2F201901%2Fjava%E9%94%81%E7%9B%B8%E5%85%B3%2F</url>
    <content type="text"><![CDATA[在并发系统中常常需要对某些业务资源进行加锁操作，解决一些因并发操作导致的数据不一致,以及读到脏数据问题。 加锁的目的本质上是对资源的一种操作控制,防止其数据或状态出现不可控的变化。 java中对于锁的支持使用volatilejava提供了volatile关键字,在多个处理器中可以立即读到最新的值,即一个线程修改值后另一个线程立即能获取到更新后的值。 在某些适用volatile场景的地方使用volatile控制线程变量可见性会起到很好的效果,虽然volatile不能代替synchronize(因为volatile不能提供原子操作,只是对于多线程的变量可见性),但在适用的场景下要优于synchronize执行成本,因为它不会引起线程上下文的切换和调度。 使用synchronizesynchronize通过锁机制实现同步具体锁对象有三种方式 普通方法的同步,锁是当前实力对象 静态方法的同步,锁是当前类的class对象 对于同步代码块,锁是括号内的对象 synchronize的实现原理synchronize是通过jvm执行Monitor的互斥执行和协作来实现锁的。 互斥:使用synchronize获取的对象锁来进行共享数据线程互斥 协作:通过notify/notifyAll/wait方法同步线程之间的操作 必要条件:每个Object和Class都关联了一个monitor Monitor 的工作机理 线程进入同步方法中。 为了继续执行临界区代码，线程必须获取 Monitor 锁。如果获取锁成功，将成为该监视者对象的拥有者。任一时刻内，监视者对象只属于一个活动线程（The Owner）,对于重入的synchronize关键字monitor会讲进入数自增1,所以synchronize是可重入锁 拥有监视者对象的线程可以调用 wait() 进入等待集合（Wait Set），同时释放监视锁，进入等待状态。 其他线程调用 notify() / notifyAll() 接口唤醒等待集合中的线程，这些等待的线程需要重新获取监视锁后才能执行 wait() 之后的代码。 同步方法执行完毕了，线程退出临界区，并释放监视锁。 synchronize锁机制的优化为了减少锁获取和释放带来的开销在JSE1.6版本锁的状态达到了四个,级别从低到高依次为 无锁状态&lt;偏向锁状态&lt;轻量级锁状态&lt;重量级锁状态随着竞争激烈程度依次递增。synchronize不支持锁的降级,这种策略是为了提高获取和释放锁的效率。 偏向锁-一段代码一直被同一个线程访问,那么该线程自动获取锁,此举为了降低获取锁的代价。 优点:加锁和解锁不需要额外的消耗,和非同步代码比较仅存在纳秒级别的差距。 缺点:一旦出现锁竞争会有撤销锁的消耗。 轻量级锁-当锁是偏向锁的时候，被另一个线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，提高性能。 优点:线程不阻塞,提高性能 缺点:如果长时间得不到锁自旋会消耗cpu 重量级锁-当锁是轻量级锁的时候,另一个线程虽然在自旋但不会一直自旋,当自旋到一定次数还没有获取到锁就会进入阻塞该锁膨胀为重量级锁,重量级锁会让其他申请的线程进入阻塞,性能降低。 优点:不会消耗cpu 缺点:线程阻塞,响应时间缓慢。 自旋状态-轻量级锁的具体实现原理,指尝试获取锁的线程不会立即阻塞，而是采用循环的方式去尝试获取锁，这样的好处是减少线程上下文切换的消耗，缺点是循环会消耗CPU。 CAS(compare and swap)和AQS(AbstractQueuedSynchronizer)CAS的介绍CAS是一个原子操作,利用了处理器的CMPXCHG指令实现的,CAS操作包括三个操作数,内存位置(V),预期原值(A)和新值(B)。如果内存位置和预期原值相等则处理器会将内存位置更新为新值(B),若反之则不做任何操作。 CAS的优点在于竞争不大的情况下系统开销小,缺点是只能保证一个变量的原子操作,以及不能避免ABA问题(如果另一个线程修改V值假设原来是A，先修改成B，再修改回成A,当前线程的CAS操作无法分辨当前V值是否发生过变化)。 AQS的介绍AQS是JDK下提供的一套用于实现基于FIFO等待队列的阻塞锁或相关的同步组件的一个同步框架。 AQS的实现原理内部通过一个volatile的int类型成功变量表示同步状态 123456789101112131415161718192021222324252627282930/** * The synchronization state. * 同步状态 */private volatile int state;/** * Returns the current value of synchronization state. * 获取当前同步状态 */protected final int getState() &#123; return state;&#125;/** * Sets the value of synchronization state. * 设置当前同步状态 */protected final void setState(int newState) &#123; state = newState;&#125;/** * Atomically sets synchronization state to the given updated * value if the current state value equals the expected value. * 使用CAS设置当前状态,该方法能保证状态设置的原子性 */protected final boolean compareAndSetState(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, stateOffset, expect, update);&#125; 内置的FIFO双向队列来完成获取锁线程的排队工作 同步器包含两个节点类型的应用，一个指向头节点，一个指向尾节点，未获取到锁的线程会创建节点线程安全（compareAndSetTail）的加入队列尾部。同步队列遵循FIFO，首节点是获取同步状态成功的节点。 未获取到锁的线程将创建一个节点，设置到尾节点 首节点的线程在释放锁时，将会唤醒后继节点。而后继节点将会在获取锁成功时将自己设置为首节点 独占式和共享式获取锁独享锁-指该锁一次只能被一个线程所持有共享锁-指该锁可被多个线程所持有 独占锁(ReentrantLock) ​ 每个节点自旋观察自己的前一节点是不是Header节点，如果是，就去尝试获取锁 ​ 独占式锁获取流程 ​ 共享锁(CountDownLatch) ​ 共享式与独占式的区别 ​ 共享锁获取流程 Java中的锁 (原理、锁优化、CAS、AQS)Java中的锁分类]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>锁</tag>
      </tags>
  </entry>
</search>
